{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Malignant Comment Classification\n",
    "By-\n",
    "Nikhil Bharadwaj, \n",
    "Hemanta Pattnaik, \n",
    "Nikhil Gohil, \n",
    "Pratik Bhatia, \n",
    "Tejas Mehta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "### COMMENT CLASSIFICATION \n",
    "\n",
    "1. Import necessary files <br/>\n",
    "2. Read the train.csv file <br/>\n",
    "3. List the various fields in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 8)\n"
     ]
    }
   ],
   "source": [
    "#Read the csv file into dataframe df\n",
    "df = pd.read_csv(\"data/train.csv\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id               object\n",
      "comment_text     object\n",
      "toxic             int64\n",
      "severe_toxic      int64\n",
      "obscene           int64\n",
      "threat            int64\n",
      "insult            int64\n",
      "identity_hate     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#List the fields in our dataframe\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence we have a sufficiently large dataset consistly of 95851 samples. Each sample contains 8 fields. <br/>\n",
    "**It was observed that running train_test_split on the heavy preprocessed dataframe sometimes resulted in system going out of memory. Hence to avoid such cases, one extra line of code was added. The df.reindex code will shuffle the indices initially, so that later splitting dataset into training and testing will give fairer results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below line causes shuffling of indices, to avoid using train_test_split later\n",
    "df = df.reindex(np.random.permutation(df.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate the comment field data and outcome labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68579                 REDIRECT Talk:Roland Green (cyclist)\n",
      "20578    REDIRECT Talk:Wrestling at the 1904 Summer Oly...\n",
      "52793    \"\\n\\n Understanding how Wikipedia does things ...\n",
      "85375    You need to look up the difference between a c...\n",
      "61373    Get a life people. You cannot canvey your ange...\n",
      "Name: comment_text, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "comment = df['comment_text']\n",
    "print(comment.head())\n",
    "comment = comment.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
      "68579      0             0        0       0       0              0\n",
      "20578      0             0        0       0       0              0\n",
      "52793      0             0        0       0       0              0\n",
      "85375      0             0        0       0       0              0\n",
      "61373      0             0        0       0       0              0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "label = df[['toxic', 'severe_toxic' , 'obscene' , 'threat' , 'insult' , 'identity_hate']]\n",
    "print(label.head())\n",
    "label = label.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us find out the frequency of occurence of multilabelled data \n",
    "- ct1 counts samples having atleast one label\n",
    "- ct2 counts samples having 2 or more than 2 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16225\n",
      "9865\n"
     ]
    }
   ],
   "source": [
    "ct1,ct2 = 0,0\n",
    "for i in range(label.shape[0]):\n",
    "    ct = np.count_nonzero(label[i])\n",
    "    if ct :\n",
    "        ct1 = ct1+1\n",
    "    if ct>1 :\n",
    "        ct2 = ct2+1\n",
    "print(ct1)\n",
    "print(ct2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualisations\n",
    "### Let us analyse the no. of comments having lengths varying from 0 to 1200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average length of comment: 394.073\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ4AAAEKCAYAAAAiizNaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3df7QdVX338feH8CtGIIGkeTCBEiTFB6EiIISC9goaLtQS6kKEuiTwUNKnoMVKnxpqJQpSpS1a01okS2KCC/lRBIkCxhg51B+L3yAhQMwFRJLyqwQSLggS+D5/zPfAIdwfc5N75txz8nmtNevMfGfPnL05cL/MzJ69FRGYmZlVZYtWV8DMzDYvTjxmZlYpJx4zM6uUE4+ZmVXKicfMzCrlxGNmZpVqauKRdIakeyUtl/SpjO0oaYmklfk5LuOSNFdSj6R7JO3XcJ6ZWX6lpJkN8f0lLctj5kpSM9tjZmabrmmJR9LewKnAgcC7gA9J2gOYDSyNiKnA0twGOBKYmsss4MI8z47AHOCgPNecerLKMqc2HNfdrPaYmdnwaOYVz/8GbomIFyJiPXAT8GFgBrAwyywEjsn1GcAlUbgZGCtpZ+AIYElErImIZ4AlQHfu2z4ibo7iLdhLGs5lZmYj1JZNPPe9wHmSdgJ+CxwF3A5MjIjHsszjwMRcnwQ82nD8qowNFF/VR/xNJM2iuIpi22233X/XXXfd+FaNYK+++ipbbNG5j+3cvvbm9rWvX/3qV/8TEROG63xNSzwRcb+k84EfAc8DdwOvbFAmJDV9zJ6ImAfMA9hzzz1jxYoVzf7KlqjVanR1dbW6Gk3j9rU3t699SXpkOM/X1PQcERdHxP4R8T7gGeBXwBN5m4z8fDKLrwZ2aTh8csYGik/uI25mZiNYs3u1/V5+7krxfOc7wCKg3jNtJnBtri8CTszebdOAtXlLbjEwXdK47FQwHVic+9ZJmpa92U5sOJeZmY1QzXzGA/DdfMbzMnB6RDwr6cvAlZJOAR4Bjsuy11M8B+oBXgBOBoiINZLOBW7LcudExJpcPw1YAIwGbsjFzMxGsKYmnoh4bx+xp4HD+4gHcHo/55kPzO8jfjuw96bX1MzMqtKZXTDMzGzEcuIxM7NKOfGYmVmlnHjMzKxSTjxmZlYpJx4zM6uUE4+ZmVXKicfMzCrlxGNmZpVy4jEzs0o58ZiZWaWceMzMrFJOPGZmViknHjMzq5QTj5mZVarZM5D+jaTlku6VdJmkbSVNkXSLpB5JV0jaOstuk9s9uX+3hvOclfEVko5oiHdnrEfS7Ga2xczMhkfTEo+kScBfAwdExN7AKOB44HzgqxGxB/AMcEoecgrwTMa/muWQtFce906gG/gPSaMkjQK+DhwJ7AWckGXNzGwEa/atti2B0ZK2BN4CPAYcBlyV+xcCx+T6jNwm9x8uSRm/PCJeioiHKabGPjCXnoh4KCJ+B1yeZc3MbARrWuKJiNXAvwC/oUg4a4E7gGcjYn0WWwVMyvVJwKN57Posv1NjfINj+oubmdkItmWzTixpHMUVyBTgWeA/KW6VVU7SLGAWwIQJE6jVaq2oRtP19vZ2bNvA7Wt3bp/VNS3xAB8AHo6IpwAkXQ0cAoyVtGVe1UwGVmf51cAuwKq8NbcD8HRDvK7xmP7ibxAR84B5AHvuuWd0dXVtcuNGolqtRqe2Ddy+duf2WV0zn/H8Bpgm6S35rOZw4D7gRuDYLDMTuDbXF+U2uf8nEREZPz57vU0BpgK3ArcBU7OX3NYUHRAWNbE9ZmY2DJp2xRMRt0i6CrgTWA/cRXHVcR1wuaQvZuziPORi4NuSeoA1FImEiFgu6UqKpLUeOD0iXgGQ9AlgMUWPufkRsbxZ7TEzs+HRzFttRMQcYM4G4YcoeqRtWPZF4CP9nOc84Lw+4tcD1w+lTr99+RV2m33dUA5pGwu6x7S6CmZmg/LIBWZmViknHjMzq5QTj5mZVcqJx8zMKuXEY2ZmlXLiMTOzSjnxmJlZpZx4zMysUk48ZmZWKSceMzOrlBOPmZlVyonHzMwq5cRjZmaVcuIxM7NKOfGYmVmlnHjMzKxSTUs8kvaUdHfDsk7SpyTtKGmJpJX5OS7LS9JcST2S7pG0X8O5Zmb5lZJmNsT3l7Qsj5mbU2ybmdkI1rTEExErImLfiNgX2B94AbgGmA0sjYipwNLcBjgSmJrLLOBCAEk7UsxiehDFzKVz6skqy5zacFx3s9pjZmbDo6pbbYcDD0bEI8AMYGHGFwLH5PoM4JIo3AyMlbQzcASwJCLWRMQzwBKgO/dtHxE3R0QAlzScy8zMRqgtK/qe44HLcn1iRDyW648DE3N9EvBowzGrMjZQfFUf8TeRNIviKorx4ydw9j7rN7ohI1lvby+1Wq3V1Wgat6+9uX1W1/TEI2lr4GjgrA33RURIimbXISLmAfMAdt19j7hgWVX5tloLusfQ1dXV6mo0Ta1Wc/vamNtndVXcajsSuDMinsjtJ/I2Gfn5ZMZXA7s0HDc5YwPFJ/cRNzOzEayKxHMCr99mA1gE1HumzQSubYifmL3bpgFr85bcYmC6pHHZqWA6sDj3rZM0LXuzndhwLjMzG6Gaes9J0hjgg8BfNoS/DFwp6RTgEeC4jF8PHAX0UPSAOxkgItZIOhe4LcudExFrcv00YAEwGrghFzMzG8Gamngi4nlgpw1iT1P0ctuwbACn93Oe+cD8PuK3A3sPS2XNzKwSHrnAzMwq5cRjZmaVGjTxSPqIpO1y/R8kXd04nI2ZmdlQlLni+VxEPCfpUOADwMXkcDZmZmZDVSbxvJKffwLMi4jrgK2bVyUzM+tkZRLPakkXAR8Frpe0TcnjzMzM3qRMAjmO4iXOIyLiWWBH4P81tVZmZtaxyiSeiyLi6ohYCZAjBny8udUyM7NOVSbxvLNxQ9Ioivl1zMzMhqzfxCPpLEnPAX+Ys4euy+0n8ZhoZma2kfpNPBHxpYjYDvjniNg+l+0iYqeIeNMUB2ZmZmUMOlZbRJwlaRLw+43lI+K/mlkxMzPrTIMmHklfpphB9D5ef6cnACceMzMbsjKjU/8ZsGdEvNTsypiZWecr06vtIWCrZlfEzMw2D2USzwvA3ZIukjS3vpQ5uaSxkq6S9ICk+yUdLGlHSUskrczPcVlWee4eSfc0DkQqaWaWXylpZkN8f0nL8pi5OROpmZmNYGUSzyLgXOAXwB0NSxlfA34YEe8A3gXcD8wGlkbEVGBpbgMcCUzNZRY5EKmkHYE5wEHAgcCcerLKMqc2HNddsl5mZtYiZXq1LZQ0Gtg1IlaUPbGkHYD3ASfleX4H/E7SDKAriy0EasBngBnAJTkT6c15tbRzll1Sn+5a0hKgW1IN2D4ibs74JcAxePprM7MRrUyvtj8F/oViROopkvYFzomIowc5dArwFPAtSe+iuEo6A5iYw+4APA5MzPVJwKMNx6/K2EDxVX3E+2rDLIqrKMaPn8DZ+6wfpOrtqbe3l1qt1upqNI3b197cPqsr06vt8xS3uGoAEXG3pN1Lnns/4JMRcYukr/H6bTXyXCEphlTjjRAR84B5ALvuvkdcsKxMs9vPgu4xdHV1tboaTVOr1dy+Nub2WV2ZZzwvR8TaDWKvljhuFbAqIm7J7asoEtETeQuN/Hwy968Gdmk4fnLGBopP7iNuZmYjWJnEs1zSnwOjJE2V9G8UHQ0GFBGPA49K2jNDh1O8hLoIqPdMm8nr474tAk7M3m3TgLV5S24xMF3SuOxUMB1YnPvWSZqWvdlOxGPImZmNeGXuOX0S+CzwEnAZRSI4t+T5PwlcKmlriveBTqZIdldKOgV4hGK+H4DrgaOAHoou3CcDRMQaSecCt2W5c+odDYDTgAXAaIpOBe5YYGY2wpXp1fYCReL57FBPHhF3Awf0sevwPsoGcHo/55kPzO8jfjuw91DrZWZmrVOmV9sBwN8Du/HGQUL/sHnVMjOzTlXmVtulFFNdL6NcpwIzM7N+lUk8T0XEoqbXxMzMNgtlEs8cSd+kGN7mtRGqI+LqptXKzMw6VpnEczLwDooRquu32gJw4jEzsyErk3jeExF7Dl7MzMxscGVeIP2FpL2aXhMzM9sslLnimUYxH8/DFM94RPHajbtTm5nZkJVJPJ7jxszMhk2ZkQseyTHSdtmg/CNNq5WZmXWsMiMXnEsxmduDFL3ZyM/DmlctMzPrVGVutR0HvD1nEDUzM9skZXq13QuMbXZFzMxs81DmiudLwF2S7uWNIxcMNvW1mZnZm5RJPAuB8/EgoWZmNgzK3Gp7ISLmRsSNEXFTfSlzckm/lrRM0t2Sbs/YjpKWSFqZn+MyLklzJfVIukfSfg3nmZnlV0qa2RDfP8/fk8dqiO03M7OKlUk8P5X0JUkHS9qvvgzhO94fEftGRH1CuNnA0oiYSjHw6OyMHwlMzWUWcCEUiQqYAxwEHEgxaOm4POZC4NSG4/zOkZnZCFfmVtu783NaQ2xTulPPALpyfSFQAz6T8UtyJtKbJY2VtHOWXVKf7lrSEqBbUg3YPiJuzvglwDF4+mszsxGtzAuk79+E8wfwI0kBXBQR84CJEfFY7n8cmJjrk4BHG45dlbGB4qv6iL+JpFkUV1GMHz+Bs/dZvwlNGrl6e3up1WqtrkbTuH3tze2zujIvkO5AcavrfRm6CTgnItaWOP+hEbFa0u8BSyQ90LgzIiKTUlNlwpsHsOvue8QFy8pc6LWfBd1j6OrqanU1mqZWq7l9bczts7oyz3jmA89RvEh6HLAO+FaZk0fE6vx8EriG4hnNE3kLjfx8MouvphiWp25yxgaKT+4jbmZmI1iZxPP2iJgTEQ/l8gVg98EOkjRG0nb1dWA6xcuoi4B6z7SZwLW5vgg4MXu3TQPW5i25xcB0SeOyU8F0YHHuWydpWvZmO7HhXGZmNkKVuef0W0mHRsTPACQdAvy2xHETgWuyh/OWwHci4oeSbgOulHQKxUCjx2X564GjgB7gBYqZT4mINTle3G1Z7px6RwPgNGABMJqiU4E7FpiZjXBlEs9fAQvzWQ/AMxSDhg4oIh4C3tVH/Gng8D7iAZzez7nmU9zy2zB+O7D3YHUxM7ORo0yvtruBd0naPrfXNb1WZmbWsQZ9xiPpHyWNjYh1EbEun7V8sYrKmZlZ5ynTueDIiHi2vhERz1A8izEzMxuyMolnlKRt6huSRgPbDFDezMysX2U6F1wKLJVUf3fnZIqhbszMzIasTOeC8yX9EvhAhs6NiMXNrZaZmXWqUmPHRMQPgR82uS5mZrYZKPOMx8zMbNg48ZiZWaX6TTySlubn+dVVx8zMOt1Az3h2lvRHwNGSLgfeMK10RNzZ1JqZmVlHGijxnA18jmK6ga9ssG9TZiA1M7PNWL+JJyKuAq6S9LmIOLfCOpmZWQcr8x7PuZKO5vUZSGsR8YPmVsvMzDpVmUFCvwScAdyXyxmS/rHZFTMzs85Upjv1nwAfjIj5OS9ON/Chsl8gaZSkuyT9ILenSLpFUo+kKyRtnfFtcrsn9+/WcI6zMr5C0hEN8e6M9UiaXbZOZmbWOmXf4xnbsL5Dv6X6dgZwf8P2+cBXI2IPiknlTsn4KcAzGf9qlkPSXsDxwDspkt5/ZDIbBXwdOBLYCzghy5qZ2QhWJvF8CbhL0gJJC4E7gPPKnFzSZIorpm/mtih6w12VRRYCx+T6DF4ffPQq4PAsPwO4PCJeioiHKabGPjCXnoh4KCJ+B1yeZc3MbAQr07ngMkk14D0Z+kxEPF7y/P8K/B2wXW7vBDwbEetzexUwKdcnAY/md66XtDbLTwJubjhn4zGPbhA/qK9KSJoFzAIYP34CZ++zvq9iba+3t5dardbqajSN29fe3D6rKztI6GPAoqGcWNKHgCcj4g5JXRtRt2ETEfOAeQC77r5HXLCsVLPbzoLuMXR1dbW6Gk1Tq9Xcvjbm9lldM/8CH0Ix6sFRwLbA9sDXgLGStsyrnsnA6iy/GtgFWCVpS4pnSU83xOsaj+kvbmZmI1TTBgmNiLMiYnJE7EbROeAnEfEx4Ebg2Cw2E7g21xflNrn/JxERGT8+e71NAaYCtwK3AVOzl9zW+R1DuiozM7PqDXjFkz3HlkfEO4bxOz8DXC7pi8BdwMUZvxj4tqQeYA1FIiEilku6kuIdovXA6RHxStbvE8BiYBQwPyKWD2M9zcysCQZMPBHxSr4ns2tE/GZjvyQiakAt1x+i6JG2YZkXgY/0c/x59NGTLiKuB67f2HqZmVn1yjzjGQcsl3Qr8Hw9GBFHN61WtlGWrV7LSbOva3U1mmZB95hWV8HMhkGZxPO5ptfCzMw2G2Xe47lJ0u8DUyPix5LeQvFMxczMbMjKDBJ6KsVIAhdlaBLwvWZWyszMOleZ7tSnU7yTsw4gIlYCv9fMSpmZWecqk3heyrHQAMiXO6N5VTIzs05WJvHcJOnvgdGSPgj8J/D95lbLzMw6VZnEMxt4ClgG/CXFezP/0MxKmZlZ5yrTq+3VnA7hFopbbCtyKBszM7MhGzTxSPoT4BvAg4CAKZL+MiJuaHblzMys85R5gfQC4P0R0QMg6e3AdYATj5mZDVmZZzzP1ZNOegh4rkn1MTOzDtfvFY+kD+fq7ZKuB66keMbzEYopCczMzIZsoFttf9qw/gTwx7n+FDC6aTUyM7OO1m/iiYiTq6yImZltHsqM1TZF0lckXS1pUX0pcdy2km6V9EtJyyV9oeF8t0jqkXRFzh5KzjB6RcZvkbRbw7nOyvgKSUc0xLsz1iNp9sb8AzAzs2qV6dX2PYrZQb8PvDqEc78EHBYRvZK2An4m6Qbg08BXI+JySd8ATgEuzM9nImIPSccD5wMflbQXxWyk7wTeBvxY0h/kd3wd+CCwCrhN0qKIuG8IdTQzs4qVSTwvRsTcoZ44XzLtzc2tcgngMODPM74Q+DxF4pmR61CMhv3vkpTxyyPiJeDhnBq7PoNpT85oiqTLs6wTj5nZCFYm8XxN0hzgRxRXMQBExJ2DHShpFHAHsAfF1cmDwLMRsT6LrKKYZoH8fDTPvV7SWmCnjN/ccNrGYx7dIH5QP/WYBcwCGD9+Amfvs76vYm1v4mg4s0PbBtDb20utVmt1NZrG7Wtvnd6+4VQm8ewDfJziSqV+q61+5TKgiHgF2FfSWOAa4B0bWc9NEhHzgHkAu+6+R1ywrEyz28+Z+6ynU9sGxdTXXV1dra5G09RqNbevjXV6+4ZTmb9SHwF2b5waYagi4llJNwIHA2MlbZlXPZOB1VlsNbALsCqnXtgBeLohXtd4TH9xMzMbocqMXHAvMHaoJ5Y0Ia90kDSaohPA/cCNwLFZbCZwba4vym1y/0/yOdEi4Pjs9TYFmArcSvES69TsJbc1RQeEQXvbmZlZa5W54hkLPCDpNt74jOfoQY7bGViYz3m2AK6MiB9Iug+4XNIXgbsoesyRn9/OzgNrKBIJEbFc0pUUnQbWA6fnLTwkfQJYDIwC5kfE8jKNNjOz1imTeOZszIkj4h7g3X3EH+L1XmmN8Rcpbuv1da7zgPP6iF9PMT+QmZm1iTLz8dxURUXMzGzzUGY+nucoerEBbE3xPs7zEbF9MytmZmadqcwVz3b19YYXOqc1s1JmZta5yvRqe00UvgccMWhhMzOzPpS51fbhhs0tgAOAF5tWIzMz62hlerU1zsuzHvg1xe02MzOzISvzjMfz8piZ2bAZaOrrswc4LiLi3CbUx8zMOtxAVzzP9xEbQzFvzk6AE4+ZmQ3ZQFNfX1Bfl7QdcAZwMnA5cEF/x5mZmQ1kwGc8knakmDH0YxSTtu0XEc9UUTEzM+tMAz3j+WfgwxTz2OwTEb39lTUzMytroBdIzwTeBvwD8N+S1uXynKR11VTPzMw6zUDPeIY0qoGZmVkZTi5mZlappiUeSbtIulHSfZKWSzoj4ztKWiJpZX6Oy7gkzZXUI+keSfs1nGtmll8paWZDfH9Jy/KYuTmIqZmZjWDNvOJZD5wZEXtRjGZ9uqS9gNnA0oiYCizNbYAjKaa1ngrMAi6E13rWzQEOophAbk49WWWZUxuO625ie8zMbBg0LfFExGMRcWeuPwfcD0yiGOdtYRZbCByT6zOAS3IE7JuBsZJ2phgJe0lErMmu3EuA7ty3fUTcHBEBXNJwLjMzG6HKDBK6ySTtRjEN9i3AxIh4LHc9DkzM9UnAow2HrcrYQPFVfcT7+v5ZFFdRjB8/gbP3Wb/xjRnBJo6GMzu0bQC9vb3UarVWV6Np3L721untG05NTzyS3gp8F/hURKxrfAwTESEp+j14mETEPIr3kdh19z3igmWV5NvKnbnPejq1bQALusfQ1dXV6mo0Ta1Wc/vaWKe3bzg1tVebpK0oks6lEXF1hp/I22Tk55MZXw3s0nD45IwNFJ/cR9zMzEawZvZqE3AxcH9EfKVh1yKg3jNtJnBtQ/zE7N02DVibt+QWA9MljctOBdOBxblvnaRp+V0nNpzLzMxGqGbelzkE+DiwTNLdGft74MvAlZJOAR4Bjst91wNHAT3ACxQDkhIRaySdC9yW5c6JiDW5fhqwABgN3JCLmZmNYE1LPBHxM6C/92oO76N8AKf3c675wPw+4rcDe29CNc3MrGIeucDMzCrlxGNmZpVy4jEzs0p17ksf1nGWrV7LSbOva3U1mmZB95hWV8GsEr7iMTOzSjnxmJlZpZx4zMysUk48ZmZWKSceMzOrlBOPmZlVyonHzMwq5cRjZmaVcuIxM7NKOfGYmVmlnHjMzKxSzZyBdL6kJyXd2xDbUdISSSvzc1zGJWmupB5J90jar+GYmVl+paSZDfH9JS3LY+bmLKRmZjbCNfOKZwHQvUFsNrA0IqYCS3Mb4Ehgai6zgAuhSFTAHOAg4EBgTj1ZZZlTG47b8LvMzGwEalriiYj/AtZsEJ4BLMz1hcAxDfFLonAzMFbSzsARwJKIWBMRzwBLgO7ct31E3Jwzl17ScC4zMxvBqn7GMzEiHsv1x4GJuT4JeLSh3KqMDRRf1UfczMxGuJbNxxMRISmq+C5Jsyhu4TF+/ATO3md9FV9buYmj4cwObRt0fvt6e3up1WqtrkbTuH1WV3XieULSzhHxWN4uezLjq4FdGspNzthqoGuDeC3jk/so36eImAfMA9h19z3igmWdOf/dmfusp1PbBp3fvgXdY+jq6mp1NZqmVqu5fQZUf6ttEVDvmTYTuLYhfmL2bpsGrM1bcouB6ZLGZaeC6cDi3LdO0rTszXZiw7nMzGwEa9r/Pkq6jOJqZbykVRS9074MXCnpFOAR4Lgsfj1wFNADvACcDBARaySdC9yW5c6JiHqHhdMoes6NBm7IxaxteWpv21w0LfFExAn97Dq8j7IBnN7PeeYD8/uI3w7svSl1NDOz6nnkAjMzq5QTj5mZVcqJx8zMKuXEY2ZmlXLiMTOzSjnxmJlZpTr3NXAzG1H8npLV+YrHzMwq5cRjZmaVcuIxM7NK+RmPmdkw6PRnWMPJVzxmZlYpJx4zM6uUE4+ZmVXKicfMzCrlxGNmZpVq+8QjqVvSCkk9kma3uj5mZjawtk48kkYBXweOBPYCTpC0V2trZWZmA2nrxAMcCPRExEMR8TvgcmBGi+tkZmYDUES0ug4bTdKxQHdE/EVufxw4KCI+sUG5WcCs3NwbuLfSilZnPPA/ra5EE7l97c3ta197RsR2w3WyzWLkgoiYB8wDkHR7RBzQ4io1RSe3Ddy+duf2tS9Jtw/n+dr9VttqYJeG7ckZMzOzEardE89twFRJUyRtDRwPLGpxnczMbABtfastItZL+gSwGBgFzI+I5YMcNq/5NWuZTm4buH3tzu1rX8PatrbuXGBmZu2n3W+1mZlZm3HiMTOzSm02iacThtaRtIukGyXdJ2m5pDMyvqOkJZJW5ue4jEvS3GzzPZL2a20LBidplKS7JP0gt6dIuiXbcEV2IkHSNrndk/t3a2W9y5A0VtJVkh6QdL+kgzvst/ub/PfyXkmXSdq2nX8/SfMlPSnp3obYkH8vSTOz/EpJM1vRlr70075/zn8/75F0jaSxDfvOyvatkHREQ3zof1sjouMXio4HDwK7A1sDvwT2anW9NqIdOwP75fp2wK8ohgr6J2B2xmcD5+f6UcANgIBpwC2tbkOJNn4a+A7wg9y+Ejg+178B/FWunwZ8I9ePB65odd1LtG0h8Be5vjUwtlN+O2AS8DAwuuF3O6mdfz/gfcB+wL0NsSH9XsCOwEP5OS7Xx7W6bQO0bzqwZa6f39C+vfLv5jbAlPx7Ompj/7a2vPEV/QM+GFjcsH0WcFar6zUM7boW+CCwAtg5YzsDK3L9IuCEhvKvlRuJC8V7WEuBw4Af5H/E/9PwH8JrvyNFT8aDc33LLKdWt2GAtu2Qf5i1QbxTfrtJwKP5B3bL/P2OaPffD9htgz/MQ/q9gBOAixribyjX6mXD9m2w78+AS3P9DX8z67/fxv5t3VxutdX/o6hblbG2lbcm3g3cAkyMiMdy1+PAxFxvt3b/K/B3wKu5vRPwbESsz+3G+r/Wtty/NsuPVFOAp4Bv5a3Eb0oaQ4f8dhGxGvgX4DfAYxS/xx10zu9XN9Tfq61+xw38H4qrOBjm9m0uiaejSHor8F3gUxGxrnFfFP/b0XZ95CV9CHgyIu5odV2aZEuK2xoXRsS7gecpbtW8pl1/O4B81jGDIsG+DRgDdLe0Uk3Wzr/XYCR9FlgPXNqM828uiadjhtaRtBVF0rk0Iq7O8BOSds79OwNPZryd2n0IcLSkX1OMMn4Y8DVgrKT6i86N9X+tbbl/B+DpKis8RKuAVRFxS25fRZGIOuG3A/gA8HBEPBURLwNXU/ymnfL71Q3192q33xFJJwEfAj6WyRWGuX2bS+LpiKF1JAm4GLg/Ir7SsGsRUO8tM5Pi2U89fmL2uJkGrG24TTCiRMRZETE5Inaj+H1+EhEfA24Ejs1iG7at3uZjs/yI/b/PiHgceFTSnhk6HLiPDvjt0m+AaZLekv+e1tvXEb9fg6H+XouB6ZLG5VXh9IyNSJK6KW53Hx0RLzTsWgQcn70RpwBTgVvZ2L+trX64VeFDtKMoeoE9CHy21fXZyDYcSnFpfw9wdy5HUdwbX5EkSr8AAAR9SURBVAqsBH4M7JjlRTFR3oPAMuCAVrehZDu7eL1X2+75L3gP8J/ANhnfNrd7cv/ura53iXbtC9yev9/3KHo5dcxvB3wBeIBi2pFvU/SAatvfD7iM4nnVyxRXrKdszO9F8aykJ5eTW92uQdrXQ/HMpv735RsN5T+b7VsBHNkQH/LfVg+ZY2ZmldpcbrWZmdkI4cRjZmaVcuIxM7NKOfGYmVmlnHjMzKxSTjzW9iT1Nvn8J0l6W8P2ryWN34TzXZaj//7N8NSwepL2lXRUq+th7amtp742q8hJFO+m/PemnkjS/wLeExF7bOq5Wmxf4ADg+lZXxNqPr3isI0maIOm7km7L5ZCMfz7nIalJekjSXzcc87mcV+RneVXyt5KOpfgDe6mkuyWNzuKflHSnpGWS3tHH928r6Vu5/y5J789dPwIm5bneu8ExE3MOlF/m8kcZ/7SKOW7ulfSpjO2W86YskPQrSZdK+oCkn+e8Lwc2tHehpJ9KekTShyX9U9brhzkEE5L2l3STpDskLW4YFqYm6XxJt+b3vDffUD8H+Gi246OS/jjX7872bjdsP6Z1nla/PevFy6YuQG8fse8Ah+b6rhTDDAF8HvgFxVv14ynGB9sKeA/Fm9rbUsx1tBL42zymxhvfRP818MlcPw34Zh/ffyYwP9ffQTGkzLYMPAz9FRQDv0Ixz8kOwP4Ub8KPAd4KLKcYlXw3ikEc96H4H8g7gPkUb9DPAL7X0N6fZRvfBbxAvnUOXAMck/t+AUzI+Ecb6l4DLsj1o4Af5/pJwL831P37wCG5/lZyKgQvXvpafKvNOtUHgL2KYcMA2F7FqN4A10XES8BLkp6kGNr+EODaiHgReFHS9wc5f32A1juAD/ex/1Dg3wAi4gFJjwB/AKzro2zdYcCJecwrwFpJhwLXRMTzAJKuBt5LMR7WwxGxLOPLgaUREZKWUSSmuhsi4uWMjwJ+mPF6uT2BvYEl+c9rFMVQKn21tfG8jX4OfEXSpcDVEbFqgHbaZs6JxzrVFsC0TCSvyT+sLzWEXmHj/juon2Njjx8Oje14tWH7Vd5Yp5cAIuJVSS9HRGxQTsDyiDh4kO/pt60R8WVJ11FcFf1c0hER8cBQG2SbBz/jsU71I+CT9Q1J+w5S/ufAn+azmbdSDAtf9xzF7beh+CnwsfzuP6C43bdikGOWAn+Vx4yStEOe55gc9XkMxayQPx1iXQazApgg6eD87q0kvXOQY97wz0TS2yNiWUScTzFi8Zuee5nVOfFYJ3iLpFUNy6eBvwYOyG7L9wH/d6ATRMRtFLev7qGYdXEZxayYAAuAb2zQuWAw/wFskbe3rgBOytt7AzkDeH8ecwfF3PV35vffSjHb7Dcj4q6SdSglIn5HMTXB+ZJ+SfGs648GOexGiluZd0v6KPCp7PxwD8VoxzcMfLhtzjw6tVmS9NaI6JX0FuC/gFn5h9/MhpGf8Zi9bp6kvSh6ny100jFrDl/xmJlZpfyMx8zMKuXEY2ZmlXLiMTOzSjnxmJlZpZx4zMysUv8faVzRzLzzA9cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [len(comment[i]) for i in range(comment.shape[0])]\n",
    "\n",
    "print('average length of comment: {:.3f}'.format(sum(x)/len(x)) )\n",
    "bins = [1,200,400,600,800,1000,1200]\n",
    "plt.hist(x, bins=bins)\n",
    "plt.xlabel('Length of comments')\n",
    "plt.ylabel('Number of comments')       \n",
    "plt.axis([0, 1200, 0, 90000])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of comments classified as toxic,severe_toxic,....etc depending on their lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = np.zeros(label.shape)\n",
    "for ix in range(comment.shape[0]):\n",
    "    l = len(comment[ix])\n",
    "    if label[ix][0] :\n",
    "        y[ix][0] = l\n",
    "    if label[ix][1] :\n",
    "        y[ix][1] = l\n",
    "    if label[ix][2] :\n",
    "        y[ix][2] = l\n",
    "    if label[ix][3] :\n",
    "        y[ix][3] = l\n",
    "    if label[ix][4] :\n",
    "        y[ix][4] = l\n",
    "    if label[ix][5] :\n",
    "        y[ix][5] = l\n",
    "\n",
    "labelsplt = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
    "color = ['orange','brown','purple','yellow','teal','chartreuse']        \n",
    "plt.hist(y,bins = bins,label = labelsplt,color = color)\n",
    "plt.axis([0, 1200, 0, 8000])\n",
    "plt.xlabel('Length of comments')\n",
    "plt.ylabel('Number of comments') \n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove excessive length comments\n",
    "Some very large length comments can be seen, in our dataset. These pose serious problems like adding excessively more words to the training dataset, causing training time to increase and accuracy to decrease!<br/>\n",
    "Hence, a threshold of 400 characters will be created and only comments which have length smaller than 400 will be used further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = []\n",
    "labels = []\n",
    "\n",
    "for ix in range(comment.shape[0]):\n",
    "    if len(comment[ix])<=400:\n",
    "        comments.append(comment[ix])\n",
    "        labels.append(label[ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115910\n"
     ]
    }
   ],
   "source": [
    "print(len(comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, after removing comments longer than 400 characters, we are still left with more than 69000 comments, which seems enough for training purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing \n",
    "Preprocessing involved the following steps, but these will be performed in a slightly different manner:\n",
    "- Removing Punctuations and other special characters\n",
    "- Splitting the comments into individual words\n",
    "- Removing Stop Words\n",
    "- Stemming and Lemmatising\n",
    "- Applying Count Vectoriser\n",
    "- Splitting dataset into Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing a string containing all punctuations to be removed\n",
    "The string library contains punctuation characters. This is imported and all numbers are appended to this string. Also, we can notice that our comment_text field contains strings such as won't, didn't, etc which contain apostrophe character('). To prevent these words from being converted to wont/didnt, the character ' represented as \\' in escape sequence notation is replaced by empty character in the punctuation string. <br/>\n",
    "\n",
    "**maketrans()** returns a translation table that maps each character in the punctuation_edit into the character at the same position in the outtab string i.e. it replaces every character in the removal list with a space, since outtab contains a string with spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~0123456789\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "print(string.punctuation)\n",
    "punctuation_edit = string.punctuation.replace('\\'','') +\"0123456789\"\n",
    "print (punctuation_edit)\n",
    "outtab = \"                                         \"\n",
    "trantab = str.maketrans(punctuation_edit, outtab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating the list of stop words\n",
    "**Stop words** are those words that are frequently used in both written and verbal communication and thereby do not have either a positive/negative impact on our statement.E.g. is, this, us,etc. <br/>\n",
    "Single letter words if existing or created due to any preprocessing step do not convey any useful meaning and hence can be directly removed. Hence letters from b to z, will be added to the list of stop words imported directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stop_words import get_stop_words\n",
    "stop_words = get_stop_words('english')\n",
    "stop_words.append('')\n",
    "\n",
    "for x in range(ord('b'), ord('z')+1):\n",
    "    stop_words.append(chr(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'after', 'again', 'against', 'all', 'am', 'an', 'and', 'any', 'are', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', \"can't\", 'cannot', 'could', \"couldn't\", 'did', \"didn't\", 'do', 'does', \"doesn't\", 'doing', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', \"hadn't\", 'has', \"hasn't\", 'have', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", \"he's\", 'her', 'here', \"here's\", 'hers', 'herself', 'him', 'himself', 'his', 'how', \"how's\", 'i', \"i'd\", \"i'll\", \"i'm\", \"i've\", 'if', 'in', 'into', 'is', \"isn't\", 'it', \"it's\", 'its', 'itself', \"let's\", 'me', 'more', 'most', \"mustn't\", 'my', 'myself', 'no', 'nor', 'not', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'ought', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 'same', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', \"shouldn't\", 'so', 'some', 'such', 'than', 'that', \"that's\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', \"there's\", 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 'very', 'was', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", \"we've\", 'were', \"weren't\", 'what', \"what's\", 'when', \"when's\", 'where', \"where's\", 'which', 'while', 'who', \"who's\", 'whom', 'why', \"why's\", 'with', \"won't\", 'would', \"wouldn't\", 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves', '', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "print (stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming and Lemmatizing\n",
    "**Stemming** is the process of converting inflected/derived words to their word stem or the root form. Basically, a large number of similar origin words are converted to the same word.E.g. words like \"stems\", \"stemmer\", \"stemming\", \"stemmed\" as based on \"stem\". This helps in achieving the training process with a better accuracy.<br/>\n",
    "**Lemmatizing** is the process of grouping together the inflected forms of a word so they can be analysed as a single item. This is quite similar to stemming in its working but differs since it depends on correctly identifying the intended part of speech and meaning of a word in a sentence, as well as within the larger context surrounding that sentence, such as neighboring sentences or even an entire document.<br/>\n",
    "The **wordnet library in nltk** will be used for this purpose. Stemmer and Lemmatizer are also imported from nltk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/tejasmehta/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create objects for stemmer and lemmatizer\n",
    "lemmatiser = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "#download words from wordnet library\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can now, loop once through all the comments applying :\n",
    "- punctuation removal\n",
    "- splitting the words by space\n",
    "- applying stemmer and lemmatizer\n",
    "- recombining the words again for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(comments)):\n",
    "    comments[i] = comments[i].lower().translate(trantab)\n",
    "    l = []\n",
    "    for word in comments[i].split():\n",
    "        l.append(stemmer.stem(lemmatiser.lemmatize(word,pos=\"v\")))\n",
    "    comments[i] = \" \".join(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Count Vectorizer\n",
    "Here we can finally convert our comments into a matrix of token counts, which signifies the number of times it occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aren', 'can', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'let', 'll', 'mustn', 're', 'shan', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "#import required library\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#create object supplying our custom stop words\n",
    "count_vector = CountVectorizer(stop_words=stop_words)\n",
    "#fitting it to converts comments into bag of words format\n",
    "tf = count_vector.fit_transform(comments).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(115910, 72310)\n"
     ]
    }
   ],
   "source": [
    "# print(count_vector.get_feature_names())\n",
    "print(tf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence from its shape we can imply that after all preprocessing we have a list of 52905 words in total.\n",
    "## Splitting dataset into training and testing\n",
    "- Since the system was going out of memory using train_test_split, I had jumbled all the indexes in the beginning itself. \n",
    "- The shuffle function defined here performs the task of assigning first 2/3rd values to train and remaining 1/3rd values to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38636, 72310)\n",
      "(77274, 72310)\n"
     ]
    }
   ],
   "source": [
    "def shuffle(matrix, target, test_proportion):\n",
    "    ratio = int(matrix.shape[0]/test_proportion)\n",
    "    X_train = matrix[ratio:,:]\n",
    "    X_test =  matrix[:ratio,:]\n",
    "    Y_train = target[ratio:,:]\n",
    "    Y_test =  target[:ratio,:]\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = shuffle(tf, labels,3)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation :\n",
    "### Let us define all the evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "def evaluate_score(Y_test,predict): \n",
    "    loss = hamming_loss(Y_test,predict)\n",
    "    print(\"Hamming_loss : {}\".format(loss*100))\n",
    "    accuracy = accuracy_score(Y_test,predict)\n",
    "    print(\"Accuracy : {}\".format(accuracy*100))\n",
    "    try : \n",
    "        loss = log_loss(Y_test,predict)\n",
    "    except :\n",
    "        loss = log_loss(Y_test,predict.toarray())\n",
    "    print(\"Log_loss : {}\".format(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting with the First Model -\n",
    "### Problem Transformation Methods :\n",
    "**These include the Binary Relevance, Label Powerset and Classifier Chain methods. Implementations of these methods is available in the scikit-multilearn library. **\n",
    "- I will be implementing the most basic method,which is the **Binary Relevance** method from scratch. It does not take into account the interdependence of labels and basically creates a separate classifier for each of the labels.\n",
    "- Scikit-multilearn library's classifier will also be imported and tested with different classifiers to observe if it gives similar results.\n",
    "\n",
    "### 1. Binary Relevance (BR) Method with MultinomialNB classifiers (from scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf will be the list of the classifiers for all the 6 labels\n",
    "# each classifier is fit with the training data and corresponding classifier\n",
    "clf = []\n",
    "for ix in range(6):\n",
    "    clf.append(MultinomialNB())\n",
    "    clf[ix].fit(X_train,Y_train[:,ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38636, 6)\n"
     ]
    }
   ],
   "source": [
    "# predict list contains the predictions, it is transposed later to get the proper shape\n",
    "predict = []\n",
    "for ix in range(6):\n",
    "    predict.append(clf[ix].predict(X_test))\n",
    "\n",
    "predict = np.asarray(np.transpose(predict))\n",
    "print(predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming_loss : 3.1154018704489768\n",
      "Accuracy : 88.54177451081893\n",
      "Log_loss : 1.8998639376584106\n"
     ]
    }
   ],
   "source": [
    "# calculate results\n",
    "evaluate_score(Y_test,predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. BR Method with SVM classifier (from scikit-multilearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BinaryRelevance(classifier=SVC(C=1.0, cache_size=200, class_weight=None,\n",
       "                               coef0=0.0, decision_function_shape='ovr',\n",
       "                               degree=3, gamma='auto_deprecated', kernel='rbf',\n",
       "                               max_iter=-1, probability=False,\n",
       "                               random_state=None, shrinking=True, tol=0.001,\n",
       "                               verbose=False),\n",
       "                require_dense=[False, True])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create and fit classifier\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.svm import SVC\n",
    "classifier = BinaryRelevance(classifier = SVC(), require_dense = [False, True])\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming_loss : 4.292197259895779\n",
      "Accuracy : 88.38906719122063\n",
      "Log_loss : 0.4614351050527784\n"
     ]
    }
   ],
   "source": [
    "#calculate scores\n",
    "evaluate_score(Y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. BR Method with Multinomial classifier (from scikit-multilearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryRelevance(classifier=MultinomialNB(alpha=1.0, class_prior=None,\n",
       "                                         fit_prior=True),\n",
       "                require_dense=[False, True])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create and fit classifier\n",
    "classifier = BinaryRelevance(classifier = MultinomialNB(), require_dense = [False, True])\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming_loss : 3.1154018704489768\n",
      "Accuracy : 88.54177451081893\n",
      "Log_loss : 1.8998639376584106\n"
     ]
    }
   ],
   "source": [
    "#calculate scores\n",
    "evaluate_score(Y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. BR Method with GausseanNB classifier (from scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "#create and fit classifiers\n",
    "clf = []\n",
    "for ix in range(6):\n",
    "    clf.append(GaussianNB())\n",
    "    clf[ix].fit(X_train,Y_train[:,ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "predict = []\n",
    "for ix in range(6):\n",
    "    predict.append(clf[ix].predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate scores\n",
    "predict = np.asarray(np.transpose(predict))\n",
    "evaluate_score(Y_test,predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Classifier chain with MultinomialNB classifier (from scikit-multilearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassifierChain(classifier=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "        require_dense=[True, True])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create and fit classifier\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "classifier = ClassifierChain(MultinomialNB())\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predictions\n",
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming_loss : 3.5647090927370133\n",
      "Accuracy : 88.25886509543712\n",
      "Log_loss : 1.506849253150214\n"
     ]
    }
   ],
   "source": [
    "#calculate scores\n",
    "evaluate_score(Y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Label Powerset with MultinomialNB classifier (from scikit-multilearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelPowerset(classifier=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "       require_dense=[True, True])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create and fit classifier\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "classifier = LabelPowerset(MultinomialNB())\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predictions\n",
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming_loss : 3.1726198170250046\n",
      "Accuracy : 88.80606661209013\n",
      "Log_loss : 1.4765486777963348\n"
     ]
    }
   ],
   "source": [
    "#calculate scores\n",
    "evaluate_score(Y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptation Algorithms\n",
    "### 7. MLkNN  with k=2 (from scikit-multilearn)\n",
    "This is the adapted multi-label version of K Nearest Neighbours. Its implementation is available in the multilearn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create and fit classifier\n",
    "from skmultilearn.adapt import MLkNN\n",
    "classifier = MLkNN(k=2)\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predictions\n",
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate scores\n",
    "evaluate_score(Y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. BP-MLL Neural Networks (from scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 4)                 211956    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 30        \n",
      "=================================================================\n",
      "Total params: 211,986\n",
      "Trainable params: 211,986\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#define model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(4, activation='relu', input_dim = X_train.shape[1]))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#compile model with all parameters set\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "46418/46418 [==============================] - 60s 1ms/step - loss: 0.3684 - acc: 0.9419\n",
      "Epoch 2/10\n",
      "46418/46418 [==============================] - 60s 1ms/step - loss: 0.3489 - acc: 0.9901\n",
      "Epoch 3/10\n",
      "46418/46418 [==============================] - 62s 1ms/step - loss: 0.3449 - acc: 0.9906\n",
      "Epoch 4/10\n",
      "46418/46418 [==============================] - 59s 1ms/step - loss: 0.3425 - acc: 0.9888: 0s - loss: 0.3424 - acc: 0.98\n",
      "Epoch 5/10\n",
      "46418/46418 [==============================] - 59s 1ms/step - loss: 0.3424 - acc: 0.9876\n",
      "Epoch 6/10\n",
      "46418/46418 [==============================] - 58s 1ms/step - loss: 0.3424 - acc: 0.9879\n",
      "Epoch 7/10\n",
      "46418/46418 [==============================] - 57s 1ms/step - loss: 0.3414 - acc: 0.9868\n",
      "Epoch 8/10\n",
      "46418/46418 [==============================] - 60s 1ms/step - loss: 0.3404 - acc: 0.9851\n",
      "Epoch 9/10\n",
      "46418/46418 [==============================] - 61s 1ms/step - loss: 0.3402 - acc: 0.9846\n",
      "Epoch 10/10\n",
      "46418/46418 [==============================] - 61s 1ms/step - loss: 0.3395 - acc: 0.9825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x210b649470>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit using check pointer\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.myneural.h5py', \n",
    "                               verbose=1, save_best_only=True)\n",
    "model.fit(X_train, Y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predictions\n",
    "predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6.69890046e-01   9.70017936e-05   1.44642159e-01   1.16227047e-05\n",
      "   1.78119496e-01   7.23966770e-03]\n"
     ]
    }
   ],
   "source": [
    "print(predict[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Since the results returned by the model are in the form of probabilities, they have to be explicitly converted to either 0/1 using the round function. This is because the hamming_loss and accuracy_score cannot work on these values directly. However, log loss can compute loss directly without modifying the values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log_loss : 0.36017768848519677\n",
      "Hamming_loss : 13.960101684691285\n",
      "Accuracy : 29.52302985910638\n"
     ]
    }
   ],
   "source": [
    "#calculate score\n",
    "loss = log_loss(Y_test,predict)\n",
    "print(\"Log_loss : {}\".format(loss))\n",
    "predict = np.round(predict)\n",
    "loss = hamming_loss(Y_test,predict)\n",
    "print(\"Hamming_loss : {}\".format(loss*100))\n",
    "accuracy = accuracy_score(Y_test,predict)\n",
    "print(\"Accuracy : {}\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Let us try improving the BP-MLL model (Refining)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras import optimizers\n",
    "\n",
    "#define parameters for using in param grid\n",
    "nodes = [16, 32, 64] # number of nodes in the hidden layer\n",
    "lrs = [0.001, 0.002, 0.003] # learning rate, default = 0.001\n",
    "epochs = [10,20,30]\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(nodes=10,lr=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(nodes, activation='relu', input_dim = X_train.shape[1]))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(6, activation='softmax'))\n",
    "    opt = optimizers.RMSprop(lr=lr)\n",
    "    model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "[CV] epochs=10, lr=0.001, nodes=16 ...................................\n",
      "Epoch 1/10\n",
      "30945/30945 [==============================] - 39s 1ms/step - loss: 0.3682 - acc: 0.9536\n",
      "Epoch 2/10\n",
      "30945/30945 [==============================] - 27s 878us/step - loss: 0.3440 - acc: 0.9794\n",
      "Epoch 3/10\n",
      "30945/30945 [==============================] - 25s 820us/step - loss: 0.3379 - acc: 0.9786\n",
      "Epoch 4/10\n",
      "30945/30945 [==============================] - 26s 837us/step - loss: 0.3324 - acc: 0.9745\n",
      "Epoch 5/10\n",
      "30945/30945 [==============================] - 26s 832us/step - loss: 0.3280 - acc: 0.9718\n",
      "Epoch 6/10\n",
      "30945/30945 [==============================] - 26s 842us/step - loss: 0.3249 - acc: 0.9688\n",
      "Epoch 7/10\n",
      "30945/30945 [==============================] - 27s 878us/step - loss: 0.3227 - acc: 0.9654\n",
      "Epoch 8/10\n",
      "30945/30945 [==============================] - 26s 838us/step - loss: 0.3202 - acc: 0.9647\n",
      "Epoch 9/10\n",
      "30945/30945 [==============================] - 26s 843us/step - loss: 0.3190 - acc: 0.9596\n",
      "Epoch 10/10\n",
      "30945/30945 [==============================] - 27s 858us/step - loss: 0.3157 - acc: 0.9602\n",
      "15473/15473 [==============================] - 14s 882us/step\n",
      "30945/30945 [==============================] - 25s 812us/step\n",
      "[CV] .................... epochs=10, lr=0.001, nodes=16, total= 5.5min\n",
      "[CV] epochs=10, lr=0.001, nodes=16 ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  5.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.3783 - acc: 0.9584\n",
      "Epoch 2/10\n",
      "30945/30945 [==============================] - 22s 715us/step - loss: 0.3515 - acc: 0.9802\n",
      "Epoch 3/10\n",
      "30945/30945 [==============================] - 22s 706us/step - loss: 0.3447 - acc: 0.9793\n",
      "Epoch 4/10\n",
      "30945/30945 [==============================] - 23s 731us/step - loss: 0.3407 - acc: 0.9788\n",
      "Epoch 5/10\n",
      "30945/30945 [==============================] - 23s 733us/step - loss: 0.3373 - acc: 0.9770\n",
      "Epoch 6/10\n",
      "30945/30945 [==============================] - 22s 726us/step - loss: 0.3342 - acc: 0.9748\n",
      "Epoch 7/10\n",
      "30945/30945 [==============================] - 22s 713us/step - loss: 0.3312 - acc: 0.9697\n",
      "Epoch 8/10\n",
      "30945/30945 [==============================] - 22s 695us/step - loss: 0.3303 - acc: 0.9648\n",
      "Epoch 9/10\n",
      "30945/30945 [==============================] - 22s 702us/step - loss: 0.3280 - acc: 0.9621\n",
      "Epoch 10/10\n",
      "30945/30945 [==============================] - 22s 712us/step - loss: 0.3268 - acc: 0.9588\n",
      "15473/15473 [==============================] - 11s 720us/step\n",
      "30945/30945 [==============================] - 20s 657us/step\n",
      "[CV] .................... epochs=10, lr=0.001, nodes=16, total= 4.6min\n",
      "[CV] epochs=10, lr=0.001, nodes=16 ...................................\n",
      "Epoch 1/10\n",
      "30946/30946 [==============================] - 35s 1ms/step - loss: 0.3705 - acc: 0.8698\n",
      "Epoch 2/10\n",
      "30946/30946 [==============================] - 22s 718us/step - loss: 0.3464 - acc: 0.9863\n",
      "Epoch 3/10\n",
      "30946/30946 [==============================] - 22s 703us/step - loss: 0.3407 - acc: 0.9855\n",
      "Epoch 4/10\n",
      "30946/30946 [==============================] - 22s 707us/step - loss: 0.3358 - acc: 0.9822\n",
      "Epoch 5/10\n",
      "30946/30946 [==============================] - 21s 680us/step - loss: 0.3315 - acc: 0.9808\n",
      "Epoch 6/10\n",
      "30946/30946 [==============================] - 21s 684us/step - loss: 0.3276 - acc: 0.9772\n",
      "Epoch 7/10\n",
      "30946/30946 [==============================] - 21s 678us/step - loss: 0.3268 - acc: 0.9731\n",
      "Epoch 8/10\n",
      "30946/30946 [==============================] - 23s 742us/step - loss: 0.3239 - acc: 0.9692\n",
      "Epoch 9/10\n",
      "30946/30946 [==============================] - 22s 720us/step - loss: 0.3239 - acc: 0.9666\n",
      "Epoch 10/10\n",
      "30946/30946 [==============================] - 23s 735us/step - loss: 0.3200 - acc: 0.9641\n",
      "15472/15472 [==============================] - 11s 726us/step\n",
      "30946/30946 [==============================] - 20s 648us/step\n",
      "[CV] .................... epochs=10, lr=0.001, nodes=16, total= 4.6min\n",
      "[CV] epochs=10, lr=0.001, nodes=32 ...................................\n",
      "Epoch 1/10\n",
      "30945/30945 [==============================] - 50s 2ms/step - loss: 0.3620 - acc: 0.9808\n",
      "Epoch 2/10\n",
      "30945/30945 [==============================] - 38s 1ms/step - loss: 0.3390 - acc: 0.9796\n",
      "Epoch 3/10\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.3307 - acc: 0.9748\n",
      "Epoch 4/10\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3259 - acc: 0.9741\n",
      "Epoch 5/10\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.3214 - acc: 0.9715\n",
      "Epoch 6/10\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.3169 - acc: 0.9686\n",
      "Epoch 7/10\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3139 - acc: 0.9637\n",
      "Epoch 8/10\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.3112 - acc: 0.9610\n",
      "Epoch 9/10\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.3077 - acc: 0.9581\n",
      "Epoch 10/10\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.3059 - acc: 0.9556\n",
      "15473/15473 [==============================] - 14s 918us/step\n",
      "30945/30945 [==============================] - 26s 836us/step\n",
      "[CV] .................... epochs=10, lr=0.001, nodes=32, total= 7.1min\n",
      "[CV] epochs=10, lr=0.001, nodes=32 ...................................\n",
      "Epoch 1/10\n",
      "30945/30945 [==============================] - 48s 2ms/step - loss: 0.3743 - acc: 0.9775\n",
      "Epoch 2/10\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.3518 - acc: 0.9829\n",
      "Epoch 3/10\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.3443 - acc: 0.9796\n",
      "Epoch 4/10\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.3386 - acc: 0.9766\n",
      "Epoch 5/10\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.3343 - acc: 0.9740\n",
      "Epoch 6/10\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.3309 - acc: 0.9720\n",
      "Epoch 7/10\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.3280 - acc: 0.9694\n",
      "Epoch 8/10\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.3261 - acc: 0.9677\n",
      "Epoch 9/10\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.3237 - acc: 0.9626\n",
      "Epoch 10/10\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.3212 - acc: 0.9587\n",
      "15473/15473 [==============================] - 14s 932us/step\n",
      "30945/30945 [==============================] - 27s 861us/step\n",
      "[CV] .................... epochs=10, lr=0.001, nodes=32, total= 7.2min\n",
      "[CV] epochs=10, lr=0.001, nodes=32 ...................................\n",
      "Epoch 1/10\n",
      "30946/30946 [==============================] - 44s 1ms/step - loss: 0.3608 - acc: 0.9766\n",
      "Epoch 2/10\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3390 - acc: 0.9807\n",
      "Epoch 3/10\n",
      "30946/30946 [==============================] - 35s 1ms/step - loss: 0.3311 - acc: 0.9780\n",
      "Epoch 4/10\n",
      "30946/30946 [==============================] - 34s 1ms/step - loss: 0.3269 - acc: 0.9726\n",
      "Epoch 5/10\n",
      "30946/30946 [==============================] - 38s 1ms/step - loss: 0.3224 - acc: 0.9702\n",
      "Epoch 6/10\n",
      "30946/30946 [==============================] - 38s 1ms/step - loss: 0.3198 - acc: 0.9676\n",
      "Epoch 7/10\n",
      "30946/30946 [==============================] - 38s 1ms/step - loss: 0.3156 - acc: 0.9659\n",
      "Epoch 8/10\n",
      "30946/30946 [==============================] - 38s 1ms/step - loss: 0.3120 - acc: 0.9646\n",
      "Epoch 9/10\n",
      "30946/30946 [==============================] - 38s 1ms/step - loss: 0.3094 - acc: 0.9592\n",
      "Epoch 10/10\n",
      "30946/30946 [==============================] - 38s 1ms/step - loss: 0.3088 - acc: 0.9571\n",
      "15472/15472 [==============================] - 14s 935us/step\n",
      "30946/30946 [==============================] - 26s 855us/step\n",
      "[CV] .................... epochs=10, lr=0.001, nodes=32, total= 7.1min\n",
      "[CV] epochs=10, lr=0.001, nodes=64 ...................................\n",
      "Epoch 1/10\n",
      "30945/30945 [==============================] - 73s 2ms/step - loss: 0.3561 - acc: 0.9807\n",
      "Epoch 2/10\n",
      "30945/30945 [==============================] - 61s 2ms/step - loss: 0.3341 - acc: 0.9778\n",
      "Epoch 3/10\n",
      "30945/30945 [==============================] - 61s 2ms/step - loss: 0.3249 - acc: 0.9749\n",
      "Epoch 4/10\n",
      "30945/30945 [==============================] - 61s 2ms/step - loss: 0.3188 - acc: 0.9719\n",
      "Epoch 5/10\n",
      "30945/30945 [==============================] - 59s 2ms/step - loss: 0.3143 - acc: 0.9656\n",
      "Epoch 6/10\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3086 - acc: 0.9597\n",
      "Epoch 7/10\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3055 - acc: 0.9588\n",
      "Epoch 8/10\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3015 - acc: 0.9559\n",
      "Epoch 9/10\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.2992 - acc: 0.9491\n",
      "Epoch 10/10\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.2956 - acc: 0.9456\n",
      "15473/15473 [==============================] - 14s 906us/step\n",
      "30945/30945 [==============================] - 24s 769us/step\n",
      "[CV] .................... epochs=10, lr=0.001, nodes=64, total=10.7min\n",
      "[CV] epochs=10, lr=0.001, nodes=64 ...................................\n",
      "Epoch 1/10\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.3643 - acc: 0.9838\n",
      "Epoch 2/10\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3427 - acc: 0.9774\n",
      "Epoch 3/10\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3337 - acc: 0.9737\n",
      "Epoch 4/10\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3264 - acc: 0.9703\n",
      "Epoch 5/10\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3204 - acc: 0.9655\n",
      "Epoch 6/10\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3175 - acc: 0.9599\n",
      "Epoch 7/10\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.3131 - acc: 0.9585\n",
      "Epoch 8/10\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.3099 - acc: 0.9515\n",
      "Epoch 9/10\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3073 - acc: 0.9495\n",
      "Epoch 10/10\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3056 - acc: 0.9434\n",
      "15473/15473 [==============================] - 13s 853us/step\n",
      "30945/30945 [==============================] - 24s 776us/step\n",
      "[CV] .................... epochs=10, lr=0.001, nodes=64, total= 9.8min\n",
      "[CV] epochs=10, lr=0.001, nodes=64 ...................................\n",
      "Epoch 1/10\n",
      "30946/30946 [==============================] - 62s 2ms/step - loss: 0.3546 - acc: 0.9802\n",
      "Epoch 2/10\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.3317 - acc: 0.9786\n",
      "Epoch 3/10\n",
      "30946/30946 [==============================] - 52s 2ms/step - loss: 0.3230 - acc: 0.9737\n",
      "Epoch 4/10\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.3166 - acc: 0.9714\n",
      "Epoch 5/10\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3120 - acc: 0.9684\n",
      "Epoch 6/10\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3084 - acc: 0.9609\n",
      "Epoch 7/10\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.3045 - acc: 0.9566\n",
      "Epoch 8/10\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.3018 - acc: 0.9511\n",
      "Epoch 9/10\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.2986 - acc: 0.9489\n",
      "Epoch 10/10\n",
      "30946/30946 [==============================] - 50s 2ms/step - loss: 0.2965 - acc: 0.9439\n",
      "15472/15472 [==============================] - 13s 848us/step\n",
      "30946/30946 [==============================] - 26s 830us/step\n",
      "[CV] .................... epochs=10, lr=0.001, nodes=64, total= 9.8min\n",
      "[CV] epochs=10, lr=0.002, nodes=16 ...................................\n",
      "Epoch 1/10\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3601 - acc: 0.9709\n",
      "Epoch 2/10\n",
      "30945/30945 [==============================] - 23s 742us/step - loss: 0.3402 - acc: 0.9831\n",
      "Epoch 3/10\n",
      "30945/30945 [==============================] - 23s 738us/step - loss: 0.3344 - acc: 0.9774\n",
      "Epoch 4/10\n",
      "30945/30945 [==============================] - 23s 745us/step - loss: 0.3306 - acc: 0.9756\n",
      "Epoch 5/10\n",
      "30945/30945 [==============================] - 23s 735us/step - loss: 0.3290 - acc: 0.9693\n",
      "Epoch 6/10\n",
      "30945/30945 [==============================] - 23s 731us/step - loss: 0.3258 - acc: 0.9688\n",
      "Epoch 7/10\n",
      "30945/30945 [==============================] - 22s 726us/step - loss: 0.3224 - acc: 0.9659\n",
      "Epoch 8/10\n",
      "30945/30945 [==============================] - 23s 731us/step - loss: 0.3201 - acc: 0.9626\n",
      "Epoch 9/10\n",
      "30945/30945 [==============================] - 22s 711us/step - loss: 0.3189 - acc: 0.9584\n",
      "Epoch 10/10\n",
      "30945/30945 [==============================] - 23s 738us/step - loss: 0.3169 - acc: 0.9568\n",
      "15473/15473 [==============================] - 12s 798us/step\n",
      "30945/30945 [==============================] - 22s 714us/step\n",
      "[CV] .................... epochs=10, lr=0.002, nodes=16, total= 4.7min\n",
      "[CV] epochs=10, lr=0.002, nodes=16 ...................................\n",
      "Epoch 1/10\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3694 - acc: 0.9723\n",
      "Epoch 2/10\n",
      "30945/30945 [==============================] - 22s 716us/step - loss: 0.3500 - acc: 0.9833\n",
      "Epoch 3/10\n",
      "30945/30945 [==============================] - 22s 712us/step - loss: 0.3439 - acc: 0.9797\n",
      "Epoch 4/10\n",
      "30945/30945 [==============================] - 22s 710us/step - loss: 0.3407 - acc: 0.9738\n",
      "Epoch 5/10\n",
      "30945/30945 [==============================] - 22s 710us/step - loss: 0.3354 - acc: 0.9691\n",
      "Epoch 6/10\n",
      "30945/30945 [==============================] - 22s 712us/step - loss: 0.3329 - acc: 0.9694\n",
      "Epoch 7/10\n",
      "30945/30945 [==============================] - 22s 712us/step - loss: 0.3292 - acc: 0.9608\n",
      "Epoch 8/10\n",
      "30945/30945 [==============================] - 22s 717us/step - loss: 0.3286 - acc: 0.9598\n",
      "Epoch 9/10\n",
      "30945/30945 [==============================] - 22s 716us/step - loss: 0.3275 - acc: 0.9554\n",
      "Epoch 10/10\n",
      "30945/30945 [==============================] - 22s 723us/step - loss: 0.3248 - acc: 0.9513\n",
      "15473/15473 [==============================] - 12s 796us/step\n",
      "30945/30945 [==============================] - 22s 721us/step\n",
      "[CV] .................... epochs=10, lr=0.002, nodes=16, total= 4.6min\n",
      "[CV] epochs=10, lr=0.002, nodes=16 ...................................\n",
      "Epoch 1/10\n",
      "30946/30946 [==============================] - 35s 1ms/step - loss: 0.3582 - acc: 0.9780\n",
      "Epoch 2/10\n",
      "30946/30946 [==============================] - 23s 739us/step - loss: 0.3391 - acc: 0.9829\n",
      "Epoch 3/10\n",
      "30946/30946 [==============================] - 22s 723us/step - loss: 0.3343 - acc: 0.9771\n",
      "Epoch 4/10\n",
      "30946/30946 [==============================] - 22s 720us/step - loss: 0.3311 - acc: 0.9725\n",
      "Epoch 5/10\n",
      "30946/30946 [==============================] - 22s 718us/step - loss: 0.3278 - acc: 0.9690\n",
      "Epoch 6/10\n",
      "30946/30946 [==============================] - 22s 719us/step - loss: 0.3245 - acc: 0.9660\n",
      "Epoch 7/10\n",
      "30946/30946 [==============================] - 22s 720us/step - loss: 0.3220 - acc: 0.9642\n",
      "Epoch 8/10\n",
      "30946/30946 [==============================] - 22s 722us/step - loss: 0.3193 - acc: 0.9606\n",
      "Epoch 9/10\n",
      "30946/30946 [==============================] - 22s 712us/step - loss: 0.3176 - acc: 0.9598\n",
      "Epoch 10/10\n",
      "30946/30946 [==============================] - 22s 722us/step - loss: 0.3147 - acc: 0.9576\n",
      "15472/15472 [==============================] - 12s 793us/step\n",
      "30946/30946 [==============================] - 22s 723us/step\n",
      "[CV] .................... epochs=10, lr=0.002, nodes=16, total= 4.7min\n",
      "[CV] epochs=10, lr=0.002, nodes=32 ...................................\n",
      "Epoch 1/10\n",
      "30945/30945 [==============================] - 48s 2ms/step - loss: 0.3539 - acc: 0.9795\n",
      "Epoch 2/10\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.3353 - acc: 0.9778\n",
      "Epoch 3/10\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.3276 - acc: 0.9752\n",
      "Epoch 4/10\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.3207 - acc: 0.9723\n",
      "Epoch 5/10\n",
      "30945/30945 [==============================] - 38s 1ms/step - loss: 0.3176 - acc: 0.9687\n",
      "Epoch 6/10\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.3130 - acc: 0.9643\n",
      "Epoch 7/10\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.3112 - acc: 0.9614\n",
      "Epoch 8/10\n",
      "30945/30945 [==============================] - 38s 1ms/step - loss: 0.3082 - acc: 0.9553\n",
      "Epoch 9/10\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.3045 - acc: 0.9519\n",
      "Epoch 10/10\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.3018 - acc: 0.9487\n",
      "15473/15473 [==============================] - 12s 800us/step\n",
      "30945/30945 [==============================] - 22s 713us/step\n",
      "[CV] .................... epochs=10, lr=0.002, nodes=32, total= 7.1min\n",
      "[CV] epochs=10, lr=0.002, nodes=32 ...................................\n",
      "Epoch 1/10\n",
      "30945/30945 [==============================] - 46s 1ms/step - loss: 0.3632 - acc: 0.9803\n",
      "Epoch 2/10\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.3445 - acc: 0.9795\n",
      "Epoch 3/10\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3367 - acc: 0.9724\n",
      "Epoch 4/10\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3307 - acc: 0.9690\n",
      "Epoch 5/10\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3288 - acc: 0.9625\n",
      "Epoch 6/10\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3243 - acc: 0.9632\n",
      "Epoch 7/10\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3197 - acc: 0.9583\n",
      "Epoch 8/10\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3204 - acc: 0.9520\n",
      "Epoch 9/10\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.3159 - acc: 0.9495\n",
      "Epoch 10/10\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3138 - acc: 0.9470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15473/15473 [==============================] - 13s 852us/step\n",
      "30945/30945 [==============================] - 24s 770us/step\n",
      "[CV] .................... epochs=10, lr=0.002, nodes=32, total= 6.6min\n",
      "[CV] epochs=10, lr=0.002, nodes=32 ...................................\n",
      "Epoch 1/10\n",
      "30946/30946 [==============================] - 45s 1ms/step - loss: 0.3548 - acc: 0.9814\n",
      "Epoch 2/10\n",
      "30946/30946 [==============================] - 34s 1ms/step - loss: 0.3352 - acc: 0.9780\n",
      "Epoch 3/10\n",
      "30946/30946 [==============================] - 34s 1ms/step - loss: 0.3259 - acc: 0.9722\n",
      "Epoch 4/10\n",
      "30946/30946 [==============================] - 34s 1ms/step - loss: 0.3205 - acc: 0.9696\n",
      "Epoch 5/10\n",
      "30946/30946 [==============================] - 34s 1ms/step - loss: 0.3160 - acc: 0.9651\n",
      "Epoch 6/10\n",
      "30946/30946 [==============================] - 34s 1ms/step - loss: 0.3119 - acc: 0.9607\n",
      "Epoch 7/10\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.3099 - acc: 0.9561\n",
      "Epoch 8/10\n",
      "30946/30946 [==============================] - 34s 1ms/step - loss: 0.3047 - acc: 0.9522\n",
      "Epoch 9/10\n",
      "30946/30946 [==============================] - 34s 1ms/step - loss: 0.3058 - acc: 0.9479\n",
      "Epoch 10/10\n",
      "30946/30946 [==============================] - 34s 1ms/step - loss: 0.3041 - acc: 0.9500\n",
      "15472/15472 [==============================] - 13s 851us/step\n",
      "30946/30946 [==============================] - 24s 776us/step\n",
      "[CV] .................... epochs=10, lr=0.002, nodes=32, total= 6.6min\n",
      "[CV] epochs=10, lr=0.002, nodes=64 ...................................\n",
      "Epoch 1/10\n",
      "30945/30945 [==============================] - 67s 2ms/step - loss: 0.3499 - acc: 0.9750\n",
      "Epoch 2/10\n",
      "30945/30945 [==============================] - 58s 2ms/step - loss: 0.3300 - acc: 0.9731\n",
      "Epoch 3/10\n",
      "30945/30945 [==============================] - 58s 2ms/step - loss: 0.3217 - acc: 0.9677\n",
      "Epoch 4/10\n",
      "30945/30945 [==============================] - 58s 2ms/step - loss: 0.3148 - acc: 0.9635\n",
      "Epoch 5/10\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3100 - acc: 0.9568\n",
      "Epoch 6/10\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3064 - acc: 0.9474\n",
      "Epoch 7/10\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3021 - acc: 0.9409\n",
      "Epoch 8/10\n",
      "30945/30945 [==============================] - 58s 2ms/step - loss: 0.3010 - acc: 0.9378\n",
      "Epoch 9/10\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3002 - acc: 0.9291\n",
      "Epoch 10/10\n",
      "30945/30945 [==============================] - 58s 2ms/step - loss: 0.2972 - acc: 0.9269\n",
      "15473/15473 [==============================] - 14s 873us/step\n",
      "30945/30945 [==============================] - 24s 787us/step\n",
      "[CV] .................... epochs=10, lr=0.002, nodes=64, total=10.5min\n",
      "[CV] epochs=10, lr=0.002, nodes=64 ...................................\n",
      "Epoch 1/10\n",
      "30945/30945 [==============================] - 65s 2ms/step - loss: 0.3631 - acc: 0.9803\n",
      "Epoch 2/10\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3417 - acc: 0.9754\n",
      "Epoch 3/10\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3341 - acc: 0.9694\n",
      "Epoch 4/10\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3273 - acc: 0.9643\n",
      "Epoch 5/10\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3216 - acc: 0.9594\n",
      "Epoch 6/10\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3171 - acc: 0.9568\n",
      "Epoch 7/10\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3137 - acc: 0.9479\n",
      "Epoch 8/10\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3091 - acc: 0.9446\n",
      "Epoch 9/10\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3080 - acc: 0.9408\n",
      "Epoch 10/10\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3070 - acc: 0.9382\n",
      "15473/15473 [==============================] - 14s 909us/step\n",
      "30945/30945 [==============================] - 26s 826us/step\n",
      "[CV] .................... epochs=10, lr=0.002, nodes=64, total=10.0min\n",
      "[CV] epochs=10, lr=0.002, nodes=64 ...................................\n",
      "Epoch 1/10\n",
      "30946/30946 [==============================] - 65s 2ms/step - loss: 0.3508 - acc: 0.9796\n",
      "Epoch 2/10\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.3297 - acc: 0.9765\n",
      "Epoch 3/10\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.3221 - acc: 0.9693\n",
      "Epoch 4/10\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3160 - acc: 0.9637\n",
      "Epoch 5/10\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3109 - acc: 0.9568\n",
      "Epoch 6/10\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.3077 - acc: 0.9508\n",
      "Epoch 7/10\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.3049 - acc: 0.9450\n",
      "Epoch 8/10\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3030 - acc: 0.9413\n",
      "Epoch 9/10\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.2981 - acc: 0.9332\n",
      "Epoch 10/10\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.2986 - acc: 0.9289\n",
      "15472/15472 [==============================] - 14s 917us/step\n",
      "30946/30946 [==============================] - 24s 765us/step\n",
      "[CV] .................... epochs=10, lr=0.002, nodes=64, total= 9.9min\n",
      "[CV] epochs=10, lr=0.003, nodes=16 ...................................\n",
      "Epoch 1/10\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3543 - acc: 0.9575\n",
      "Epoch 2/10\n",
      "30945/30945 [==============================] - 23s 743us/step - loss: 0.3372 - acc: 0.9789\n",
      "Epoch 3/10\n",
      "30945/30945 [==============================] - 23s 732us/step - loss: 0.3319 - acc: 0.9771\n",
      "Epoch 4/10\n",
      "30945/30945 [==============================] - 23s 733us/step - loss: 0.3288 - acc: 0.9730\n",
      "Epoch 5/10\n",
      "30945/30945 [==============================] - 23s 732us/step - loss: 0.3250 - acc: 0.9677\n",
      "Epoch 6/10\n",
      "30945/30945 [==============================] - 22s 707us/step - loss: 0.3217 - acc: 0.9682\n",
      "Epoch 7/10\n",
      "30945/30945 [==============================] - 22s 724us/step - loss: 0.3197 - acc: 0.9630\n",
      "Epoch 8/10\n",
      "30945/30945 [==============================] - 23s 734us/step - loss: 0.3182 - acc: 0.9570\n",
      "Epoch 9/10\n",
      "30945/30945 [==============================] - 23s 733us/step - loss: 0.3164 - acc: 0.9526\n",
      "Epoch 10/10\n",
      "30945/30945 [==============================] - 23s 734us/step - loss: 0.3177 - acc: 0.9496\n",
      "15473/15473 [==============================] - 12s 792us/step\n",
      "30945/30945 [==============================] - 23s 730us/step\n",
      "[CV] .................... epochs=10, lr=0.003, nodes=16, total= 4.7min\n",
      "[CV] epochs=10, lr=0.003, nodes=16 ...................................\n",
      "Epoch 1/10\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3635 - acc: 0.9752\n",
      "Epoch 2/10\n",
      "30945/30945 [==============================] - 19s 608us/step - loss: 0.3477 - acc: 0.9794\n",
      "Epoch 3/10\n",
      "30945/30945 [==============================] - 19s 610us/step - loss: 0.3434 - acc: 0.9747\n",
      "Epoch 4/10\n",
      "30945/30945 [==============================] - 19s 604us/step - loss: 0.3400 - acc: 0.9707\n",
      "Epoch 5/10\n",
      "30945/30945 [==============================] - 18s 585us/step - loss: 0.3377 - acc: 0.9707\n",
      "Epoch 6/10\n",
      "30945/30945 [==============================] - 19s 608us/step - loss: 0.3339 - acc: 0.9617\n",
      "Epoch 7/10\n",
      "30945/30945 [==============================] - 19s 598us/step - loss: 0.3309 - acc: 0.9575\n",
      "Epoch 8/10\n",
      "30945/30945 [==============================] - 19s 609us/step - loss: 0.3303 - acc: 0.9576\n",
      "Epoch 9/10\n",
      "30945/30945 [==============================] - 19s 600us/step - loss: 0.3297 - acc: 0.9534\n",
      "Epoch 10/10\n",
      "30945/30945 [==============================] - 19s 612us/step - loss: 0.3277 - acc: 0.9475\n",
      "15473/15473 [==============================] - 11s 689us/step\n",
      "30945/30945 [==============================] - 19s 607us/step\n",
      "[CV] .................... epochs=10, lr=0.003, nodes=16, total= 4.0min\n",
      "[CV] epochs=10, lr=0.003, nodes=16 ...................................\n",
      "Epoch 1/10\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.3553 - acc: 0.9826\n",
      "Epoch 2/10\n",
      "30946/30946 [==============================] - 19s 618us/step - loss: 0.3363 - acc: 0.9818\n",
      "Epoch 3/10\n",
      "30946/30946 [==============================] - 19s 623us/step - loss: 0.3281 - acc: 0.9751\n",
      "Epoch 4/10\n",
      "30946/30946 [==============================] - 19s 622us/step - loss: 0.3245 - acc: 0.9675\n",
      "Epoch 5/10\n",
      "30946/30946 [==============================] - 19s 627us/step - loss: 0.3230 - acc: 0.9649\n",
      "Epoch 6/10\n",
      "30946/30946 [==============================] - 19s 619us/step - loss: 0.3188 - acc: 0.9581\n",
      "Epoch 7/10\n",
      "30946/30946 [==============================] - 20s 632us/step - loss: 0.3160 - acc: 0.9534\n",
      "Epoch 8/10\n",
      "30946/30946 [==============================] - 19s 621us/step - loss: 0.3147 - acc: 0.9505\n",
      "Epoch 9/10\n",
      "30946/30946 [==============================] - 20s 637us/step - loss: 0.3142 - acc: 0.9454\n",
      "Epoch 10/10\n",
      "30946/30946 [==============================] - 20s 635us/step - loss: 0.3123 - acc: 0.9435\n",
      "15472/15472 [==============================] - 11s 692us/step\n",
      "30946/30946 [==============================] - 19s 612us/step\n",
      "[CV] .................... epochs=10, lr=0.003, nodes=16, total= 4.2min\n",
      "[CV] epochs=10, lr=0.003, nodes=32 ...................................\n",
      "Epoch 1/10\n",
      "30945/30945 [==============================] - 42s 1ms/step - loss: 0.3524 - acc: 0.9763\n",
      "Epoch 2/10\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3349 - acc: 0.9775\n",
      "Epoch 3/10\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3278 - acc: 0.9733\n",
      "Epoch 4/10\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3229 - acc: 0.9684\n",
      "Epoch 5/10\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3201 - acc: 0.9621\n",
      "Epoch 6/10\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3146 - acc: 0.9584\n",
      "Epoch 7/10\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3112 - acc: 0.9537\n",
      "Epoch 8/10\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3088 - acc: 0.9480\n",
      "Epoch 9/10\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3088 - acc: 0.9463\n",
      "Epoch 10/10\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3069 - acc: 0.9414\n",
      "15473/15473 [==============================] - 13s 863us/step\n",
      "30945/30945 [==============================] - 24s 777us/step\n",
      "[CV] .................... epochs=10, lr=0.003, nodes=32, total= 6.2min\n",
      "[CV] epochs=10, lr=0.003, nodes=32 ...................................\n",
      "Epoch 1/10\n",
      "30945/30945 [==============================] - 45s 1ms/step - loss: 0.3633 - acc: 0.9725\n",
      "Epoch 2/10\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3441 - acc: 0.9799\n",
      "Epoch 3/10\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3371 - acc: 0.9718\n",
      "Epoch 4/10\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3308 - acc: 0.9659\n",
      "Epoch 5/10\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3280 - acc: 0.9571\n",
      "Epoch 6/10\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3259 - acc: 0.9502\n",
      "Epoch 7/10\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3234 - acc: 0.9452\n",
      "Epoch 8/10\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.3215 - acc: 0.9444\n",
      "Epoch 9/10\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3199 - acc: 0.9354\n",
      "Epoch 10/10\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3191 - acc: 0.9344\n",
      "15473/15473 [==============================] - 13s 855us/step\n",
      "30945/30945 [==============================] - 24s 764us/step\n",
      "[CV] .................... epochs=10, lr=0.003, nodes=32, total= 6.6min\n",
      "[CV] epochs=10, lr=0.003, nodes=32 ...................................\n",
      "Epoch 1/10\n",
      "30946/30946 [==============================] - 45s 1ms/step - loss: 0.3513 - acc: 0.9797\n",
      "Epoch 2/10\n",
      "30946/30946 [==============================] - 34s 1ms/step - loss: 0.3349 - acc: 0.9799\n",
      "Epoch 3/10\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.3254 - acc: 0.9713\n",
      "Epoch 4/10\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.3198 - acc: 0.9646\n",
      "Epoch 5/10\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.3155 - acc: 0.9591\n",
      "Epoch 6/10\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.3125 - acc: 0.9549\n",
      "Epoch 7/10\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.3106 - acc: 0.9427\n",
      "Epoch 8/10\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.3087 - acc: 0.9396\n",
      "Epoch 9/10\n",
      "30946/30946 [==============================] - 34s 1ms/step - loss: 0.3074 - acc: 0.9336\n",
      "Epoch 10/10\n",
      "30946/30946 [==============================] - 34s 1ms/step - loss: 0.3075 - acc: 0.9259\n",
      "15472/15472 [==============================] - 13s 863us/step\n",
      "30946/30946 [==============================] - 24s 777us/step\n",
      "[CV] .................... epochs=10, lr=0.003, nodes=32, total= 6.5min\n",
      "[CV] epochs=10, lr=0.003, nodes=64 ...................................\n",
      "Epoch 1/10\n",
      "30945/30945 [==============================] - 65s 2ms/step - loss: 0.3491 - acc: 0.9751\n",
      "Epoch 2/10\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3304 - acc: 0.9719\n",
      "Epoch 3/10\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3219 - acc: 0.9677\n",
      "Epoch 4/10\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3147 - acc: 0.9589\n",
      "Epoch 5/10\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3111 - acc: 0.9520\n",
      "Epoch 6/10\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3078 - acc: 0.9498\n",
      "Epoch 7/10\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3061 - acc: 0.9427\n",
      "Epoch 8/10\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3074 - acc: 0.9406\n",
      "Epoch 9/10\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3020 - acc: 0.9376\n",
      "Epoch 10/10\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3011 - acc: 0.9271\n",
      "15473/15473 [==============================] - 14s 917us/step\n",
      "30945/30945 [==============================] - 26s 845us/step\n",
      "[CV] .................... epochs=10, lr=0.003, nodes=64, total=10.1min\n",
      "[CV] epochs=10, lr=0.003, nodes=64 ...................................\n",
      "Epoch 1/10\n",
      "30945/30945 [==============================] - 66s 2ms/step - loss: 0.3603 - acc: 0.9801\n",
      "Epoch 2/10\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3412 - acc: 0.9748\n",
      "Epoch 3/10\n",
      "30945/30945 [==============================] - 51s 2ms/step - loss: 0.3308 - acc: 0.9662\n",
      "Epoch 4/10\n",
      "30945/30945 [==============================] - 51s 2ms/step - loss: 0.3260 - acc: 0.9568\n",
      "Epoch 5/10\n",
      "30945/30945 [==============================] - 51s 2ms/step - loss: 0.3207 - acc: 0.9554\n",
      "Epoch 6/10\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.3165 - acc: 0.9516\n",
      "Epoch 7/10\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3148 - acc: 0.9438\n",
      "Epoch 8/10\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3136 - acc: 0.9408\n",
      "Epoch 9/10\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3128 - acc: 0.9390\n",
      "Epoch 10/10\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3112 - acc: 0.9342\n",
      "15473/15473 [==============================] - 14s 937us/step\n",
      "30945/30945 [==============================] - 26s 846us/step\n",
      "[CV] .................... epochs=10, lr=0.003, nodes=64, total= 9.9min\n",
      "[CV] epochs=10, lr=0.003, nodes=64 ...................................\n",
      "Epoch 1/10\n",
      "30946/30946 [==============================] - 65s 2ms/step - loss: 0.3504 - acc: 0.9786\n",
      "Epoch 2/10\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3322 - acc: 0.9749\n",
      "Epoch 3/10\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3201 - acc: 0.9655\n",
      "Epoch 4/10\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.3149 - acc: 0.9567\n",
      "Epoch 5/10\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3093 - acc: 0.9545\n",
      "Epoch 6/10\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3076 - acc: 0.9505\n",
      "Epoch 7/10\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3042 - acc: 0.9391\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3025 - acc: 0.9366\n",
      "Epoch 9/10\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3007 - acc: 0.9303\n",
      "Epoch 10/10\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3020 - acc: 0.9212\n",
      "15472/15472 [==============================] - 14s 935us/step\n",
      "30946/30946 [==============================] - 24s 778us/step\n",
      "[CV] .................... epochs=10, lr=0.003, nodes=64, total=10.0min\n",
      "[CV] epochs=20, lr=0.001, nodes=16 ...................................\n",
      "Epoch 1/20\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3706 - acc: 0.9596\n",
      "Epoch 2/20\n",
      "30945/30945 [==============================] - 23s 734us/step - loss: 0.3420 - acc: 0.9811\n",
      "Epoch 3/20\n",
      "30945/30945 [==============================] - 22s 700us/step - loss: 0.3362 - acc: 0.9808\n",
      "Epoch 4/20\n",
      "30945/30945 [==============================] - 23s 733us/step - loss: 0.3320 - acc: 0.9792\n",
      "Epoch 5/20\n",
      "30945/30945 [==============================] - 23s 733us/step - loss: 0.3284 - acc: 0.9772\n",
      "Epoch 6/20\n",
      "30945/30945 [==============================] - 23s 739us/step - loss: 0.3237 - acc: 0.9749\n",
      "Epoch 7/20\n",
      "30945/30945 [==============================] - 23s 738us/step - loss: 0.3222 - acc: 0.9709\n",
      "Epoch 8/20\n",
      "30945/30945 [==============================] - 23s 750us/step - loss: 0.3200 - acc: 0.9684\n",
      "Epoch 9/20\n",
      "30945/30945 [==============================] - 23s 747us/step - loss: 0.3179 - acc: 0.9669\n",
      "Epoch 10/20\n",
      "30945/30945 [==============================] - 22s 718us/step - loss: 0.3160 - acc: 0.9606\n",
      "Epoch 11/20\n",
      "30945/30945 [==============================] - 22s 724us/step - loss: 0.3133 - acc: 0.9587\n",
      "Epoch 12/20\n",
      "30945/30945 [==============================] - 23s 728us/step - loss: 0.3125 - acc: 0.9560\n",
      "Epoch 13/20\n",
      "30945/30945 [==============================] - 23s 727us/step - loss: 0.3106 - acc: 0.9552\n",
      "Epoch 14/20\n",
      "30945/30945 [==============================] - 23s 729us/step - loss: 0.3105 - acc: 0.9492\n",
      "Epoch 15/20\n",
      "30945/30945 [==============================] - 23s 729us/step - loss: 0.3086 - acc: 0.9478\n",
      "Epoch 16/20\n",
      "30945/30945 [==============================] - 23s 728us/step - loss: 0.3084 - acc: 0.9427\n",
      "Epoch 17/20\n",
      "30945/30945 [==============================] - 23s 739us/step - loss: 0.3089 - acc: 0.9461\n",
      "Epoch 18/20\n",
      "30945/30945 [==============================] - 22s 724us/step - loss: 0.3062 - acc: 0.9425\n",
      "Epoch 19/20\n",
      "30945/30945 [==============================] - 22s 722us/step - loss: 0.3033 - acc: 0.9362\n",
      "Epoch 20/20\n",
      "30945/30945 [==============================] - 22s 722us/step - loss: 0.3020 - acc: 0.9394\n",
      "15473/15473 [==============================] - 12s 802us/step\n",
      "30945/30945 [==============================] - 23s 737us/step\n",
      "[CV] .................... epochs=20, lr=0.001, nodes=16, total= 8.5min\n",
      "[CV] epochs=20, lr=0.001, nodes=16 ...................................\n",
      "Epoch 1/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3778 - acc: 0.9414\n",
      "Epoch 2/20\n",
      "30945/30945 [==============================] - 18s 580us/step - loss: 0.3517 - acc: 0.9800\n",
      "Epoch 3/20\n",
      "30945/30945 [==============================] - 19s 601us/step - loss: 0.3457 - acc: 0.9793\n",
      "Epoch 4/20\n",
      "30945/30945 [==============================] - 19s 606us/step - loss: 0.3419 - acc: 0.9802\n",
      "Epoch 5/20\n",
      "30945/30945 [==============================] - 19s 605us/step - loss: 0.3397 - acc: 0.9772\n",
      "Epoch 6/20\n",
      "30945/30945 [==============================] - 19s 608us/step - loss: 0.3374 - acc: 0.9751\n",
      "Epoch 7/20\n",
      "30945/30945 [==============================] - 19s 602us/step - loss: 0.3344 - acc: 0.9729\n",
      "Epoch 8/20\n",
      "30945/30945 [==============================] - 19s 606us/step - loss: 0.3313 - acc: 0.9694\n",
      "Epoch 9/20\n",
      "30945/30945 [==============================] - 19s 605us/step - loss: 0.3293 - acc: 0.9673\n",
      "Epoch 10/20\n",
      "30945/30945 [==============================] - 19s 603us/step - loss: 0.3280 - acc: 0.9665\n",
      "Epoch 11/20\n",
      "30945/30945 [==============================] - 19s 612us/step - loss: 0.3270 - acc: 0.9624\n",
      "Epoch 12/20\n",
      "30945/30945 [==============================] - 19s 612us/step - loss: 0.3251 - acc: 0.9591\n",
      "Epoch 13/20\n",
      "30945/30945 [==============================] - 19s 608us/step - loss: 0.3230 - acc: 0.9547\n",
      "Epoch 14/20\n",
      "30945/30945 [==============================] - 19s 610us/step - loss: 0.3214 - acc: 0.9527\n",
      "Epoch 15/20\n",
      "30945/30945 [==============================] - 19s 612us/step - loss: 0.3203 - acc: 0.9525\n",
      "Epoch 16/20\n",
      "30945/30945 [==============================] - 19s 616us/step - loss: 0.3199 - acc: 0.9492\n",
      "Epoch 17/20\n",
      "30945/30945 [==============================] - 19s 619us/step - loss: 0.3194 - acc: 0.9487\n",
      "Epoch 18/20\n",
      "30945/30945 [==============================] - 19s 620us/step - loss: 0.3184 - acc: 0.9430\n",
      "Epoch 19/20\n",
      "30945/30945 [==============================] - 19s 615us/step - loss: 0.3157 - acc: 0.9447\n",
      "Epoch 20/20\n",
      "30945/30945 [==============================] - 19s 617us/step - loss: 0.3167 - acc: 0.9394\n",
      "15473/15473 [==============================] - 11s 712us/step\n",
      "30945/30945 [==============================] - 19s 616us/step\n",
      "[CV] .................... epochs=20, lr=0.001, nodes=16, total= 7.2min\n",
      "[CV] epochs=20, lr=0.001, nodes=16 ...................................\n",
      "Epoch 1/20\n",
      "30946/30946 [==============================] - 32s 1ms/step - loss: 0.3643 - acc: 0.9891\n",
      "Epoch 2/20\n",
      "30946/30946 [==============================] - 19s 615us/step - loss: 0.3431 - acc: 0.9850\n",
      "Epoch 3/20\n",
      "30946/30946 [==============================] - 19s 604us/step - loss: 0.3377 - acc: 0.9829\n",
      "Epoch 4/20\n",
      "30946/30946 [==============================] - 19s 606us/step - loss: 0.3341 - acc: 0.9783\n",
      "Epoch 5/20\n",
      "30946/30946 [==============================] - 19s 601us/step - loss: 0.3296 - acc: 0.9772\n",
      "Epoch 6/20\n",
      "30946/30946 [==============================] - 19s 608us/step - loss: 0.3285 - acc: 0.9738\n",
      "Epoch 7/20\n",
      "30946/30946 [==============================] - 19s 607us/step - loss: 0.3236 - acc: 0.9717\n",
      "Epoch 8/20\n",
      "30946/30946 [==============================] - 19s 604us/step - loss: 0.3222 - acc: 0.9698\n",
      "Epoch 9/20\n",
      "30946/30946 [==============================] - 19s 601us/step - loss: 0.3192 - acc: 0.9684\n",
      "Epoch 10/20\n",
      "30946/30946 [==============================] - 19s 606us/step - loss: 0.3191 - acc: 0.9673\n",
      "Epoch 11/20\n",
      "30946/30946 [==============================] - 19s 605us/step - loss: 0.3171 - acc: 0.9632\n",
      "Epoch 12/20\n",
      "30946/30946 [==============================] - 19s 609us/step - loss: 0.3138 - acc: 0.9603\n",
      "Epoch 13/20\n",
      "30946/30946 [==============================] - 18s 591us/step - loss: 0.3149 - acc: 0.9626\n",
      "Epoch 14/20\n",
      "30946/30946 [==============================] - 18s 596us/step - loss: 0.3126 - acc: 0.9551\n",
      "Epoch 15/20\n",
      "30946/30946 [==============================] - 19s 604us/step - loss: 0.3119 - acc: 0.9566\n",
      "Epoch 16/20\n",
      "30946/30946 [==============================] - 19s 609us/step - loss: 0.3099 - acc: 0.9542\n",
      "Epoch 17/20\n",
      "30946/30946 [==============================] - 18s 597us/step - loss: 0.3092 - acc: 0.9496\n",
      "Epoch 18/20\n",
      "30946/30946 [==============================] - 18s 582us/step - loss: 0.3087 - acc: 0.9467\n",
      "Epoch 19/20\n",
      "30946/30946 [==============================] - 19s 616us/step - loss: 0.3077 - acc: 0.9408\n",
      "Epoch 20/20\n",
      "30946/30946 [==============================] - 19s 603us/step - loss: 0.3080 - acc: 0.9418\n",
      "15472/15472 [==============================] - 11s 715us/step\n",
      "30946/30946 [==============================] - 19s 618us/step\n",
      "[CV] .................... epochs=20, lr=0.001, nodes=16, total= 7.2min\n",
      "[CV] epochs=20, lr=0.001, nodes=32 ...................................\n",
      "Epoch 1/20\n",
      "30945/30945 [==============================] - 44s 1ms/step - loss: 0.3614 - acc: 0.9747\n",
      "Epoch 2/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3379 - acc: 0.9800\n",
      "Epoch 3/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3304 - acc: 0.9764\n",
      "Epoch 4/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3243 - acc: 0.9743\n",
      "Epoch 5/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3197 - acc: 0.9721\n",
      "Epoch 6/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3164 - acc: 0.9699\n",
      "Epoch 7/20\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.3129 - acc: 0.9663\n",
      "Epoch 8/20\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.3110 - acc: 0.9641\n",
      "Epoch 9/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3069 - acc: 0.9635\n",
      "Epoch 10/20\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.3040 - acc: 0.9585\n",
      "Epoch 11/20\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.3008 - acc: 0.9570\n",
      "Epoch 12/20\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.3009 - acc: 0.9533\n",
      "Epoch 13/20\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.2995 - acc: 0.9514\n",
      "Epoch 14/20\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.2976 - acc: 0.9474\n",
      "Epoch 15/20\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.2963 - acc: 0.9437\n",
      "Epoch 16/20\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.2962 - acc: 0.9406\n",
      "Epoch 17/20\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.2932 - acc: 0.9392\n",
      "Epoch 18/20\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.2929 - acc: 0.9384\n",
      "Epoch 19/20\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.2923 - acc: 0.9351\n",
      "Epoch 20/20\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.2902 - acc: 0.9287\n",
      "15473/15473 [==============================] - 14s 916us/step\n",
      "30945/30945 [==============================] - 24s 780us/step\n",
      "[CV] .................... epochs=20, lr=0.001, nodes=32, total=11.9min\n",
      "[CV] epochs=20, lr=0.001, nodes=32 ...................................\n",
      "Epoch 1/20\n",
      "30945/30945 [==============================] - 42s 1ms/step - loss: 0.3700 - acc: 0.9682\n",
      "Epoch 2/20\n",
      "30945/30945 [==============================] - 31s 989us/step - loss: 0.3489 - acc: 0.9814\n",
      "Epoch 3/20\n",
      "30945/30945 [==============================] - 31s 991us/step - loss: 0.3422 - acc: 0.9787\n",
      "Epoch 4/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3350 - acc: 0.9767\n",
      "Epoch 5/20\n",
      "30945/30945 [==============================] - 31s 995us/step - loss: 0.3303 - acc: 0.9709\n",
      "Epoch 6/20\n",
      "30945/30945 [==============================] - 30s 981us/step - loss: 0.3269 - acc: 0.9667\n",
      "Epoch 7/20\n",
      "30945/30945 [==============================] - 31s 998us/step - loss: 0.3234 - acc: 0.9648\n",
      "Epoch 8/20\n",
      "30945/30945 [==============================] - 31s 991us/step - loss: 0.3210 - acc: 0.9608\n",
      "Epoch 9/20\n",
      "30945/30945 [==============================] - 31s 994us/step - loss: 0.3184 - acc: 0.9541\n",
      "Epoch 10/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3161 - acc: 0.9528\n",
      "Epoch 11/20\n",
      "30945/30945 [==============================] - 31s 999us/step - loss: 0.3166 - acc: 0.9467\n",
      "Epoch 12/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3121 - acc: 0.9400\n",
      "Epoch 13/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3131 - acc: 0.9384\n",
      "Epoch 14/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3089 - acc: 0.9363\n",
      "Epoch 15/20\n",
      "30945/30945 [==============================] - 31s 996us/step - loss: 0.3083 - acc: 0.9273\n",
      "Epoch 16/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3073 - acc: 0.9307\n",
      "Epoch 17/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3072 - acc: 0.9251\n",
      "Epoch 18/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3065 - acc: 0.9267\n",
      "Epoch 19/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3051 - acc: 0.9224\n",
      "Epoch 20/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3058 - acc: 0.9233\n",
      "15473/15473 [==============================] - 14s 879us/step\n",
      "30945/30945 [==============================] - 24s 778us/step\n",
      "[CV] .................... epochs=20, lr=0.001, nodes=32, total=11.3min\n",
      "[CV] epochs=20, lr=0.001, nodes=32 ...................................\n",
      "Epoch 1/20\n",
      "30946/30946 [==============================] - 42s 1ms/step - loss: 0.3591 - acc: 0.9844\n",
      "Epoch 2/20\n",
      "30946/30946 [==============================] - 30s 981us/step - loss: 0.3369 - acc: 0.9804\n",
      "Epoch 3/20\n",
      "30946/30946 [==============================] - 30s 962us/step - loss: 0.3284 - acc: 0.9768\n",
      "Epoch 4/20\n",
      "30946/30946 [==============================] - 30s 982us/step - loss: 0.3220 - acc: 0.9723\n",
      "Epoch 5/20\n",
      "30946/30946 [==============================] - 31s 986us/step - loss: 0.3177 - acc: 0.9710\n",
      "Epoch 6/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.3143 - acc: 0.9665\n",
      "Epoch 7/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.3114 - acc: 0.9625\n",
      "Epoch 8/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.3084 - acc: 0.9617\n",
      "Epoch 9/20\n",
      "30946/30946 [==============================] - 32s 1ms/step - loss: 0.3062 - acc: 0.9609\n",
      "Epoch 10/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.3037 - acc: 0.9549\n",
      "Epoch 11/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.3036 - acc: 0.9508\n",
      "Epoch 12/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.3011 - acc: 0.9471\n",
      "Epoch 13/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.3000 - acc: 0.9469\n",
      "Epoch 14/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.2984 - acc: 0.9406\n",
      "Epoch 15/20\n",
      "30946/30946 [==============================] - 31s 995us/step - loss: 0.2976 - acc: 0.9379\n",
      "Epoch 16/20\n",
      "30946/30946 [==============================] - 31s 989us/step - loss: 0.2954 - acc: 0.9354\n",
      "Epoch 17/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.2938 - acc: 0.9320\n",
      "Epoch 18/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.2943 - acc: 0.9239\n",
      "Epoch 19/20\n",
      "30946/30946 [==============================] - 30s 983us/step - loss: 0.2933 - acc: 0.9229\n",
      "Epoch 20/20\n",
      "30946/30946 [==============================] - 31s 999us/step - loss: 0.2913 - acc: 0.9210\n",
      "15472/15472 [==============================] - 13s 870us/step\n",
      "30946/30946 [==============================] - 22s 727us/step\n",
      "[CV] .................... epochs=20, lr=0.001, nodes=32, total=11.3min\n",
      "[CV] epochs=20, lr=0.001, nodes=64 ...................................\n",
      "Epoch 1/20\n",
      "30945/30945 [==============================] - 64s 2ms/step - loss: 0.3551 - acc: 0.9815\n",
      "Epoch 2/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3340 - acc: 0.9779\n",
      "Epoch 3/20\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.3239 - acc: 0.9744\n",
      "Epoch 4/20\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.3175 - acc: 0.9685\n",
      "Epoch 5/20\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.3115 - acc: 0.9650\n",
      "Epoch 6/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3062 - acc: 0.9593\n",
      "Epoch 7/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3024 - acc: 0.9540\n",
      "Epoch 8/20\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.2992 - acc: 0.9511\n",
      "Epoch 9/20\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.2976 - acc: 0.9452\n",
      "Epoch 10/20\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.2955 - acc: 0.9431\n",
      "Epoch 11/20\n",
      "30945/30945 [==============================] - 51s 2ms/step - loss: 0.2924 - acc: 0.9364\n",
      "Epoch 12/20\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.2917 - acc: 0.9361\n",
      "Epoch 13/20\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.2905 - acc: 0.9335\n",
      "Epoch 14/20\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.2885 - acc: 0.9286\n",
      "Epoch 15/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.2874 - acc: 0.9275\n",
      "Epoch 16/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.2870 - acc: 0.9295\n",
      "Epoch 17/20\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.2866 - acc: 0.9224\n",
      "Epoch 18/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.2875 - acc: 0.9209\n",
      "Epoch 19/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.2852 - acc: 0.9189\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.2851 - acc: 0.9132\n",
      "15473/15473 [==============================] - 14s 890us/step\n",
      "30945/30945 [==============================] - 24s 783us/step\n",
      "[CV] .................... epochs=20, lr=0.001, nodes=64, total=18.5min\n",
      "[CV] epochs=20, lr=0.001, nodes=64 ...................................\n",
      "Epoch 1/20\n",
      "30945/30945 [==============================] - 65s 2ms/step - loss: 0.3652 - acc: 0.9787\n",
      "Epoch 2/20\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3437 - acc: 0.9787\n",
      "Epoch 3/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3337 - acc: 0.9731\n",
      "Epoch 4/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3279 - acc: 0.9686\n",
      "Epoch 5/20\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.3227 - acc: 0.9650\n",
      "Epoch 6/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3197 - acc: 0.9635\n",
      "Epoch 7/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3140 - acc: 0.9575\n",
      "Epoch 8/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3124 - acc: 0.9516\n",
      "Epoch 9/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3095 - acc: 0.9497\n",
      "Epoch 10/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3070 - acc: 0.9446\n",
      "Epoch 11/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3059 - acc: 0.9419\n",
      "Epoch 12/20\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.3029 - acc: 0.9387\n",
      "Epoch 13/20\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3012 - acc: 0.9348\n",
      "Epoch 14/20\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3024 - acc: 0.9336\n",
      "Epoch 15/20\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.3002 - acc: 0.9276\n",
      "Epoch 16/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.2979 - acc: 0.9207\n",
      "Epoch 17/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.2977 - acc: 0.9200\n",
      "Epoch 18/20\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.2955 - acc: 0.9156\n",
      "Epoch 19/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.2949 - acc: 0.9162\n",
      "Epoch 20/20\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.2945 - acc: 0.9137\n",
      "15473/15473 [==============================] - 14s 894us/step\n",
      "30945/30945 [==============================] - 24s 783us/step\n",
      "[CV] .................... epochs=20, lr=0.001, nodes=64, total=18.6min\n",
      "[CV] epochs=20, lr=0.001, nodes=64 ...................................\n",
      "Epoch 1/20\n",
      "30946/30946 [==============================] - 63s 2ms/step - loss: 0.3544 - acc: 0.9832\n",
      "Epoch 2/20\n",
      "30946/30946 [==============================] - 51s 2ms/step - loss: 0.3329 - acc: 0.9773\n",
      "Epoch 3/20\n",
      "30946/30946 [==============================] - 52s 2ms/step - loss: 0.3235 - acc: 0.9746\n",
      "Epoch 4/20\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.3165 - acc: 0.9688\n",
      "Epoch 5/20\n",
      "30946/30946 [==============================] - 52s 2ms/step - loss: 0.3110 - acc: 0.9648\n",
      "Epoch 6/20\n",
      "30946/30946 [==============================] - 52s 2ms/step - loss: 0.3081 - acc: 0.9574\n",
      "Epoch 7/20\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.3044 - acc: 0.9581\n",
      "Epoch 8/20\n",
      "30946/30946 [==============================] - 52s 2ms/step - loss: 0.3010 - acc: 0.9536\n",
      "Epoch 9/20\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.2991 - acc: 0.9467\n",
      "Epoch 10/20\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.2968 - acc: 0.9445\n",
      "Epoch 11/20\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.2942 - acc: 0.9416\n",
      "Epoch 12/20\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.2920 - acc: 0.9319\n",
      "Epoch 13/20\n",
      "30946/30946 [==============================] - 51s 2ms/step - loss: 0.2897 - acc: 0.9299\n",
      "Epoch 14/20\n",
      "30946/30946 [==============================] - 51s 2ms/step - loss: 0.2903 - acc: 0.9288\n",
      "Epoch 15/20\n",
      "30946/30946 [==============================] - 52s 2ms/step - loss: 0.2871 - acc: 0.9238\n",
      "Epoch 16/20\n",
      "30946/30946 [==============================] - 52s 2ms/step - loss: 0.2884 - acc: 0.9132\n",
      "Epoch 17/20\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.2858 - acc: 0.9189\n",
      "Epoch 18/20\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.2864 - acc: 0.9139\n",
      "Epoch 19/20\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.2858 - acc: 0.9124\n",
      "Epoch 20/20\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.2856 - acc: 0.9092\n",
      "15472/15472 [==============================] - 14s 893us/step\n",
      "30946/30946 [==============================] - 26s 840us/step\n",
      "[CV] .................... epochs=20, lr=0.001, nodes=64, total=18.4min\n",
      "[CV] epochs=20, lr=0.002, nodes=16 ...................................\n",
      "Epoch 1/20\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3594 - acc: 0.9672\n",
      "Epoch 2/20\n",
      "30945/30945 [==============================] - 22s 706us/step - loss: 0.3411 - acc: 0.9851\n",
      "Epoch 3/20\n",
      "30945/30945 [==============================] - 21s 693us/step - loss: 0.3360 - acc: 0.9817\n",
      "Epoch 4/20\n",
      "30945/30945 [==============================] - 22s 698us/step - loss: 0.3308 - acc: 0.9795\n",
      "Epoch 5/20\n",
      "30945/30945 [==============================] - 22s 696us/step - loss: 0.3287 - acc: 0.9748\n",
      "Epoch 6/20\n",
      "30945/30945 [==============================] - 22s 701us/step - loss: 0.3230 - acc: 0.9714\n",
      "Epoch 7/20\n",
      "30945/30945 [==============================] - 22s 698us/step - loss: 0.3230 - acc: 0.9661\n",
      "Epoch 8/20\n",
      "30945/30945 [==============================] - 22s 696us/step - loss: 0.3178 - acc: 0.9609\n",
      "Epoch 9/20\n",
      "30945/30945 [==============================] - 21s 684us/step - loss: 0.3162 - acc: 0.9599\n",
      "Epoch 10/20\n",
      "30945/30945 [==============================] - 22s 695us/step - loss: 0.3172 - acc: 0.9568\n",
      "Epoch 11/20\n",
      "30945/30945 [==============================] - 21s 679us/step - loss: 0.3138 - acc: 0.9507\n",
      "Epoch 12/20\n",
      "30945/30945 [==============================] - 21s 676us/step - loss: 0.3137 - acc: 0.9485\n",
      "Epoch 13/20\n",
      "30945/30945 [==============================] - 21s 682us/step - loss: 0.3117 - acc: 0.9425\n",
      "Epoch 14/20\n",
      "30945/30945 [==============================] - 21s 681us/step - loss: 0.3102 - acc: 0.9409\n",
      "Epoch 15/20\n",
      "30945/30945 [==============================] - 21s 680us/step - loss: 0.3100 - acc: 0.9397\n",
      "Epoch 16/20\n",
      "30945/30945 [==============================] - 21s 687us/step - loss: 0.3108 - acc: 0.9366\n",
      "Epoch 17/20\n",
      "30945/30945 [==============================] - 21s 686us/step - loss: 0.3088 - acc: 0.9373\n",
      "Epoch 18/20\n",
      "30945/30945 [==============================] - 21s 686us/step - loss: 0.3074 - acc: 0.9347\n",
      "Epoch 19/20\n",
      "30945/30945 [==============================] - 21s 691us/step - loss: 0.3052 - acc: 0.9261\n",
      "Epoch 20/20\n",
      "30945/30945 [==============================] - 21s 686us/step - loss: 0.3047 - acc: 0.9297\n",
      "15473/15473 [==============================] - 13s 838us/step\n",
      "30945/30945 [==============================] - 23s 729us/step\n",
      "[CV] .................... epochs=20, lr=0.002, nodes=16, total= 8.1min\n",
      "[CV] epochs=20, lr=0.002, nodes=16 ...................................\n",
      "Epoch 1/20\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3672 - acc: 0.9509\n",
      "Epoch 2/20\n",
      "30945/30945 [==============================] - 22s 699us/step - loss: 0.3481 - acc: 0.9826\n",
      "Epoch 3/20\n",
      "30945/30945 [==============================] - 21s 689us/step - loss: 0.3430 - acc: 0.9813\n",
      "Epoch 4/20\n",
      "30945/30945 [==============================] - 21s 665us/step - loss: 0.3405 - acc: 0.9780\n",
      "Epoch 5/20\n",
      "30945/30945 [==============================] - 20s 657us/step - loss: 0.3348 - acc: 0.9734\n",
      "Epoch 6/20\n",
      "30945/30945 [==============================] - 20s 660us/step - loss: 0.3332 - acc: 0.9697\n",
      "Epoch 7/20\n",
      "30945/30945 [==============================] - 21s 670us/step - loss: 0.3309 - acc: 0.9659\n",
      "Epoch 8/20\n",
      "30945/30945 [==============================] - 20s 660us/step - loss: 0.3285 - acc: 0.9650\n",
      "Epoch 9/20\n",
      "30945/30945 [==============================] - 21s 672us/step - loss: 0.3258 - acc: 0.9625\n",
      "Epoch 10/20\n",
      "30945/30945 [==============================] - 21s 684us/step - loss: 0.3252 - acc: 0.9596\n",
      "Epoch 11/20\n",
      "30945/30945 [==============================] - 21s 678us/step - loss: 0.3226 - acc: 0.9575\n",
      "Epoch 12/20\n",
      "30945/30945 [==============================] - 21s 673us/step - loss: 0.3249 - acc: 0.9529\n",
      "Epoch 13/20\n",
      "30945/30945 [==============================] - 20s 656us/step - loss: 0.3212 - acc: 0.9520\n",
      "Epoch 14/20\n",
      "30945/30945 [==============================] - 21s 678us/step - loss: 0.3186 - acc: 0.9450\n",
      "Epoch 15/20\n",
      "30945/30945 [==============================] - 21s 686us/step - loss: 0.3181 - acc: 0.9441\n",
      "Epoch 16/20\n",
      "30945/30945 [==============================] - 21s 682us/step - loss: 0.3164 - acc: 0.9430\n",
      "Epoch 17/20\n",
      "30945/30945 [==============================] - 21s 668us/step - loss: 0.3162 - acc: 0.9379\n",
      "Epoch 18/20\n",
      "30945/30945 [==============================] - 21s 691us/step - loss: 0.3165 - acc: 0.9360\n",
      "Epoch 19/20\n",
      "30945/30945 [==============================] - 21s 688us/step - loss: 0.3164 - acc: 0.9315\n",
      "Epoch 20/20\n",
      "30945/30945 [==============================] - 21s 681us/step - loss: 0.3149 - acc: 0.9350\n",
      "15473/15473 [==============================] - 13s 840us/step\n",
      "30945/30945 [==============================] - 23s 738us/step\n",
      "[CV] .................... epochs=20, lr=0.002, nodes=16, total= 8.0min\n",
      "[CV] epochs=20, lr=0.002, nodes=16 ...................................\n",
      "Epoch 1/20\n",
      "30946/30946 [==============================] - 34s 1ms/step - loss: 0.3571 - acc: 0.9702\n",
      "Epoch 2/20\n",
      "30946/30946 [==============================] - 21s 672us/step - loss: 0.3395 - acc: 0.9835\n",
      "Epoch 3/20\n",
      "30946/30946 [==============================] - 21s 690us/step - loss: 0.3312 - acc: 0.9802\n",
      "Epoch 4/20\n",
      "30946/30946 [==============================] - 21s 680us/step - loss: 0.3277 - acc: 0.9730\n",
      "Epoch 5/20\n",
      "30946/30946 [==============================] - 21s 667us/step - loss: 0.3232 - acc: 0.9709\n",
      "Epoch 6/20\n",
      "30946/30946 [==============================] - 21s 675us/step - loss: 0.3204 - acc: 0.9654\n",
      "Epoch 7/20\n",
      "30946/30946 [==============================] - 21s 681us/step - loss: 0.3185 - acc: 0.9610\n",
      "Epoch 8/20\n",
      "30946/30946 [==============================] - 21s 679us/step - loss: 0.3160 - acc: 0.9565\n",
      "Epoch 9/20\n",
      "30946/30946 [==============================] - 20s 657us/step - loss: 0.3140 - acc: 0.9511\n",
      "Epoch 10/20\n",
      "30946/30946 [==============================] - 21s 679us/step - loss: 0.3129 - acc: 0.9455\n",
      "Epoch 11/20\n",
      "30946/30946 [==============================] - 21s 681us/step - loss: 0.3111 - acc: 0.9455\n",
      "Epoch 12/20\n",
      "30946/30946 [==============================] - 21s 680us/step - loss: 0.3098 - acc: 0.9388\n",
      "Epoch 13/20\n",
      "30946/30946 [==============================] - 21s 684us/step - loss: 0.3106 - acc: 0.9344\n",
      "Epoch 14/20\n",
      "30946/30946 [==============================] - 21s 694us/step - loss: 0.3066 - acc: 0.9299\n",
      "Epoch 15/20\n",
      "30946/30946 [==============================] - 21s 687us/step - loss: 0.3071 - acc: 0.9290\n",
      "Epoch 16/20\n",
      "30946/30946 [==============================] - 21s 685us/step - loss: 0.3052 - acc: 0.9216\n",
      "Epoch 17/20\n",
      "30946/30946 [==============================] - 20s 646us/step - loss: 0.3047 - acc: 0.9182\n",
      "Epoch 18/20\n",
      "30946/30946 [==============================] - 21s 687us/step - loss: 0.3049 - acc: 0.9140\n",
      "Epoch 19/20\n",
      "30946/30946 [==============================] - 21s 685us/step - loss: 0.3036 - acc: 0.9122\n",
      "Epoch 20/20\n",
      "30946/30946 [==============================] - 21s 679us/step - loss: 0.3025 - acc: 0.9049\n",
      "15472/15472 [==============================] - 13s 828us/step\n",
      "30946/30946 [==============================] - 23s 733us/step\n",
      "[CV] .................... epochs=20, lr=0.002, nodes=16, total= 8.0min\n",
      "[CV] epochs=20, lr=0.002, nodes=32 ...................................\n",
      "Epoch 1/20\n",
      "30945/30945 [==============================] - 43s 1ms/step - loss: 0.3528 - acc: 0.9804\n",
      "Epoch 2/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3365 - acc: 0.9792\n",
      "Epoch 3/20\n",
      "30945/30945 [==============================] - 30s 966us/step - loss: 0.3264 - acc: 0.9744\n",
      "Epoch 4/20\n",
      "30945/30945 [==============================] - 31s 990us/step - loss: 0.3232 - acc: 0.9688\n",
      "Epoch 5/20\n",
      "30945/30945 [==============================] - 30s 985us/step - loss: 0.3184 - acc: 0.9659\n",
      "Epoch 6/20\n",
      "30945/30945 [==============================] - 29s 948us/step - loss: 0.3144 - acc: 0.9604\n",
      "Epoch 7/20\n",
      "30945/30945 [==============================] - 31s 999us/step - loss: 0.3109 - acc: 0.9595\n",
      "Epoch 8/20\n",
      "30945/30945 [==============================] - 31s 993us/step - loss: 0.3077 - acc: 0.9542\n",
      "Epoch 9/20\n",
      "30945/30945 [==============================] - 31s 995us/step - loss: 0.3071 - acc: 0.9518\n",
      "Epoch 10/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3040 - acc: 0.9461\n",
      "Epoch 11/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3020 - acc: 0.9487\n",
      "Epoch 12/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3014 - acc: 0.9375\n",
      "Epoch 13/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.2996 - acc: 0.9397\n",
      "Epoch 14/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.2984 - acc: 0.9368\n",
      "Epoch 15/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.2987 - acc: 0.9311\n",
      "Epoch 16/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.2975 - acc: 0.9299\n",
      "Epoch 17/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.2964 - acc: 0.9249\n",
      "Epoch 18/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.2976 - acc: 0.9211\n",
      "Epoch 19/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.2973 - acc: 0.9191\n",
      "Epoch 20/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.2967 - acc: 0.9159\n",
      "15473/15473 [==============================] - 14s 896us/step\n",
      "30945/30945 [==============================] - 23s 729us/step\n",
      "[CV] .................... epochs=20, lr=0.002, nodes=32, total=11.4min\n",
      "[CV] epochs=20, lr=0.002, nodes=32 ...................................\n",
      "Epoch 1/20\n",
      "30945/30945 [==============================] - 46s 1ms/step - loss: 0.3656 - acc: 0.9688\n",
      "Epoch 2/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3438 - acc: 0.9777\n",
      "Epoch 3/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3363 - acc: 0.9764\n",
      "Epoch 4/20\n",
      "30945/30945 [==============================] - 30s 973us/step - loss: 0.3315 - acc: 0.9715\n",
      "Epoch 5/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3279 - acc: 0.9696\n",
      "Epoch 6/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3245 - acc: 0.9656\n",
      "Epoch 7/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3227 - acc: 0.9587\n",
      "Epoch 8/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3189 - acc: 0.9554\n",
      "Epoch 9/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3169 - acc: 0.9503\n",
      "Epoch 10/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3156 - acc: 0.9457\n",
      "Epoch 11/20\n",
      "30945/30945 [==============================] - 31s 999us/step - loss: 0.3128 - acc: 0.9464\n",
      "Epoch 12/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3105 - acc: 0.9400\n",
      "Epoch 13/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3126 - acc: 0.9436\n",
      "Epoch 14/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3083 - acc: 0.9399\n",
      "Epoch 15/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3093 - acc: 0.9386\n",
      "Epoch 16/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3081 - acc: 0.9327\n",
      "Epoch 17/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3082 - acc: 0.9227\n",
      "Epoch 18/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3078 - acc: 0.9256\n",
      "Epoch 19/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3070 - acc: 0.9206\n",
      "Epoch 20/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3073 - acc: 0.9175\n",
      "15473/15473 [==============================] - 14s 889us/step\n",
      "30945/30945 [==============================] - 23s 735us/step\n",
      "[CV] .................... epochs=20, lr=0.002, nodes=32, total=11.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] epochs=20, lr=0.002, nodes=32 ...................................\n",
      "Epoch 1/20\n",
      "30946/30946 [==============================] - 46s 1ms/step - loss: 0.3526 - acc: 0.9826\n",
      "Epoch 2/20\n",
      "30946/30946 [==============================] - 32s 1ms/step - loss: 0.3335 - acc: 0.9775\n",
      "Epoch 3/20\n",
      "30946/30946 [==============================] - 31s 990us/step - loss: 0.3248 - acc: 0.9709\n",
      "Epoch 4/20\n",
      "30946/30946 [==============================] - 31s 994us/step - loss: 0.3187 - acc: 0.9674\n",
      "Epoch 5/20\n",
      "30946/30946 [==============================] - 31s 996us/step - loss: 0.3153 - acc: 0.9621\n",
      "Epoch 6/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.3110 - acc: 0.9586\n",
      "Epoch 7/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.3083 - acc: 0.9551\n",
      "Epoch 8/20\n",
      "30946/30946 [==============================] - 29s 951us/step - loss: 0.3062 - acc: 0.9510\n",
      "Epoch 9/20\n",
      "30946/30946 [==============================] - 31s 998us/step - loss: 0.3034 - acc: 0.9460\n",
      "Epoch 10/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.3019 - acc: 0.9436\n",
      "Epoch 11/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.3016 - acc: 0.9416\n",
      "Epoch 12/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.3015 - acc: 0.9366\n",
      "Epoch 13/20\n",
      "30946/30946 [==============================] - 29s 953us/step - loss: 0.2988 - acc: 0.9309\n",
      "Epoch 14/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.2976 - acc: 0.9307\n",
      "Epoch 15/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.2963 - acc: 0.9247\n",
      "Epoch 16/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.2983 - acc: 0.9230\n",
      "Epoch 17/20\n",
      "30946/30946 [==============================] - 30s 964us/step - loss: 0.2968 - acc: 0.9213\n",
      "Epoch 18/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.2947 - acc: 0.9176\n",
      "Epoch 19/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.2955 - acc: 0.9144\n",
      "Epoch 20/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.2964 - acc: 0.9118\n",
      "15472/15472 [==============================] - 14s 891us/step\n",
      "30946/30946 [==============================] - 22s 715us/step\n",
      "[CV] .................... epochs=20, lr=0.002, nodes=32, total=11.3min\n",
      "[CV] epochs=20, lr=0.002, nodes=64 ...................................\n",
      "Epoch 1/20\n",
      "30945/30945 [==============================] - 66s 2ms/step - loss: 0.3503 - acc: 0.9808\n",
      "Epoch 2/20\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3307 - acc: 0.9710\n",
      "Epoch 3/20\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3183 - acc: 0.9673\n",
      "Epoch 4/20\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3126 - acc: 0.9632\n",
      "Epoch 5/20\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3076 - acc: 0.9584\n",
      "Epoch 6/20\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3030 - acc: 0.9526\n",
      "Epoch 7/20\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3022 - acc: 0.9461\n",
      "Epoch 8/20\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.2989 - acc: 0.9391\n",
      "Epoch 9/20\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.2962 - acc: 0.9285\n",
      "Epoch 10/20\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.2947 - acc: 0.9281\n",
      "Epoch 11/20\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.2943 - acc: 0.9251\n",
      "Epoch 12/20\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.2941 - acc: 0.9225\n",
      "Epoch 13/20\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.2941 - acc: 0.9104\n",
      "Epoch 14/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.2932 - acc: 0.9192\n",
      "Epoch 15/20\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.2920 - acc: 0.9054\n",
      "Epoch 16/20\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.2942 - acc: 0.9048\n",
      "Epoch 17/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.2938 - acc: 0.9031\n",
      "Epoch 18/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.2954 - acc: 0.8965\n",
      "Epoch 19/20\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.2935 - acc: 0.8966\n",
      "Epoch 20/20\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.2947 - acc: 0.8883\n",
      "15473/15473 [==============================] - 15s 990us/step\n",
      "30945/30945 [==============================] - 26s 841us/step\n",
      "[CV] .................... epochs=20, lr=0.002, nodes=64, total=19.1min\n",
      "[CV] epochs=20, lr=0.002, nodes=64 ...................................\n",
      "Epoch 1/20\n",
      "30945/30945 [==============================] - 64s 2ms/step - loss: 0.3619 - acc: 0.9792\n",
      "Epoch 2/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3417 - acc: 0.9735\n",
      "Epoch 3/20\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.3320 - acc: 0.9696\n",
      "Epoch 4/20\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.3245 - acc: 0.9659\n",
      "Epoch 5/20\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.3203 - acc: 0.9582\n",
      "Epoch 6/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3147 - acc: 0.9580\n",
      "Epoch 7/20\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.3127 - acc: 0.9508\n",
      "Epoch 8/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3089 - acc: 0.9429\n",
      "Epoch 9/20\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.3069 - acc: 0.9376\n",
      "Epoch 10/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3068 - acc: 0.9350\n",
      "Epoch 11/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3058 - acc: 0.9329\n",
      "Epoch 12/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3046 - acc: 0.9270\n",
      "Epoch 13/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3044 - acc: 0.9193\n",
      "Epoch 14/20\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.3036 - acc: 0.9152\n",
      "Epoch 15/20\n",
      "30945/30945 [==============================] - 51s 2ms/step - loss: 0.3032 - acc: 0.9140\n",
      "Epoch 16/20\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.3036 - acc: 0.9099\n",
      "Epoch 17/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3060 - acc: 0.8989\n",
      "Epoch 18/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3024 - acc: 0.9024\n",
      "Epoch 19/20\n",
      "30945/30945 [==============================] - 51s 2ms/step - loss: 0.3062 - acc: 0.8947\n",
      "Epoch 20/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3020 - acc: 0.8902\n",
      "15473/15473 [==============================] - 14s 906us/step\n",
      "30945/30945 [==============================] - 24s 784us/step\n",
      "[CV] .................... epochs=20, lr=0.002, nodes=64, total=18.4min\n",
      "[CV] epochs=20, lr=0.002, nodes=64 ...................................\n",
      "Epoch 1/20\n",
      "30946/30946 [==============================] - 65s 2ms/step - loss: 0.3505 - acc: 0.9804\n",
      "Epoch 2/20\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3302 - acc: 0.9772\n",
      "Epoch 3/20\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.3214 - acc: 0.9717\n",
      "Epoch 4/20\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3159 - acc: 0.9665\n",
      "Epoch 5/20\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.3130 - acc: 0.9604\n",
      "Epoch 6/20\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.3072 - acc: 0.9569\n",
      "Epoch 7/20\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.3025 - acc: 0.9511\n",
      "Epoch 8/20\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.3008 - acc: 0.9466\n",
      "Epoch 9/20\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.2992 - acc: 0.9412\n",
      "Epoch 10/20\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.2965 - acc: 0.9361\n",
      "Epoch 11/20\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.2962 - acc: 0.9309\n",
      "Epoch 12/20\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.2947 - acc: 0.9266\n",
      "Epoch 13/20\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.2929 - acc: 0.9225\n",
      "Epoch 14/20\n",
      "30946/30946 [==============================] - 52s 2ms/step - loss: 0.2917 - acc: 0.9181\n",
      "Epoch 15/20\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.2920 - acc: 0.9129\n",
      "Epoch 16/20\n",
      "30946/30946 [==============================] - 50s 2ms/step - loss: 0.2927 - acc: 0.9125\n",
      "Epoch 17/20\n",
      "30946/30946 [==============================] - 52s 2ms/step - loss: 0.2923 - acc: 0.9028\n",
      "Epoch 18/20\n",
      "30946/30946 [==============================] - 52s 2ms/step - loss: 0.2917 - acc: 0.9020\n",
      "Epoch 19/20\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.2927 - acc: 0.8999\n",
      "Epoch 20/20\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.2910 - acc: 0.8946\n",
      "15472/15472 [==============================] - 14s 901us/step\n",
      "30946/30946 [==============================] - 26s 846us/step\n",
      "[CV] .................... epochs=20, lr=0.002, nodes=64, total=18.6min\n",
      "[CV] epochs=20, lr=0.003, nodes=16 ...................................\n",
      "Epoch 1/20\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3534 - acc: 0.9817\n",
      "Epoch 2/20\n",
      "30945/30945 [==============================] - 21s 687us/step - loss: 0.3372 - acc: 0.9798\n",
      "Epoch 3/20\n",
      "30945/30945 [==============================] - 21s 678us/step - loss: 0.3309 - acc: 0.9734\n",
      "Epoch 4/20\n",
      "30945/30945 [==============================] - 21s 674us/step - loss: 0.3255 - acc: 0.9716\n",
      "Epoch 5/20\n",
      "30945/30945 [==============================] - 21s 695us/step - loss: 0.3237 - acc: 0.9637\n",
      "Epoch 6/20\n",
      "30945/30945 [==============================] - 21s 694us/step - loss: 0.3204 - acc: 0.9613\n",
      "Epoch 7/20\n",
      "30945/30945 [==============================] - 21s 680us/step - loss: 0.3178 - acc: 0.9557\n",
      "Epoch 8/20\n",
      "30945/30945 [==============================] - 21s 693us/step - loss: 0.3157 - acc: 0.9505\n",
      "Epoch 9/20\n",
      "30945/30945 [==============================] - 21s 694us/step - loss: 0.3148 - acc: 0.9496\n",
      "Epoch 10/20\n",
      "30945/30945 [==============================] - 21s 688us/step - loss: 0.3136 - acc: 0.9396\n",
      "Epoch 11/20\n",
      "30945/30945 [==============================] - 21s 663us/step - loss: 0.3129 - acc: 0.9343\n",
      "Epoch 12/20\n",
      "30945/30945 [==============================] - 20s 660us/step - loss: 0.3111 - acc: 0.9279\n",
      "Epoch 13/20\n",
      "30945/30945 [==============================] - 20s 660us/step - loss: 0.3107 - acc: 0.9298\n",
      "Epoch 14/20\n",
      "30945/30945 [==============================] - 20s 652us/step - loss: 0.3093 - acc: 0.9271\n",
      "Epoch 15/20\n",
      "30945/30945 [==============================] - 21s 668us/step - loss: 0.3113 - acc: 0.9260\n",
      "Epoch 16/20\n",
      "30945/30945 [==============================] - 20s 662us/step - loss: 0.3103 - acc: 0.9202\n",
      "Epoch 17/20\n",
      "30945/30945 [==============================] - 21s 684us/step - loss: 0.3081 - acc: 0.9163\n",
      "Epoch 18/20\n",
      "30945/30945 [==============================] - 21s 682us/step - loss: 0.3107 - acc: 0.9155\n",
      "Epoch 19/20\n",
      "30945/30945 [==============================] - 21s 672us/step - loss: 0.3118 - acc: 0.9152\n",
      "Epoch 20/20\n",
      "30945/30945 [==============================] - 21s 672us/step - loss: 0.3101 - acc: 0.9093\n",
      "15473/15473 [==============================] - 13s 844us/step\n",
      "30945/30945 [==============================] - 23s 730us/step\n",
      "[CV] .................... epochs=20, lr=0.003, nodes=16, total= 8.0min\n",
      "[CV] epochs=20, lr=0.003, nodes=16 ...................................\n",
      "Epoch 1/20\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3641 - acc: 0.9802\n",
      "Epoch 2/20\n",
      "30945/30945 [==============================] - 22s 711us/step - loss: 0.3487 - acc: 0.9794\n",
      "Epoch 3/20\n",
      "30945/30945 [==============================] - 22s 702us/step - loss: 0.3433 - acc: 0.9722\n",
      "Epoch 4/20\n",
      "30945/30945 [==============================] - 22s 706us/step - loss: 0.3376 - acc: 0.9664\n",
      "Epoch 5/20\n",
      "30945/30945 [==============================] - 22s 709us/step - loss: 0.3380 - acc: 0.9650\n",
      "Epoch 6/20\n",
      "30945/30945 [==============================] - 22s 709us/step - loss: 0.3356 - acc: 0.9593\n",
      "Epoch 7/20\n",
      "30945/30945 [==============================] - 22s 708us/step - loss: 0.3316 - acc: 0.9510\n",
      "Epoch 8/20\n",
      "30945/30945 [==============================] - 22s 708us/step - loss: 0.3305 - acc: 0.9474\n",
      "Epoch 9/20\n",
      "30945/30945 [==============================] - 21s 691us/step - loss: 0.3295 - acc: 0.9500\n",
      "Epoch 10/20\n",
      "30945/30945 [==============================] - 21s 685us/step - loss: 0.3283 - acc: 0.9435\n",
      "Epoch 11/20\n",
      "30945/30945 [==============================] - 21s 688us/step - loss: 0.3271 - acc: 0.9394\n",
      "Epoch 12/20\n",
      "30945/30945 [==============================] - 22s 695us/step - loss: 0.3243 - acc: 0.9380\n",
      "Epoch 13/20\n",
      "30945/30945 [==============================] - 22s 696us/step - loss: 0.3233 - acc: 0.9388\n",
      "Epoch 14/20\n",
      "30945/30945 [==============================] - 21s 678us/step - loss: 0.3234 - acc: 0.9340\n",
      "Epoch 15/20\n",
      "30945/30945 [==============================] - 22s 707us/step - loss: 0.3217 - acc: 0.9300\n",
      "Epoch 16/20\n",
      "30945/30945 [==============================] - 22s 702us/step - loss: 0.3224 - acc: 0.9288\n",
      "Epoch 17/20\n",
      "30945/30945 [==============================] - 22s 695us/step - loss: 0.3223 - acc: 0.9208\n",
      "Epoch 18/20\n",
      "30945/30945 [==============================] - 21s 680us/step - loss: 0.3230 - acc: 0.9204\n",
      "Epoch 19/20\n",
      "30945/30945 [==============================] - 22s 709us/step - loss: 0.3205 - acc: 0.9201\n",
      "Epoch 20/20\n",
      "30945/30945 [==============================] - 22s 707us/step - loss: 0.3243 - acc: 0.9182\n",
      "15473/15473 [==============================] - 13s 870us/step\n",
      "30945/30945 [==============================] - 23s 737us/step\n",
      "[CV] .................... epochs=20, lr=0.003, nodes=16, total= 8.2min\n",
      "[CV] epochs=20, lr=0.003, nodes=16 ...................................\n",
      "Epoch 1/20\n",
      "30946/30946 [==============================] - 34s 1ms/step - loss: 0.3552 - acc: 0.9835\n",
      "Epoch 2/20\n",
      "30946/30946 [==============================] - 22s 699us/step - loss: 0.3387 - acc: 0.9815\n",
      "Epoch 3/20\n",
      "30946/30946 [==============================] - 21s 686us/step - loss: 0.3324 - acc: 0.9777\n",
      "Epoch 4/20\n",
      "30946/30946 [==============================] - 21s 686us/step - loss: 0.3275 - acc: 0.9735\n",
      "Epoch 5/20\n",
      "30946/30946 [==============================] - 21s 687us/step - loss: 0.3254 - acc: 0.9686\n",
      "Epoch 6/20\n",
      "30946/30946 [==============================] - 21s 684us/step - loss: 0.3241 - acc: 0.9659\n",
      "Epoch 7/20\n",
      "30946/30946 [==============================] - 21s 679us/step - loss: 0.3196 - acc: 0.9592\n",
      "Epoch 8/20\n",
      "30946/30946 [==============================] - 22s 701us/step - loss: 0.3198 - acc: 0.9534\n",
      "Epoch 9/20\n",
      "30946/30946 [==============================] - 21s 689us/step - loss: 0.3169 - acc: 0.9469\n",
      "Epoch 10/20\n",
      "30946/30946 [==============================] - 21s 688us/step - loss: 0.3169 - acc: 0.9497\n",
      "Epoch 11/20\n",
      "30946/30946 [==============================] - 21s 689us/step - loss: 0.3141 - acc: 0.9455\n",
      "Epoch 12/20\n",
      "30946/30946 [==============================] - 21s 689us/step - loss: 0.3123 - acc: 0.9409\n",
      "Epoch 13/20\n",
      "30946/30946 [==============================] - 21s 689us/step - loss: 0.3147 - acc: 0.9307\n",
      "Epoch 14/20\n",
      "30946/30946 [==============================] - 21s 683us/step - loss: 0.3131 - acc: 0.9316\n",
      "Epoch 15/20\n",
      "30946/30946 [==============================] - 21s 681us/step - loss: 0.3107 - acc: 0.9282\n",
      "Epoch 16/20\n",
      "30946/30946 [==============================] - 21s 679us/step - loss: 0.3119 - acc: 0.9304\n",
      "Epoch 17/20\n",
      "30946/30946 [==============================] - 21s 675us/step - loss: 0.3098 - acc: 0.9249\n",
      "Epoch 18/20\n",
      "30946/30946 [==============================] - 21s 691us/step - loss: 0.3087 - acc: 0.9205\n",
      "Epoch 19/20\n",
      "30946/30946 [==============================] - 21s 689us/step - loss: 0.3105 - acc: 0.9190\n",
      "Epoch 20/20\n",
      "30946/30946 [==============================] - 21s 689us/step - loss: 0.3064 - acc: 0.9067\n",
      "15472/15472 [==============================] - 13s 851us/step\n",
      "30946/30946 [==============================] - 23s 738us/step\n",
      "[CV] .................... epochs=20, lr=0.003, nodes=16, total= 8.1min\n",
      "[CV] epochs=20, lr=0.003, nodes=32 ...................................\n",
      "Epoch 1/20\n",
      "30945/30945 [==============================] - 43s 1ms/step - loss: 0.3514 - acc: 0.9831\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3359 - acc: 0.9762\n",
      "Epoch 3/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3267 - acc: 0.9721\n",
      "Epoch 4/20\n",
      "30945/30945 [==============================] - ETA: 0s - loss: 0.3212 - acc: 0.967 - 31s 1ms/step - loss: 0.3217 - acc: 0.9674\n",
      "Epoch 5/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3176 - acc: 0.9609\n",
      "Epoch 6/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3143 - acc: 0.9580\n",
      "Epoch 7/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3125 - acc: 0.9501\n",
      "Epoch 8/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3081 - acc: 0.9483\n",
      "Epoch 9/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3064 - acc: 0.9406\n",
      "Epoch 10/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3067 - acc: 0.9411\n",
      "Epoch 11/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3052 - acc: 0.9363\n",
      "Epoch 12/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3056 - acc: 0.9281\n",
      "Epoch 13/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3050 - acc: 0.9277\n",
      "Epoch 14/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3028 - acc: 0.9243\n",
      "Epoch 15/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3017 - acc: 0.9189\n",
      "Epoch 16/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3015 - acc: 0.9198\n",
      "Epoch 17/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3017 - acc: 0.9129\n",
      "Epoch 18/20\n",
      "30945/30945 [==============================] - 30s 958us/step - loss: 0.3032 - acc: 0.9100\n",
      "Epoch 19/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3028 - acc: 0.9031\n",
      "Epoch 20/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.2995 - acc: 0.9008\n",
      "15473/15473 [==============================] - 14s 889us/step\n",
      "30945/30945 [==============================] - 22s 724us/step\n",
      "[CV] .................... epochs=20, lr=0.003, nodes=32, total=11.5min\n",
      "[CV] epochs=20, lr=0.003, nodes=32 ...................................\n",
      "Epoch 1/20\n",
      "30945/30945 [==============================] - 46s 1ms/step - loss: 0.3612 - acc: 0.9805\n",
      "Epoch 2/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3440 - acc: 0.9782\n",
      "Epoch 3/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3364 - acc: 0.9723\n",
      "Epoch 4/20\n",
      "30945/30945 [==============================] - 31s 988us/step - loss: 0.3318 - acc: 0.9677\n",
      "Epoch 5/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3265 - acc: 0.9628\n",
      "Epoch 6/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3235 - acc: 0.9592\n",
      "Epoch 7/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3213 - acc: 0.9491\n",
      "Epoch 8/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3185 - acc: 0.9408\n",
      "Epoch 9/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3181 - acc: 0.9402\n",
      "Epoch 10/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3163 - acc: 0.9360\n",
      "Epoch 11/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3157 - acc: 0.9301\n",
      "Epoch 12/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3141 - acc: 0.9258\n",
      "Epoch 13/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3154 - acc: 0.9197\n",
      "Epoch 14/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3123 - acc: 0.9160\n",
      "Epoch 15/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3141 - acc: 0.9131\n",
      "Epoch 16/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3128 - acc: 0.9051\n",
      "Epoch 17/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3115 - acc: 0.9013\n",
      "Epoch 18/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3103 - acc: 0.9000\n",
      "Epoch 19/20\n",
      "30945/30945 [==============================] - 27s 868us/step - loss: 0.3139 - acc: 0.8929\n",
      "Epoch 20/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3120 - acc: 0.8971\n",
      "15473/15473 [==============================] - 14s 905us/step\n",
      "30945/30945 [==============================] - 24s 782us/step\n",
      "[CV] .................... epochs=20, lr=0.003, nodes=32, total=11.4min\n",
      "[CV] epochs=20, lr=0.003, nodes=32 ...................................\n",
      "Epoch 1/20\n",
      "30946/30946 [==============================] - 43s 1ms/step - loss: 0.3532 - acc: 0.9820\n",
      "Epoch 2/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.3339 - acc: 0.9769\n",
      "Epoch 3/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.3254 - acc: 0.9724\n",
      "Epoch 4/20\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3198 - acc: 0.9650\n",
      "Epoch 5/20\n",
      "30946/30946 [==============================] - 37s 1ms/step - loss: 0.3150 - acc: 0.9600\n",
      "Epoch 6/20\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3115 - acc: 0.9567\n",
      "Epoch 7/20\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3130 - acc: 0.9529\n",
      "Epoch 8/20\n",
      "30946/30946 [==============================] - 35s 1ms/step - loss: 0.3099 - acc: 0.9469\n",
      "Epoch 9/20\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3082 - acc: 0.9419\n",
      "Epoch 10/20\n",
      "30946/30946 [==============================] - 35s 1ms/step - loss: 0.3077 - acc: 0.9355\n",
      "Epoch 11/20\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3043 - acc: 0.9299\n",
      "Epoch 12/20\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3032 - acc: 0.9292\n",
      "Epoch 13/20\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3041 - acc: 0.9225\n",
      "Epoch 14/20\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3039 - acc: 0.9148\n",
      "Epoch 15/20\n",
      "30946/30946 [==============================] - 35s 1ms/step - loss: 0.3034 - acc: 0.9162\n",
      "Epoch 16/20\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3026 - acc: 0.9020\n",
      "Epoch 17/20\n",
      "30946/30946 [==============================] - 37s 1ms/step - loss: 0.3026 - acc: 0.9072\n",
      "Epoch 18/20\n",
      "30946/30946 [==============================] - 38s 1ms/step - loss: 0.3009 - acc: 0.9005\n",
      "Epoch 19/20\n",
      "30946/30946 [==============================] - 37s 1ms/step - loss: 0.2988 - acc: 0.8981\n",
      "Epoch 20/20\n",
      "30946/30946 [==============================] - 39s 1ms/step - loss: 0.2978 - acc: 0.8928\n",
      "15472/15472 [==============================] - 17s 1ms/step\n",
      "30946/30946 [==============================] - 25s 804us/step\n",
      "[CV] .................... epochs=20, lr=0.003, nodes=32, total=12.8min\n",
      "[CV] epochs=20, lr=0.003, nodes=64 ...................................\n",
      "Epoch 1/20\n",
      "30945/30945 [==============================] - 75s 2ms/step - loss: 0.3511 - acc: 0.9769\n",
      "Epoch 2/20\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.3313 - acc: 0.9749\n",
      "Epoch 3/20\n",
      "30945/30945 [==============================] - 61s 2ms/step - loss: 0.3223 - acc: 0.9685\n",
      "Epoch 4/20\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.3155 - acc: 0.9594\n",
      "Epoch 5/20\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.3093 - acc: 0.9550\n",
      "Epoch 6/20\n",
      "30945/30945 [==============================] - 61s 2ms/step - loss: 0.3061 - acc: 0.9534\n",
      "Epoch 7/20\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.3044 - acc: 0.9452\n",
      "Epoch 8/20\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.3027 - acc: 0.9398\n",
      "Epoch 9/20\n",
      "30945/30945 [==============================] - 61s 2ms/step - loss: 0.3000 - acc: 0.9310: 0s - loss: 0.3001 - \n",
      "Epoch 10/20\n",
      "30945/30945 [==============================] - 61s 2ms/step - loss: 0.2994 - acc: 0.9298\n",
      "Epoch 11/20\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.3012 - acc: 0.9284\n",
      "Epoch 12/20\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.3000 - acc: 0.9210\n",
      "Epoch 13/20\n",
      "30945/30945 [==============================] - 64s 2ms/step - loss: 0.3007 - acc: 0.9186\n",
      "Epoch 14/20\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.3006 - acc: 0.9185\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30945/30945 [==============================] - 68s 2ms/step - loss: 0.3018 - acc: 0.9026\n",
      "Epoch 16/20\n",
      "30945/30945 [==============================] - 66s 2ms/step - loss: 0.2999 - acc: 0.9020\n",
      "Epoch 17/20\n",
      "30945/30945 [==============================] - 65s 2ms/step - loss: 0.3019 - acc: 0.9033\n",
      "Epoch 18/20\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.3028 - acc: 0.8954\n",
      "Epoch 19/20\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.3009 - acc: 0.8938\n",
      "Epoch 20/20\n",
      "30945/30945 [==============================] - 67s 2ms/step - loss: 0.3023 - acc: 0.8908\n",
      "15473/15473 [==============================] - 14s 934us/step\n",
      "30945/30945 [==============================] - 26s 837us/step\n",
      "[CV] .................... epochs=20, lr=0.003, nodes=64, total=22.0min\n",
      "[CV] epochs=20, lr=0.003, nodes=64 ...................................\n",
      "Epoch 1/20\n",
      "30945/30945 [==============================] - 70s 2ms/step - loss: 0.3607 - acc: 0.9771\n",
      "Epoch 2/20\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3423 - acc: 0.9740\n",
      "Epoch 3/20\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3346 - acc: 0.9677\n",
      "Epoch 4/20\n",
      "30945/30945 [==============================] - 61s 2ms/step - loss: 0.3271 - acc: 0.9604\n",
      "Epoch 5/20\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.3223 - acc: 0.9555\n",
      "Epoch 6/20\n",
      "30945/30945 [==============================] - 59s 2ms/step - loss: 0.3178 - acc: 0.9451\n",
      "Epoch 7/20\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3158 - acc: 0.9417\n",
      "Epoch 8/20\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3129 - acc: 0.9295\n",
      "Epoch 9/20\n",
      "30945/30945 [==============================] - 60s 2ms/step - loss: 0.3124 - acc: 0.9328\n",
      "Epoch 10/20\n",
      "30945/30945 [==============================] - 58s 2ms/step - loss: 0.3086 - acc: 0.9262\n",
      "Epoch 11/20\n",
      "30945/30945 [==============================] - 58s 2ms/step - loss: 0.3100 - acc: 0.9251\n",
      "Epoch 12/20\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3094 - acc: 0.9232\n",
      "Epoch 13/20\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3067 - acc: 0.9151\n",
      "Epoch 14/20\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3113 - acc: 0.9072\n",
      "Epoch 15/20\n",
      "30945/30945 [==============================] - 58s 2ms/step - loss: 0.3076 - acc: 0.9105\n",
      "Epoch 16/20\n",
      "30945/30945 [==============================] - 58s 2ms/step - loss: 0.3077 - acc: 0.9047\n",
      "Epoch 17/20\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3079 - acc: 0.9012\n",
      "Epoch 18/20\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3087 - acc: 0.8971\n",
      "Epoch 19/20\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3064 - acc: 0.8968\n",
      "Epoch 20/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3098 - acc: 0.8919\n",
      "15473/15473 [==============================] - 14s 908us/step\n",
      "30945/30945 [==============================] - 24s 788us/step\n",
      "[CV] .................... epochs=20, lr=0.003, nodes=64, total=20.1min\n",
      "[CV] epochs=20, lr=0.003, nodes=64 ...................................\n",
      "Epoch 1/20\n",
      "30946/30946 [==============================] - 65s 2ms/step - loss: 0.3489 - acc: 0.9812\n",
      "Epoch 2/20\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.3297 - acc: 0.9710\n",
      "Epoch 3/20\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3224 - acc: 0.9671\n",
      "Epoch 4/20\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3166 - acc: 0.9576\n",
      "Epoch 5/20\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.3102 - acc: 0.9504\n",
      "Epoch 6/20\n",
      "30946/30946 [==============================] - 57s 2ms/step - loss: 0.3086 - acc: 0.9457\n",
      "Epoch 7/20\n",
      "30946/30946 [==============================] - 56s 2ms/step - loss: 0.3041 - acc: 0.9406\n",
      "Epoch 8/20\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.3017 - acc: 0.9320\n",
      "Epoch 9/20\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.3016 - acc: 0.9317\n",
      "Epoch 10/20\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.3029 - acc: 0.9277\n",
      "Epoch 11/20\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.3012 - acc: 0.9211\n",
      "Epoch 12/20\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3006 - acc: 0.9196\n",
      "Epoch 13/20\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.3013 - acc: 0.9125\n",
      "Epoch 14/20\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.3028 - acc: 0.9040\n",
      "Epoch 15/20\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2992 - acc: 0.9040\n",
      "Epoch 16/20\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.3034 - acc: 0.9010\n",
      "Epoch 17/20\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2996 - acc: 0.8967\n",
      "Epoch 18/20\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3008 - acc: 0.8943\n",
      "Epoch 19/20\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.3018 - acc: 0.8923\n",
      "Epoch 20/20\n",
      "30946/30946 [==============================] - 52s 2ms/step - loss: 0.3003 - acc: 0.8926\n",
      "15472/15472 [==============================] - 14s 908us/step\n",
      "30946/30946 [==============================] - 26s 854us/step\n",
      "[CV] .................... epochs=20, lr=0.003, nodes=64, total=19.2min\n",
      "[CV] epochs=30, lr=0.001, nodes=16 ...................................\n",
      "Epoch 1/30\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.3703 - acc: 0.9533\n",
      "Epoch 2/30\n",
      "30945/30945 [==============================] - 24s 767us/step - loss: 0.3458 - acc: 0.9824\n",
      "Epoch 3/30\n",
      "30945/30945 [==============================] - 23s 748us/step - loss: 0.3388 - acc: 0.9815\n",
      "Epoch 4/30\n",
      "30945/30945 [==============================] - 23s 747us/step - loss: 0.3348 - acc: 0.9794\n",
      "Epoch 5/30\n",
      "30945/30945 [==============================] - 23s 749us/step - loss: 0.3346 - acc: 0.9779\n",
      "Epoch 6/30\n",
      "30945/30945 [==============================] - 23s 752us/step - loss: 0.3312 - acc: 0.9756\n",
      "Epoch 7/30\n",
      "30945/30945 [==============================] - 23s 753us/step - loss: 0.3293 - acc: 0.9741\n",
      "Epoch 8/30\n",
      "30945/30945 [==============================] - 23s 734us/step - loss: 0.3275 - acc: 0.9712\n",
      "Epoch 9/30\n",
      "30945/30945 [==============================] - 23s 740us/step - loss: 0.3256 - acc: 0.9688\n",
      "Epoch 10/30\n",
      "30945/30945 [==============================] - 23s 742us/step - loss: 0.3222 - acc: 0.9665\n",
      "Epoch 11/30\n",
      "30945/30945 [==============================] - 23s 735us/step - loss: 0.3208 - acc: 0.9590\n",
      "Epoch 12/30\n",
      "30945/30945 [==============================] - 23s 738us/step - loss: 0.3211 - acc: 0.9555\n",
      "Epoch 13/30\n",
      "30945/30945 [==============================] - 23s 750us/step - loss: 0.3190 - acc: 0.9587\n",
      "Epoch 14/30\n",
      "30945/30945 [==============================] - 23s 748us/step - loss: 0.3152 - acc: 0.9538\n",
      "Epoch 15/30\n",
      "30945/30945 [==============================] - 23s 744us/step - loss: 0.3161 - acc: 0.9534\n",
      "Epoch 16/30\n",
      "30945/30945 [==============================] - 23s 744us/step - loss: 0.3150 - acc: 0.9488\n",
      "Epoch 17/30\n",
      "30945/30945 [==============================] - 23s 746us/step - loss: 0.3128 - acc: 0.9461\n",
      "Epoch 18/30\n",
      "30945/30945 [==============================] - 23s 743us/step - loss: 0.3123 - acc: 0.9457\n",
      "Epoch 19/30\n",
      "30945/30945 [==============================] - 23s 730us/step - loss: 0.3095 - acc: 0.9430\n",
      "Epoch 20/30\n",
      "30945/30945 [==============================] - 23s 755us/step - loss: 0.3095 - acc: 0.9463\n",
      "Epoch 21/30\n",
      "30945/30945 [==============================] - 23s 745us/step - loss: 0.3095 - acc: 0.9434\n",
      "Epoch 22/30\n",
      "30945/30945 [==============================] - 23s 746us/step - loss: 0.3075 - acc: 0.9419\n",
      "Epoch 23/30\n",
      "30945/30945 [==============================] - 23s 738us/step - loss: 0.3072 - acc: 0.9345\n",
      "Epoch 24/30\n",
      "30945/30945 [==============================] - 23s 747us/step - loss: 0.3059 - acc: 0.9332\n",
      "Epoch 25/30\n",
      "30945/30945 [==============================] - 23s 742us/step - loss: 0.3067 - acc: 0.9308\n",
      "Epoch 26/30\n",
      "30945/30945 [==============================] - 23s 747us/step - loss: 0.3074 - acc: 0.9319\n",
      "Epoch 27/30\n",
      "30945/30945 [==============================] - 23s 743us/step - loss: 0.3062 - acc: 0.9291\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30945/30945 [==============================] - 23s 752us/step - loss: 0.3055 - acc: 0.9248\n",
      "Epoch 29/30\n",
      "30945/30945 [==============================] - 23s 740us/step - loss: 0.3047 - acc: 0.9277\n",
      "Epoch 30/30\n",
      "30945/30945 [==============================] - 23s 753us/step - loss: 0.3047 - acc: 0.9231\n",
      "15473/15473 [==============================] - 13s 858us/step\n",
      "30945/30945 [==============================] - 21s 692us/step\n",
      "[CV] .................... epochs=30, lr=0.001, nodes=16, total=12.5min\n",
      "[CV] epochs=30, lr=0.001, nodes=16 ...................................\n",
      "Epoch 1/30\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.3806 - acc: 0.9364\n",
      "Epoch 2/30\n",
      "30945/30945 [==============================] - 23s 737us/step - loss: 0.3550 - acc: 0.9847\n",
      "Epoch 3/30\n",
      "30945/30945 [==============================] - 23s 741us/step - loss: 0.3481 - acc: 0.9829\n",
      "Epoch 4/30\n",
      "30945/30945 [==============================] - 23s 741us/step - loss: 0.3434 - acc: 0.9805\n",
      "Epoch 5/30\n",
      "30945/30945 [==============================] - 23s 745us/step - loss: 0.3398 - acc: 0.9776\n",
      "Epoch 6/30\n",
      "30945/30945 [==============================] - 24s 765us/step - loss: 0.3361 - acc: 0.9750\n",
      "Epoch 7/30\n",
      "30945/30945 [==============================] - 24s 768us/step - loss: 0.3321 - acc: 0.9733\n",
      "Epoch 8/30\n",
      "30945/30945 [==============================] - 23s 756us/step - loss: 0.3299 - acc: 0.9693\n",
      "Epoch 9/30\n",
      "30945/30945 [==============================] - 23s 759us/step - loss: 0.3277 - acc: 0.9693\n",
      "Epoch 10/30\n",
      "30945/30945 [==============================] - 23s 748us/step - loss: 0.3267 - acc: 0.9660\n",
      "Epoch 11/30\n",
      "30945/30945 [==============================] - 23s 740us/step - loss: 0.3251 - acc: 0.9658\n",
      "Epoch 12/30\n",
      "30945/30945 [==============================] - 23s 745us/step - loss: 0.3246 - acc: 0.9624\n",
      "Epoch 13/30\n",
      "30945/30945 [==============================] - 23s 745us/step - loss: 0.3225 - acc: 0.9614\n",
      "Epoch 14/30\n",
      "30945/30945 [==============================] - 23s 739us/step - loss: 0.3209 - acc: 0.9567\n",
      "Epoch 15/30\n",
      "30945/30945 [==============================] - 23s 750us/step - loss: 0.3200 - acc: 0.9572\n",
      "Epoch 16/30\n",
      "30945/30945 [==============================] - 23s 752us/step - loss: 0.3184 - acc: 0.9559\n",
      "Epoch 17/30\n",
      "30945/30945 [==============================] - 23s 740us/step - loss: 0.3176 - acc: 0.9514\n",
      "Epoch 18/30\n",
      "30945/30945 [==============================] - 23s 737us/step - loss: 0.3161 - acc: 0.9489\n",
      "Epoch 19/30\n",
      "30945/30945 [==============================] - 23s 744us/step - loss: 0.3158 - acc: 0.9496\n",
      "Epoch 20/30\n",
      "30945/30945 [==============================] - 23s 731us/step - loss: 0.3148 - acc: 0.9470\n",
      "Epoch 21/30\n",
      "30945/30945 [==============================] - 22s 719us/step - loss: 0.3140 - acc: 0.9468\n",
      "Epoch 22/30\n",
      "30945/30945 [==============================] - 22s 723us/step - loss: 0.3150 - acc: 0.9448\n",
      "Epoch 23/30\n",
      "30945/30945 [==============================] - 22s 722us/step - loss: 0.3132 - acc: 0.9404\n",
      "Epoch 24/30\n",
      "30945/30945 [==============================] - 23s 728us/step - loss: 0.3134 - acc: 0.9391\n",
      "Epoch 25/30\n",
      "30945/30945 [==============================] - 23s 730us/step - loss: 0.3130 - acc: 0.9386\n",
      "Epoch 26/30\n",
      "30945/30945 [==============================] - 22s 718us/step - loss: 0.3105 - acc: 0.9331\n",
      "Epoch 27/30\n",
      "30945/30945 [==============================] - 23s 736us/step - loss: 0.3125 - acc: 0.9342\n",
      "Epoch 28/30\n",
      "30945/30945 [==============================] - 23s 747us/step - loss: 0.3112 - acc: 0.9329\n",
      "Epoch 29/30\n",
      "30945/30945 [==============================] - 23s 731us/step - loss: 0.3134 - acc: 0.9312\n",
      "Epoch 30/30\n",
      "30945/30945 [==============================] - 23s 744us/step - loss: 0.3116 - acc: 0.9337\n",
      "15473/15473 [==============================] - 14s 906us/step\n",
      "30945/30945 [==============================] - 21s 691us/step\n",
      "[CV] .................... epochs=30, lr=0.001, nodes=16, total=12.5min\n",
      "[CV] epochs=30, lr=0.001, nodes=16 ...................................\n",
      "Epoch 1/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3684 - acc: 0.9716\n",
      "Epoch 2/30\n",
      "30946/30946 [==============================] - 22s 724us/step - loss: 0.3425 - acc: 0.9813\n",
      "Epoch 3/30\n",
      "30946/30946 [==============================] - 23s 728us/step - loss: 0.3364 - acc: 0.9801\n",
      "Epoch 4/30\n",
      "30946/30946 [==============================] - 23s 727us/step - loss: 0.3331 - acc: 0.9775\n",
      "Epoch 5/30\n",
      "30946/30946 [==============================] - 22s 707us/step - loss: 0.3292 - acc: 0.9737\n",
      "Epoch 6/30\n",
      "30946/30946 [==============================] - 22s 715us/step - loss: 0.3278 - acc: 0.9712\n",
      "Epoch 7/30\n",
      "30946/30946 [==============================] - 22s 716us/step - loss: 0.3262 - acc: 0.9677\n",
      "Epoch 8/30\n",
      "30946/30946 [==============================] - 22s 703us/step - loss: 0.3217 - acc: 0.9640\n",
      "Epoch 9/30\n",
      "30946/30946 [==============================] - 22s 710us/step - loss: 0.3198 - acc: 0.9614\n",
      "Epoch 10/30\n",
      "30946/30946 [==============================] - 22s 708us/step - loss: 0.3183 - acc: 0.9596\n",
      "Epoch 11/30\n",
      "30946/30946 [==============================] - 22s 703us/step - loss: 0.3178 - acc: 0.9537\n",
      "Epoch 12/30\n",
      "30946/30946 [==============================] - 22s 697us/step - loss: 0.3157 - acc: 0.9568\n",
      "Epoch 13/30\n",
      "30946/30946 [==============================] - 22s 717us/step - loss: 0.3148 - acc: 0.9514\n",
      "Epoch 14/30\n",
      "30946/30946 [==============================] - 23s 743us/step - loss: 0.3124 - acc: 0.9512\n",
      "Epoch 15/30\n",
      "30946/30946 [==============================] - 22s 723us/step - loss: 0.3111 - acc: 0.9488\n",
      "Epoch 16/30\n",
      "30946/30946 [==============================] - 22s 725us/step - loss: 0.3110 - acc: 0.9501\n",
      "Epoch 17/30\n",
      "30946/30946 [==============================] - 22s 699us/step - loss: 0.3100 - acc: 0.9453\n",
      "Epoch 18/30\n",
      "30946/30946 [==============================] - 22s 700us/step - loss: 0.3087 - acc: 0.9465\n",
      "Epoch 19/30\n",
      "30946/30946 [==============================] - 22s 703us/step - loss: 0.3078 - acc: 0.9453\n",
      "Epoch 20/30\n",
      "30946/30946 [==============================] - 21s 681us/step - loss: 0.3074 - acc: 0.9377\n",
      "Epoch 21/30\n",
      "30946/30946 [==============================] - 21s 687us/step - loss: 0.3063 - acc: 0.9409\n",
      "Epoch 22/30\n",
      "30946/30946 [==============================] - 21s 688us/step - loss: 0.3046 - acc: 0.9355\n",
      "Epoch 23/30\n",
      "30946/30946 [==============================] - 21s 683us/step - loss: 0.3041 - acc: 0.9329\n",
      "Epoch 24/30\n",
      "30946/30946 [==============================] - 21s 688us/step - loss: 0.3050 - acc: 0.9368\n",
      "Epoch 25/30\n",
      "30946/30946 [==============================] - 22s 704us/step - loss: 0.3039 - acc: 0.9313\n",
      "Epoch 26/30\n",
      "30946/30946 [==============================] - 22s 704us/step - loss: 0.3026 - acc: 0.9275\n",
      "Epoch 27/30\n",
      "30946/30946 [==============================] - 22s 699us/step - loss: 0.3026 - acc: 0.9225\n",
      "Epoch 28/30\n",
      "30946/30946 [==============================] - 22s 704us/step - loss: 0.3022 - acc: 0.9193\n",
      "Epoch 29/30\n",
      "30946/30946 [==============================] - 22s 701us/step - loss: 0.3030 - acc: 0.9205\n",
      "Epoch 30/30\n",
      "30946/30946 [==============================] - 22s 714us/step - loss: 0.3023 - acc: 0.9172\n",
      "15472/15472 [==============================] - 14s 925us/step\n",
      "30946/30946 [==============================] - 25s 809us/step\n",
      "[CV] .................... epochs=30, lr=0.001, nodes=16, total=12.0min\n",
      "[CV] epochs=30, lr=0.001, nodes=32 ...................................\n",
      "Epoch 1/30\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.3592 - acc: 0.9794\n",
      "Epoch 2/30\n",
      "30945/30945 [==============================] - 38s 1ms/step - loss: 0.3372 - acc: 0.9800\n",
      "Epoch 3/30\n",
      "30945/30945 [==============================] - 38s 1ms/step - loss: 0.3301 - acc: 0.9756\n",
      "Epoch 4/30\n",
      "30945/30945 [==============================] - 39s 1ms/step - loss: 0.3241 - acc: 0.9742\n",
      "Epoch 5/30\n",
      "30945/30945 [==============================] - 38s 1ms/step - loss: 0.3202 - acc: 0.9705\n",
      "Epoch 6/30\n",
      "30945/30945 [==============================] - 38s 1ms/step - loss: 0.3165 - acc: 0.9682\n",
      "Epoch 7/30\n",
      "30945/30945 [==============================] - 38s 1ms/step - loss: 0.3115 - acc: 0.9636\n",
      "Epoch 8/30\n",
      "30945/30945 [==============================] - 38s 1ms/step - loss: 0.3092 - acc: 0.9614\n",
      "Epoch 9/30\n",
      "30945/30945 [==============================] - 38s 1ms/step - loss: 0.3076 - acc: 0.9607\n",
      "Epoch 10/30\n",
      "30945/30945 [==============================] - 38s 1ms/step - loss: 0.3046 - acc: 0.9568\n",
      "Epoch 11/30\n",
      "30945/30945 [==============================] - 38s 1ms/step - loss: 0.3025 - acc: 0.9541\n",
      "Epoch 12/30\n",
      "30945/30945 [==============================] - 38s 1ms/step - loss: 0.3017 - acc: 0.9512\n",
      "Epoch 13/30\n",
      "30945/30945 [==============================] - 39s 1ms/step - loss: 0.2992 - acc: 0.9471\n",
      "Epoch 14/30\n",
      "30945/30945 [==============================] - 39s 1ms/step - loss: 0.2986 - acc: 0.9430\n",
      "Epoch 15/30\n",
      "30945/30945 [==============================] - 40s 1ms/step - loss: 0.2980 - acc: 0.9431\n",
      "Epoch 16/30\n",
      "30945/30945 [==============================] - 39s 1ms/step - loss: 0.2967 - acc: 0.9419\n",
      "Epoch 17/30\n",
      "30945/30945 [==============================] - 41s 1ms/step - loss: 0.2968 - acc: 0.9347\n",
      "Epoch 18/30\n",
      "30945/30945 [==============================] - 38s 1ms/step - loss: 0.2938 - acc: 0.9355\n",
      "Epoch 19/30\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.2938 - acc: 0.9360\n",
      "Epoch 20/30\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.2934 - acc: 0.9286\n",
      "Epoch 21/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.2920 - acc: 0.9283\n",
      "Epoch 22/30\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.2926 - acc: 0.9247\n",
      "Epoch 23/30\n",
      "30945/30945 [==============================] - 38s 1ms/step - loss: 0.2911 - acc: 0.9210\n",
      "Epoch 24/30\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.2912 - acc: 0.9160\n",
      "Epoch 25/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.2902 - acc: 0.9179\n",
      "Epoch 26/30\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.2897 - acc: 0.9111\n",
      "Epoch 27/30\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.2923 - acc: 0.9107\n",
      "Epoch 28/30\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.2921 - acc: 0.9074\n",
      "Epoch 29/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.2894 - acc: 0.9030\n",
      "Epoch 30/30\n",
      "30945/30945 [==============================] - 39s 1ms/step - loss: 0.2897 - acc: 0.8993\n",
      "15473/15473 [==============================] - 16s 1ms/step\n",
      "30945/30945 [==============================] - 25s 816us/step\n",
      "[CV] .................... epochs=30, lr=0.001, nodes=32, total=20.0min\n",
      "[CV] epochs=30, lr=0.001, nodes=32 ...................................\n",
      "Epoch 1/30\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3691 - acc: 0.9816\n",
      "Epoch 2/30\n",
      "30945/30945 [==============================] - 41s 1ms/step - loss: 0.3494 - acc: 0.9783\n",
      "Epoch 3/30\n",
      "30945/30945 [==============================] - 38s 1ms/step - loss: 0.3397 - acc: 0.9770\n",
      "Epoch 4/30\n",
      "30945/30945 [==============================] - 39s 1ms/step - loss: 0.3358 - acc: 0.9745\n",
      "Epoch 5/30\n",
      "30945/30945 [==============================] - 40s 1ms/step - loss: 0.3298 - acc: 0.9702\n",
      "Epoch 6/30\n",
      "30945/30945 [==============================] - 41s 1ms/step - loss: 0.3266 - acc: 0.9671\n",
      "Epoch 7/30\n",
      "30945/30945 [==============================] - 41s 1ms/step - loss: 0.3241 - acc: 0.9630\n",
      "Epoch 8/30\n",
      "30945/30945 [==============================] - 39s 1ms/step - loss: 0.3212 - acc: 0.9624\n",
      "Epoch 9/30\n",
      "30945/30945 [==============================] - 40s 1ms/step - loss: 0.3175 - acc: 0.9575\n",
      "Epoch 10/30\n",
      "30945/30945 [==============================] - 40s 1ms/step - loss: 0.3156 - acc: 0.9548\n",
      "Epoch 11/30\n",
      "30945/30945 [==============================] - 40s 1ms/step - loss: 0.3134 - acc: 0.9549\n",
      "Epoch 12/30\n",
      "30945/30945 [==============================] - 40s 1ms/step - loss: 0.3120 - acc: 0.9480\n",
      "Epoch 13/30\n",
      "30945/30945 [==============================] - 39s 1ms/step - loss: 0.3103 - acc: 0.9466\n",
      "Epoch 14/30\n",
      "30945/30945 [==============================] - 41s 1ms/step - loss: 0.3071 - acc: 0.9398\n",
      "Epoch 15/30\n",
      "30945/30945 [==============================] - 40s 1ms/step - loss: 0.3053 - acc: 0.9393\n",
      "Epoch 16/30\n",
      "30945/30945 [==============================] - 40s 1ms/step - loss: 0.3061 - acc: 0.9336\n",
      "Epoch 17/30\n",
      "30945/30945 [==============================] - 40s 1ms/step - loss: 0.3045 - acc: 0.9348\n",
      "Epoch 18/30\n",
      "30945/30945 [==============================] - 40s 1ms/step - loss: 0.3044 - acc: 0.9303\n",
      "Epoch 19/30\n",
      "30945/30945 [==============================] - 41s 1ms/step - loss: 0.3041 - acc: 0.9289\n",
      "Epoch 20/30\n",
      "30945/30945 [==============================] - 40s 1ms/step - loss: 0.3033 - acc: 0.9271\n",
      "Epoch 21/30\n",
      "30945/30945 [==============================] - 40s 1ms/step - loss: 0.3013 - acc: 0.9266\n",
      "Epoch 22/30\n",
      "30945/30945 [==============================] - 41s 1ms/step - loss: 0.3015 - acc: 0.9235\n",
      "Epoch 23/30\n",
      "30945/30945 [==============================] - 41s 1ms/step - loss: 0.3010 - acc: 0.9190\n",
      "Epoch 24/30\n",
      "30945/30945 [==============================] - 40s 1ms/step - loss: 0.3008 - acc: 0.9109\n",
      "Epoch 25/30\n",
      "30945/30945 [==============================] - 40s 1ms/step - loss: 0.3005 - acc: 0.9092\n",
      "Epoch 26/30\n",
      "30945/30945 [==============================] - 40s 1ms/step - loss: 0.2995 - acc: 0.9160\n",
      "Epoch 27/30\n",
      "30945/30945 [==============================] - 40s 1ms/step - loss: 0.3019 - acc: 0.9118\n",
      "Epoch 28/30\n",
      "30945/30945 [==============================] - 41s 1ms/step - loss: 0.3008 - acc: 0.9105\n",
      "Epoch 29/30\n",
      "30945/30945 [==============================] - 40s 1ms/step - loss: 0.3004 - acc: 0.9065\n",
      "Epoch 30/30\n",
      "30945/30945 [==============================] - 40s 1ms/step - loss: 0.3010 - acc: 0.9010\n",
      "15473/15473 [==============================] - 17s 1ms/step\n",
      "30945/30945 [==============================] - 25s 808us/step\n",
      "[CV] .................... epochs=30, lr=0.001, nodes=32, total=21.2min\n",
      "[CV] epochs=30, lr=0.001, nodes=32 ...................................\n",
      "Epoch 1/30\n",
      "30946/30946 [==============================] - 49s 2ms/step - loss: 0.3587 - acc: 0.9812\n",
      "Epoch 2/30\n",
      "30946/30946 [==============================] - 37s 1ms/step - loss: 0.3391 - acc: 0.9802\n",
      "Epoch 3/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3324 - acc: 0.9789\n",
      "Epoch 4/30\n",
      "30946/30946 [==============================] - 37s 1ms/step - loss: 0.3255 - acc: 0.9783\n",
      "Epoch 5/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3217 - acc: 0.9725\n",
      "Epoch 6/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3177 - acc: 0.9710\n",
      "Epoch 7/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3138 - acc: 0.9669\n",
      "Epoch 8/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3123 - acc: 0.9621\n",
      "Epoch 9/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3095 - acc: 0.9595\n",
      "Epoch 10/30\n",
      "30946/30946 [==============================] - 35s 1ms/step - loss: 0.3089 - acc: 0.9561\n",
      "Epoch 11/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3061 - acc: 0.9519\n",
      "Epoch 12/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3034 - acc: 0.9499\n",
      "Epoch 13/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3048 - acc: 0.9446\n",
      "Epoch 14/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3030 - acc: 0.9418\n",
      "Epoch 15/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3010 - acc: 0.9367\n",
      "Epoch 16/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2986 - acc: 0.9351\n",
      "Epoch 17/30\n",
      "30946/30946 [==============================] - 38s 1ms/step - loss: 0.2998 - acc: 0.9360\n",
      "Epoch 18/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2975 - acc: 0.9352\n",
      "Epoch 19/30\n",
      "30946/30946 [==============================] - 38s 1ms/step - loss: 0.2972 - acc: 0.9281\n",
      "Epoch 20/30\n",
      "30946/30946 [==============================] - 37s 1ms/step - loss: 0.2961 - acc: 0.9254\n",
      "Epoch 21/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2942 - acc: 0.9244\n",
      "Epoch 22/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2955 - acc: 0.9215\n",
      "Epoch 23/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2928 - acc: 0.9177\n",
      "Epoch 24/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2928 - acc: 0.9144\n",
      "Epoch 25/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2920 - acc: 0.9110\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2913 - acc: 0.9141\n",
      "Epoch 27/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2918 - acc: 0.9088\n",
      "Epoch 28/30\n",
      "30946/30946 [==============================] - 37s 1ms/step - loss: 0.2915 - acc: 0.9094\n",
      "Epoch 29/30\n",
      "30946/30946 [==============================] - 37s 1ms/step - loss: 0.2902 - acc: 0.9022\n",
      "Epoch 30/30\n",
      "30946/30946 [==============================] - 37s 1ms/step - loss: 0.2899 - acc: 0.9019\n",
      "15472/15472 [==============================] - 16s 1ms/step\n",
      "30946/30946 [==============================] - 25s 812us/step\n",
      "[CV] .................... epochs=30, lr=0.001, nodes=32, total=19.2min\n",
      "[CV] epochs=30, lr=0.001, nodes=64 ...................................\n",
      "Epoch 1/30\n",
      "30945/30945 [==============================] - 76s 2ms/step - loss: 0.3576 - acc: 0.9797\n",
      "Epoch 2/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.3346 - acc: 0.9770\n",
      "Epoch 3/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.3259 - acc: 0.9727\n",
      "Epoch 4/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.3197 - acc: 0.9715\n",
      "Epoch 5/30\n",
      "30945/30945 [==============================] - 65s 2ms/step - loss: 0.3145 - acc: 0.9661\n",
      "Epoch 6/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.3097 - acc: 0.9618\n",
      "Epoch 7/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.3059 - acc: 0.9600\n",
      "Epoch 8/30\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.3020 - acc: 0.9565\n",
      "Epoch 9/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.2990 - acc: 0.9515\n",
      "Epoch 10/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.2965 - acc: 0.9514\n",
      "Epoch 11/30\n",
      "30945/30945 [==============================] - 65s 2ms/step - loss: 0.2932 - acc: 0.9465\n",
      "Epoch 12/30\n",
      "30945/30945 [==============================] - 64s 2ms/step - loss: 0.2921 - acc: 0.9432\n",
      "Epoch 13/30\n",
      "30945/30945 [==============================] - 64s 2ms/step - loss: 0.2906 - acc: 0.9379\n",
      "Epoch 14/30\n",
      "30945/30945 [==============================] - 64s 2ms/step - loss: 0.2885 - acc: 0.9336\n",
      "Epoch 15/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.2893 - acc: 0.9300\n",
      "Epoch 16/30\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.2871 - acc: 0.9297\n",
      "Epoch 17/30\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.2876 - acc: 0.9218\n",
      "Epoch 18/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.2871 - acc: 0.9236\n",
      "Epoch 19/30\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.2876 - acc: 0.9214\n",
      "Epoch 20/30\n",
      "30945/30945 [==============================] - 64s 2ms/step - loss: 0.2879 - acc: 0.9201\n",
      "Epoch 21/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.2859 - acc: 0.9110\n",
      "Epoch 22/30\n",
      "30945/30945 [==============================] - 64s 2ms/step - loss: 0.2854 - acc: 0.9075\n",
      "Epoch 23/30\n",
      "30945/30945 [==============================] - 64s 2ms/step - loss: 0.2846 - acc: 0.9111\n",
      "Epoch 24/30\n",
      "30945/30945 [==============================] - 64s 2ms/step - loss: 0.2857 - acc: 0.9038\n",
      "Epoch 25/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.2846 - acc: 0.9042\n",
      "Epoch 26/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.2845 - acc: 0.9040\n",
      "Epoch 27/30\n",
      "30945/30945 [==============================] - 64s 2ms/step - loss: 0.2855 - acc: 0.8937\n",
      "Epoch 28/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.2848 - acc: 0.8947\n",
      "Epoch 29/30\n",
      "30945/30945 [==============================] - 64s 2ms/step - loss: 0.2847 - acc: 0.8925\n",
      "Epoch 30/30\n",
      "30945/30945 [==============================] - 65s 2ms/step - loss: 0.2838 - acc: 0.8937\n",
      "15473/15473 [==============================] - 17s 1ms/step\n",
      "30945/30945 [==============================] - 30s 964us/step\n",
      "[CV] .................... epochs=30, lr=0.001, nodes=64, total=32.8min\n",
      "[CV] epochs=30, lr=0.001, nodes=64 ...................................\n",
      "Epoch 1/30\n",
      "30945/30945 [==============================] - 75s 2ms/step - loss: 0.3655 - acc: 0.9797\n",
      "Epoch 2/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.3445 - acc: 0.9773\n",
      "Epoch 3/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.3353 - acc: 0.9753\n",
      "Epoch 4/30\n",
      "30945/30945 [==============================] - 64s 2ms/step - loss: 0.3284 - acc: 0.9719\n",
      "Epoch 5/30\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.3235 - acc: 0.9687\n",
      "Epoch 6/30\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.3193 - acc: 0.9627\n",
      "Epoch 7/30\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.3146 - acc: 0.9561\n",
      "Epoch 8/30\n",
      "30945/30945 [==============================] - 64s 2ms/step - loss: 0.3106 - acc: 0.9538\n",
      "Epoch 9/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.3082 - acc: 0.9465\n",
      "Epoch 10/30\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.3063 - acc: 0.9448\n",
      "Epoch 11/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.3040 - acc: 0.9407\n",
      "Epoch 12/30\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.3014 - acc: 0.9320\n",
      "Epoch 13/30\n",
      "30945/30945 [==============================] - 61s 2ms/step - loss: 0.3003 - acc: 0.9333\n",
      "Epoch 14/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.2998 - acc: 0.9279\n",
      "Epoch 15/30\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.2991 - acc: 0.9243\n",
      "Epoch 16/30\n",
      "30945/30945 [==============================] - 61s 2ms/step - loss: 0.2975 - acc: 0.9237\n",
      "Epoch 17/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.2978 - acc: 0.9205\n",
      "Epoch 18/30\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.2963 - acc: 0.9209\n",
      "Epoch 19/30\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.2964 - acc: 0.9160\n",
      "Epoch 20/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.2945 - acc: 0.9116\n",
      "Epoch 21/30\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.2955 - acc: 0.9076: 1s\n",
      "Epoch 22/30\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.2961 - acc: 0.9029\n",
      "Epoch 23/30\n",
      "30945/30945 [==============================] - 61s 2ms/step - loss: 0.2961 - acc: 0.9041\n",
      "Epoch 24/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.2966 - acc: 0.9002\n",
      "Epoch 25/30\n",
      "30945/30945 [==============================] - ETA: 0s - loss: 0.2960 - acc: 0.897 - 63s 2ms/step - loss: 0.2960 - acc: 0.8974\n",
      "Epoch 26/30\n",
      "30945/30945 [==============================] - 61s 2ms/step - loss: 0.2934 - acc: 0.8973\n",
      "Epoch 27/30\n",
      "30945/30945 [==============================] - 61s 2ms/step - loss: 0.2939 - acc: 0.8922\n",
      "Epoch 28/30\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.2939 - acc: 0.8933\n",
      "Epoch 29/30\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.2959 - acc: 0.8901\n",
      "Epoch 30/30\n",
      "30945/30945 [==============================] - 61s 2ms/step - loss: 0.2946 - acc: 0.8894\n",
      "15473/15473 [==============================] - 18s 1ms/step\n",
      "30945/30945 [==============================] - 30s 955us/step\n",
      "[CV] .................... epochs=30, lr=0.001, nodes=64, total=32.3min\n",
      "[CV] epochs=30, lr=0.001, nodes=64 ...................................\n",
      "Epoch 1/30\n",
      "30946/30946 [==============================] - 72s 2ms/step - loss: 0.3570 - acc: 0.9778\n",
      "Epoch 2/30\n",
      "30946/30946 [==============================] - 63s 2ms/step - loss: 0.3332 - acc: 0.9796\n",
      "Epoch 3/30\n",
      "30946/30946 [==============================] - 61s 2ms/step - loss: 0.3239 - acc: 0.9756\n",
      "Epoch 4/30\n",
      "30946/30946 [==============================] - 61s 2ms/step - loss: 0.3176 - acc: 0.9696\n",
      "Epoch 5/30\n",
      "30946/30946 [==============================] - 62s 2ms/step - loss: 0.3136 - acc: 0.9649\n",
      "Epoch 6/30\n",
      "30946/30946 [==============================] - 60s 2ms/step - loss: 0.3090 - acc: 0.9633\n",
      "Epoch 7/30\n",
      "30946/30946 [==============================] - 62s 2ms/step - loss: 0.3063 - acc: 0.9573\n",
      "Epoch 8/30\n",
      "30946/30946 [==============================] - 61s 2ms/step - loss: 0.3013 - acc: 0.9549\n",
      "Epoch 9/30\n",
      "30946/30946 [==============================] - 61s 2ms/step - loss: 0.2991 - acc: 0.9525\n",
      "Epoch 10/30\n",
      "30946/30946 [==============================] - 60s 2ms/step - loss: 0.2965 - acc: 0.9467\n",
      "Epoch 11/30\n",
      "30946/30946 [==============================] - 59s 2ms/step - loss: 0.2939 - acc: 0.9417\n",
      "Epoch 12/30\n",
      "30946/30946 [==============================] - 60s 2ms/step - loss: 0.2936 - acc: 0.9417\n",
      "Epoch 13/30\n",
      "30946/30946 [==============================] - 62s 2ms/step - loss: 0.2933 - acc: 0.9399\n",
      "Epoch 14/30\n",
      "30946/30946 [==============================] - 61s 2ms/step - loss: 0.2902 - acc: 0.9302\n",
      "Epoch 15/30\n",
      "30946/30946 [==============================] - 60s 2ms/step - loss: 0.2884 - acc: 0.9270\n",
      "Epoch 16/30\n",
      "30946/30946 [==============================] - 59s 2ms/step - loss: 0.2870 - acc: 0.9290\n",
      "Epoch 17/30\n",
      "30946/30946 [==============================] - 62s 2ms/step - loss: 0.2866 - acc: 0.9243\n",
      "Epoch 18/30\n",
      "30946/30946 [==============================] - 62s 2ms/step - loss: 0.2869 - acc: 0.9213\n",
      "Epoch 19/30\n",
      "30946/30946 [==============================] - 60s 2ms/step - loss: 0.2852 - acc: 0.9168\n",
      "Epoch 20/30\n",
      "30946/30946 [==============================] - 60s 2ms/step - loss: 0.2855 - acc: 0.9138\n",
      "Epoch 21/30\n",
      "30946/30946 [==============================] - 62s 2ms/step - loss: 0.2849 - acc: 0.9078\n",
      "Epoch 22/30\n",
      "30946/30946 [==============================] - 61s 2ms/step - loss: 0.2852 - acc: 0.9068\n",
      "Epoch 23/30\n",
      "30946/30946 [==============================] - 60s 2ms/step - loss: 0.2838 - acc: 0.9087\n",
      "Epoch 24/30\n",
      "30946/30946 [==============================] - 60s 2ms/step - loss: 0.2838 - acc: 0.9037\n",
      "Epoch 25/30\n",
      "30946/30946 [==============================] - 1259s 41ms/step - loss: 0.2851 - acc: 0.9023\n",
      "Epoch 26/30\n",
      "30946/30946 [==============================] - 32621s 1s/step - loss: 0.2840 - acc: 0.8957\n",
      "Epoch 27/30\n",
      "30946/30946 [==============================] - 46s 1ms/step - loss: 0.2839 - acc: 0.9011\n",
      "Epoch 28/30\n",
      "30946/30946 [==============================] - 48s 2ms/step - loss: 0.2842 - acc: 0.8935\n",
      "Epoch 29/30\n",
      "30946/30946 [==============================] - 48s 2ms/step - loss: 0.2856 - acc: 0.8936\n",
      "Epoch 30/30\n",
      "30946/30946 [==============================] - 49s 2ms/step - loss: 0.2843 - acc: 0.8920\n",
      "15472/15472 [==============================] - 14s 919us/step\n",
      "30946/30946 [==============================] - 24s 763us/step\n",
      "[CV] ................... epochs=30, lr=0.001, nodes=64, total=593.2min\n",
      "[CV] epochs=30, lr=0.002, nodes=16 ...................................\n",
      "Epoch 1/30\n",
      "30945/30945 [==============================] - 39s 1ms/step - loss: 0.3593 - acc: 0.9760\n",
      "Epoch 2/30\n",
      "30945/30945 [==============================] - 25s 798us/step - loss: 0.3403 - acc: 0.9836\n",
      "Epoch 3/30\n",
      "30945/30945 [==============================] - 25s 798us/step - loss: 0.3345 - acc: 0.9805\n",
      "Epoch 4/30\n",
      "30945/30945 [==============================] - 25s 804us/step - loss: 0.3313 - acc: 0.9736\n",
      "Epoch 5/30\n",
      "30945/30945 [==============================] - 25s 806us/step - loss: 0.3281 - acc: 0.9696\n",
      "Epoch 6/30\n",
      "30945/30945 [==============================] - 25s 813us/step - loss: 0.3246 - acc: 0.9683\n",
      "Epoch 7/30\n",
      "30945/30945 [==============================] - 25s 814us/step - loss: 0.3230 - acc: 0.9625\n",
      "Epoch 8/30\n",
      "30945/30945 [==============================] - 25s 800us/step - loss: 0.3211 - acc: 0.9628\n",
      "Epoch 9/30\n",
      "30945/30945 [==============================] - 25s 823us/step - loss: 0.3191 - acc: 0.9577\n",
      "Epoch 10/30\n",
      "30945/30945 [==============================] - 26s 824us/step - loss: 0.3167 - acc: 0.9593\n",
      "Epoch 11/30\n",
      "30945/30945 [==============================] - 25s 816us/step - loss: 0.3163 - acc: 0.9596\n",
      "Epoch 12/30\n",
      "30945/30945 [==============================] - 28s 905us/step - loss: 0.3158 - acc: 0.9589\n",
      "Epoch 13/30\n",
      "30945/30945 [==============================] - 26s 837us/step - loss: 0.3140 - acc: 0.9548\n",
      "Epoch 14/30\n",
      "30945/30945 [==============================] - 26s 834us/step - loss: 0.3128 - acc: 0.9529\n",
      "Epoch 15/30\n",
      "30945/30945 [==============================] - 25s 819us/step - loss: 0.3125 - acc: 0.9509\n",
      "Epoch 16/30\n",
      "30945/30945 [==============================] - 26s 829us/step - loss: 0.3115 - acc: 0.9465\n",
      "Epoch 17/30\n",
      "30945/30945 [==============================] - 25s 817us/step - loss: 0.3082 - acc: 0.9461\n",
      "Epoch 18/30\n",
      "30945/30945 [==============================] - 26s 850us/step - loss: 0.3090 - acc: 0.9436\n",
      "Epoch 19/30\n",
      "30945/30945 [==============================] - 26s 852us/step - loss: 0.3072 - acc: 0.9405\n",
      "Epoch 20/30\n",
      "30945/30945 [==============================] - 26s 845us/step - loss: 0.3078 - acc: 0.9388\n",
      "Epoch 21/30\n",
      "30945/30945 [==============================] - 26s 837us/step - loss: 0.3059 - acc: 0.9350\n",
      "Epoch 22/30\n",
      "30945/30945 [==============================] - 26s 835us/step - loss: 0.3052 - acc: 0.9292\n",
      "Epoch 23/30\n",
      "30945/30945 [==============================] - 25s 823us/step - loss: 0.3057 - acc: 0.9294\n",
      "Epoch 24/30\n",
      "30945/30945 [==============================] - 26s 851us/step - loss: 0.3046 - acc: 0.9191\n",
      "Epoch 25/30\n",
      "30945/30945 [==============================] - 28s 907us/step - loss: 0.3046 - acc: 0.9202\n",
      "Epoch 26/30\n",
      "30945/30945 [==============================] - 27s 876us/step - loss: 0.3034 - acc: 0.9180\n",
      "Epoch 27/30\n",
      "30945/30945 [==============================] - 26s 835us/step - loss: 0.3040 - acc: 0.9123\n",
      "Epoch 28/30\n",
      "30945/30945 [==============================] - 26s 831us/step - loss: 0.3035 - acc: 0.9123\n",
      "Epoch 29/30\n",
      "30945/30945 [==============================] - 26s 843us/step - loss: 0.3033 - acc: 0.9109\n",
      "Epoch 30/30\n",
      "30945/30945 [==============================] - 27s 869us/step - loss: 0.3028 - acc: 0.9094\n",
      "15473/15473 [==============================] - 15s 982us/step\n",
      "30945/30945 [==============================] - 24s 761us/step\n",
      "[CV] .................... epochs=30, lr=0.002, nodes=16, total=13.9min\n",
      "[CV] epochs=30, lr=0.002, nodes=16 ...................................\n",
      "Epoch 1/30\n",
      "30945/30945 [==============================] - 39s 1ms/step - loss: 0.3678 - acc: 0.9748\n",
      "Epoch 2/30\n",
      "30945/30945 [==============================] - 29s 939us/step - loss: 0.3481 - acc: 0.9827\n",
      "Epoch 3/30\n",
      "30945/30945 [==============================] - 26s 841us/step - loss: 0.3417 - acc: 0.9795\n",
      "Epoch 4/30\n",
      "30945/30945 [==============================] - 25s 813us/step - loss: 0.3389 - acc: 0.9762\n",
      "Epoch 5/30\n",
      "30945/30945 [==============================] - 25s 818us/step - loss: 0.3353 - acc: 0.9712\n",
      "Epoch 6/30\n",
      "30945/30945 [==============================] - 25s 819us/step - loss: 0.3350 - acc: 0.9694\n",
      "Epoch 7/30\n",
      "30945/30945 [==============================] - 26s 825us/step - loss: 0.3314 - acc: 0.9624\n",
      "Epoch 8/30\n",
      "30945/30945 [==============================] - 25s 820us/step - loss: 0.3301 - acc: 0.9566\n",
      "Epoch 9/30\n",
      "30945/30945 [==============================] - 25s 818us/step - loss: 0.3306 - acc: 0.9573\n",
      "Epoch 10/30\n",
      "30945/30945 [==============================] - 25s 822us/step - loss: 0.3277 - acc: 0.9516\n",
      "Epoch 11/30\n",
      "30945/30945 [==============================] - 27s 878us/step - loss: 0.3259 - acc: 0.9444\n",
      "Epoch 12/30\n",
      "30945/30945 [==============================] - 24s 786us/step - loss: 0.3251 - acc: 0.9441\n",
      "Epoch 13/30\n",
      "30945/30945 [==============================] - 23s 752us/step - loss: 0.3237 - acc: 0.9389\n",
      "Epoch 14/30\n",
      "30945/30945 [==============================] - 23s 733us/step - loss: 0.3215 - acc: 0.9381\n",
      "Epoch 15/30\n",
      "30945/30945 [==============================] - 22s 723us/step - loss: 0.3217 - acc: 0.9361\n",
      "Epoch 16/30\n",
      "30945/30945 [==============================] - 23s 736us/step - loss: 0.3209 - acc: 0.9333\n",
      "Epoch 17/30\n",
      "30945/30945 [==============================] - 23s 743us/step - loss: 0.3195 - acc: 0.9327\n",
      "Epoch 18/30\n",
      "30945/30945 [==============================] - 23s 745us/step - loss: 0.3207 - acc: 0.9301\n",
      "Epoch 19/30\n",
      "30945/30945 [==============================] - 23s 734us/step - loss: 0.3185 - acc: 0.9292\n",
      "Epoch 20/30\n",
      "30945/30945 [==============================] - 23s 746us/step - loss: 0.3207 - acc: 0.9223\n",
      "Epoch 21/30\n",
      "30945/30945 [==============================] - 23s 746us/step - loss: 0.3202 - acc: 0.9257\n",
      "Epoch 22/30\n",
      "30945/30945 [==============================] - 23s 744us/step - loss: 0.3188 - acc: 0.9191\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30945/30945 [==============================] - 25s 822us/step - loss: 0.3195 - acc: 0.9178\n",
      "Epoch 24/30\n",
      "30945/30945 [==============================] - 24s 780us/step - loss: 0.3194 - acc: 0.9173\n",
      "Epoch 25/30\n",
      "30945/30945 [==============================] - 22s 703us/step - loss: 0.3188 - acc: 0.9147\n",
      "Epoch 26/30\n",
      "30945/30945 [==============================] - 22s 721us/step - loss: 0.3193 - acc: 0.9092\n",
      "Epoch 27/30\n",
      "30945/30945 [==============================] - 23s 742us/step - loss: 0.3192 - acc: 0.9111\n",
      "Epoch 28/30\n",
      "30945/30945 [==============================] - 23s 752us/step - loss: 0.3194 - acc: 0.9019\n",
      "Epoch 29/30\n",
      "30945/30945 [==============================] - 23s 737us/step - loss: 0.3204 - acc: 0.9066\n",
      "Epoch 30/30\n",
      "30945/30945 [==============================] - 23s 736us/step - loss: 0.3190 - acc: 0.9017\n",
      "15473/15473 [==============================] - 14s 928us/step\n",
      "30945/30945 [==============================] - 22s 697us/step\n",
      "[CV] .................... epochs=30, lr=0.002, nodes=16, total=13.1min\n",
      "[CV] epochs=30, lr=0.002, nodes=16 ...................................\n",
      "Epoch 1/30\n",
      "30946/30946 [==============================] - 35s 1ms/step - loss: 0.3600 - acc: 0.9842\n",
      "Epoch 2/30\n",
      "30946/30946 [==============================] - 24s 770us/step - loss: 0.3391 - acc: 0.9810\n",
      "Epoch 3/30\n",
      "30946/30946 [==============================] - 23s 735us/step - loss: 0.3342 - acc: 0.9774\n",
      "Epoch 4/30\n",
      "30946/30946 [==============================] - 23s 743us/step - loss: 0.3297 - acc: 0.9725\n",
      "Epoch 5/30\n",
      "30946/30946 [==============================] - 24s 783us/step - loss: 0.3251 - acc: 0.9671\n",
      "Epoch 6/30\n",
      "30946/30946 [==============================] - 25s 807us/step - loss: 0.3229 - acc: 0.9669\n",
      "Epoch 7/30\n",
      "30946/30946 [==============================] - 27s 873us/step - loss: 0.3201 - acc: 0.9633\n",
      "Epoch 8/30\n",
      "30946/30946 [==============================] - 28s 890us/step - loss: 0.3180 - acc: 0.9637\n",
      "Epoch 9/30\n",
      "30946/30946 [==============================] - 26s 853us/step - loss: 0.3145 - acc: 0.9584\n",
      "Epoch 10/30\n",
      "30946/30946 [==============================] - 26s 849us/step - loss: 0.3161 - acc: 0.9579\n",
      "Epoch 11/30\n",
      "30946/30946 [==============================] - 26s 846us/step - loss: 0.3142 - acc: 0.9604\n",
      "Epoch 12/30\n",
      "30946/30946 [==============================] - 27s 864us/step - loss: 0.3126 - acc: 0.9531\n",
      "Epoch 13/30\n",
      "30946/30946 [==============================] - 27s 863us/step - loss: 0.3107 - acc: 0.9509\n",
      "Epoch 14/30\n",
      "30946/30946 [==============================] - 26s 856us/step - loss: 0.3107 - acc: 0.9516\n",
      "Epoch 15/30\n",
      "30946/30946 [==============================] - 23s 753us/step - loss: 0.3085 - acc: 0.9494\n",
      "Epoch 16/30\n",
      "30946/30946 [==============================] - 23s 756us/step - loss: 0.3089 - acc: 0.9456\n",
      "Epoch 17/30\n",
      "30946/30946 [==============================] - 24s 776us/step - loss: 0.3087 - acc: 0.9434\n",
      "Epoch 18/30\n",
      "30946/30946 [==============================] - 25s 823us/step - loss: 0.3064 - acc: 0.9389\n",
      "Epoch 19/30\n",
      "30946/30946 [==============================] - 25s 793us/step - loss: 0.3068 - acc: 0.9345\n",
      "Epoch 20/30\n",
      "30946/30946 [==============================] - 23s 730us/step - loss: 0.3060 - acc: 0.9331\n",
      "Epoch 21/30\n",
      "30946/30946 [==============================] - 22s 723us/step - loss: 0.3056 - acc: 0.9302\n",
      "Epoch 22/30\n",
      "30946/30946 [==============================] - 22s 720us/step - loss: 0.3064 - acc: 0.9309\n",
      "Epoch 23/30\n",
      "30946/30946 [==============================] - 22s 717us/step - loss: 0.3073 - acc: 0.9271\n",
      "Epoch 24/30\n",
      "30946/30946 [==============================] - 23s 728us/step - loss: 0.3031 - acc: 0.9199\n",
      "Epoch 25/30\n",
      "30946/30946 [==============================] - 23s 736us/step - loss: 0.3052 - acc: 0.9214\n",
      "Epoch 26/30\n",
      "30946/30946 [==============================] - 23s 735us/step - loss: 0.3073 - acc: 0.9184\n",
      "Epoch 27/30\n",
      "30946/30946 [==============================] - 23s 734us/step - loss: 0.3039 - acc: 0.9135\n",
      "Epoch 28/30\n",
      "30946/30946 [==============================] - 23s 751us/step - loss: 0.3062 - acc: 0.9113\n",
      "Epoch 29/30\n",
      "30946/30946 [==============================] - 24s 781us/step - loss: 0.3033 - acc: 0.9131\n",
      "Epoch 30/30\n",
      "30946/30946 [==============================] - 25s 806us/step - loss: 0.3067 - acc: 0.9145\n",
      "15472/15472 [==============================] - 15s 948us/step\n",
      "30946/30946 [==============================] - 22s 712us/step\n",
      "[CV] .................... epochs=30, lr=0.002, nodes=16, total=13.2min\n",
      "[CV] epochs=30, lr=0.002, nodes=32 ...................................\n",
      "Epoch 1/30\n",
      "30945/30945 [==============================] - 47s 2ms/step - loss: 0.3546 - acc: 0.9650\n",
      "Epoch 2/30\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.3343 - acc: 0.9787\n",
      "Epoch 3/30\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.3268 - acc: 0.9739\n",
      "Epoch 4/30\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.3207 - acc: 0.9700\n",
      "Epoch 5/30\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.3158 - acc: 0.9682\n",
      "Epoch 6/30\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.3129 - acc: 0.9642\n",
      "Epoch 7/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3070 - acc: 0.9605\n",
      "Epoch 8/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3069 - acc: 0.9552\n",
      "Epoch 9/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3050 - acc: 0.9527\n",
      "Epoch 10/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3034 - acc: 0.9472\n",
      "Epoch 11/30\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.3019 - acc: 0.9452\n",
      "Epoch 12/30\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.3004 - acc: 0.9399\n",
      "Epoch 13/30\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.2995 - acc: 0.9370\n",
      "Epoch 14/30\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.2995 - acc: 0.9320\n",
      "Epoch 15/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.2977 - acc: 0.9234\n",
      "Epoch 16/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3000 - acc: 0.9205\n",
      "Epoch 17/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.2974 - acc: 0.9201\n",
      "Epoch 18/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.2962 - acc: 0.9134\n",
      "Epoch 19/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.2970 - acc: 0.9145\n",
      "Epoch 20/30\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.2959 - acc: 0.9054\n",
      "Epoch 21/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.2960 - acc: 0.9036\n",
      "Epoch 22/30\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.2959 - acc: 0.8992\n",
      "Epoch 23/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.2965 - acc: 0.8946\n",
      "Epoch 24/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.2940 - acc: 0.8987\n",
      "Epoch 25/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.2964 - acc: 0.8950\n",
      "Epoch 26/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.2954 - acc: 0.8943\n",
      "Epoch 27/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.2983 - acc: 0.8937\n",
      "Epoch 28/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.2967 - acc: 0.8873\n",
      "Epoch 29/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.2968 - acc: 0.8805\n",
      "Epoch 30/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.2963 - acc: 0.8781\n",
      "15473/15473 [==============================] - 15s 988us/step\n",
      "30945/30945 [==============================] - 25s 802us/step\n",
      "[CV] .................... epochs=30, lr=0.002, nodes=32, total=18.5min\n",
      "[CV] epochs=30, lr=0.002, nodes=32 ...................................\n",
      "Epoch 1/30\n",
      "30945/30945 [==============================] - 46s 1ms/step - loss: 0.3639 - acc: 0.9800\n",
      "Epoch 2/30\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.3466 - acc: 0.9783\n",
      "Epoch 3/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3391 - acc: 0.9736\n",
      "Epoch 4/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3343 - acc: 0.9703\n",
      "Epoch 5/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3293 - acc: 0.9663\n",
      "Epoch 6/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3249 - acc: 0.9633\n",
      "Epoch 7/30\n",
      "30945/30945 [==============================] - 38s 1ms/step - loss: 0.3230 - acc: 0.9597\n",
      "Epoch 8/30\n",
      "30945/30945 [==============================] - 38s 1ms/step - loss: 0.3204 - acc: 0.9547\n",
      "Epoch 9/30\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.3177 - acc: 0.9534\n",
      "Epoch 10/30\n",
      "30945/30945 [==============================] - 38s 1ms/step - loss: 0.3169 - acc: 0.9524\n",
      "Epoch 11/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3144 - acc: 0.9459\n",
      "Epoch 12/30\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.3121 - acc: 0.9387\n",
      "Epoch 13/30\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.3092 - acc: 0.9409\n",
      "Epoch 14/30\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.3103 - acc: 0.9352\n",
      "Epoch 15/30\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.3087 - acc: 0.9338\n",
      "Epoch 16/30\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.3084 - acc: 0.9295\n",
      "Epoch 17/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3073 - acc: 0.9227\n",
      "Epoch 18/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3078 - acc: 0.9173\n",
      "Epoch 19/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3067 - acc: 0.9206\n",
      "Epoch 20/30\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.3056 - acc: 0.9124\n",
      "Epoch 21/30\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.3065 - acc: 0.9114\n",
      "Epoch 22/30\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.3061 - acc: 0.9024\n",
      "Epoch 23/30\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.3012 - acc: 0.9007\n",
      "Epoch 24/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3038 - acc: 0.8993\n",
      "Epoch 25/30\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3030 - acc: 0.8960\n",
      "Epoch 26/30\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3036 - acc: 0.8969\n",
      "Epoch 27/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3025 - acc: 0.8979\n",
      "Epoch 28/30\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.3017 - acc: 0.8970\n",
      "Epoch 29/30\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.3038 - acc: 0.8949\n",
      "Epoch 30/30\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.3027 - acc: 0.8926\n",
      "15473/15473 [==============================] - 15s 999us/step\n",
      "30945/30945 [==============================] - 27s 883us/step\n",
      "[CV] .................... epochs=30, lr=0.002, nodes=32, total=18.3min\n",
      "[CV] epochs=30, lr=0.002, nodes=32 ...................................\n",
      "Epoch 1/30\n",
      "30946/30946 [==============================] - 51s 2ms/step - loss: 0.3534 - acc: 0.9795\n",
      "Epoch 2/30\n",
      "30946/30946 [==============================] - 37s 1ms/step - loss: 0.3335 - acc: 0.9784\n",
      "Epoch 3/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3252 - acc: 0.9720\n",
      "Epoch 4/30\n",
      "30946/30946 [==============================] - 37s 1ms/step - loss: 0.3202 - acc: 0.9669\n",
      "Epoch 5/30\n",
      "30946/30946 [==============================] - 37s 1ms/step - loss: 0.3157 - acc: 0.9632\n",
      "Epoch 6/30\n",
      "30946/30946 [==============================] - 34s 1ms/step - loss: 0.3133 - acc: 0.9530\n",
      "Epoch 7/30\n",
      "30946/30946 [==============================] - 34s 1ms/step - loss: 0.3094 - acc: 0.9508\n",
      "Epoch 8/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.3069 - acc: 0.9444\n",
      "Epoch 9/30\n",
      "30946/30946 [==============================] - 34s 1ms/step - loss: 0.3069 - acc: 0.9408\n",
      "Epoch 10/30\n",
      "30946/30946 [==============================] - 34s 1ms/step - loss: 0.3023 - acc: 0.9346\n",
      "Epoch 11/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.3026 - acc: 0.9374\n",
      "Epoch 12/30\n",
      "30946/30946 [==============================] - 32s 1ms/step - loss: 0.3023 - acc: 0.9293\n",
      "Epoch 13/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2992 - acc: 0.9259\n",
      "Epoch 14/30\n",
      "30946/30946 [==============================] - 34s 1ms/step - loss: 0.3001 - acc: 0.9218\n",
      "Epoch 15/30\n",
      "30946/30946 [==============================] - 35s 1ms/step - loss: 0.3017 - acc: 0.9209\n",
      "Epoch 16/30\n",
      "30946/30946 [==============================] - 35s 1ms/step - loss: 0.2981 - acc: 0.9143\n",
      "Epoch 17/30\n",
      "30946/30946 [==============================] - 38s 1ms/step - loss: 0.2976 - acc: 0.9133\n",
      "Epoch 18/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2984 - acc: 0.9074\n",
      "Epoch 19/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2974 - acc: 0.9064\n",
      "Epoch 20/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2970 - acc: 0.9022\n",
      "Epoch 21/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2972 - acc: 0.9003\n",
      "Epoch 22/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2958 - acc: 0.8946\n",
      "Epoch 23/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2990 - acc: 0.8967\n",
      "Epoch 24/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2977 - acc: 0.8912\n",
      "Epoch 25/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2978 - acc: 0.8885\n",
      "Epoch 26/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2995 - acc: 0.8906\n",
      "Epoch 27/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2978 - acc: 0.8923\n",
      "Epoch 28/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2968 - acc: 0.8865\n",
      "Epoch 29/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2954 - acc: 0.8839\n",
      "Epoch 30/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2958 - acc: 0.8816\n",
      "15472/15472 [==============================] - 17s 1ms/step\n",
      "30946/30946 [==============================] - 25s 814us/step\n",
      "[CV] .................... epochs=30, lr=0.002, nodes=32, total=18.8min\n",
      "[CV] epochs=30, lr=0.002, nodes=64 ...................................\n",
      "Epoch 1/30\n",
      "30945/30945 [==============================] - 73s 2ms/step - loss: 0.3522 - acc: 0.9786\n",
      "Epoch 2/30\n",
      "30945/30945 [==============================] - 60s 2ms/step - loss: 0.3324 - acc: 0.9738\n",
      "Epoch 3/30\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.3228 - acc: 0.9688\n",
      "Epoch 4/30\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.3155 - acc: 0.9634\n",
      "Epoch 5/30\n",
      "30945/30945 [==============================] - 59s 2ms/step - loss: 0.3111 - acc: 0.9595\n",
      "Epoch 6/30\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3061 - acc: 0.9542\n",
      "Epoch 7/30\n",
      "30945/30945 [==============================] - 59s 2ms/step - loss: 0.3020 - acc: 0.9460\n",
      "Epoch 8/30\n",
      "30945/30945 [==============================] - 65s 2ms/step - loss: 0.3013 - acc: 0.9469\n",
      "Epoch 9/30\n",
      "30945/30945 [==============================] - 61s 2ms/step - loss: 0.2991 - acc: 0.9455\n",
      "Epoch 10/30\n",
      "30945/30945 [==============================] - 60s 2ms/step - loss: 0.2968 - acc: 0.9392\n",
      "Epoch 11/30\n",
      "30945/30945 [==============================] - 59s 2ms/step - loss: 0.2961 - acc: 0.9323\n",
      "Epoch 12/30\n",
      "30945/30945 [==============================] - 61s 2ms/step - loss: 0.2934 - acc: 0.9283\n",
      "Epoch 13/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.2946 - acc: 0.9304\n",
      "Epoch 14/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.2959 - acc: 0.9210\n",
      "Epoch 15/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.2945 - acc: 0.9184\n",
      "Epoch 16/30\n",
      "30945/30945 [==============================] - 59s 2ms/step - loss: 0.2938 - acc: 0.9195\n",
      "Epoch 17/30\n",
      "30945/30945 [==============================] - 60s 2ms/step - loss: 0.2947 - acc: 0.9106\n",
      "Epoch 18/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.2932 - acc: 0.9123\n",
      "Epoch 19/30\n",
      "30945/30945 [==============================] - 64s 2ms/step - loss: 0.2924 - acc: 0.9026\n",
      "Epoch 20/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30945/30945 [==============================] - 64s 2ms/step - loss: 0.2955 - acc: 0.9027\n",
      "Epoch 21/30\n",
      "30945/30945 [==============================] - 65s 2ms/step - loss: 0.2927 - acc: 0.9015\n",
      "Epoch 22/30\n",
      "30945/30945 [==============================] - 64s 2ms/step - loss: 0.2943 - acc: 0.9038\n",
      "Epoch 23/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.2930 - acc: 0.8963\n",
      "Epoch 24/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.2946 - acc: 0.8939\n",
      "Epoch 25/30\n",
      "30945/30945 [==============================] - 64s 2ms/step - loss: 0.2956 - acc: 0.8918\n",
      "Epoch 26/30\n",
      "30945/30945 [==============================] - 64s 2ms/step - loss: 0.2933 - acc: 0.8879\n",
      "Epoch 27/30\n",
      "30945/30945 [==============================] - 64s 2ms/step - loss: 0.2946 - acc: 0.8891\n",
      "Epoch 28/30\n",
      "30945/30945 [==============================] - 59s 2ms/step - loss: 0.2941 - acc: 0.8809\n",
      "Epoch 29/30\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.2964 - acc: 0.8816\n",
      "Epoch 30/30\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.2965 - acc: 0.8790\n",
      "15473/15473 [==============================] - 16s 1ms/step\n",
      "30945/30945 [==============================] - 25s 798us/step\n",
      "[CV] .................... epochs=30, lr=0.002, nodes=64, total=31.4min\n",
      "[CV] epochs=30, lr=0.002, nodes=64 ...................................\n",
      "Epoch 1/30\n",
      "30945/30945 [==============================] - 66s 2ms/step - loss: 0.3608 - acc: 0.9783\n",
      "Epoch 2/30\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3404 - acc: 0.9753\n",
      "Epoch 3/30\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3316 - acc: 0.9690\n",
      "Epoch 4/30\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3247 - acc: 0.9651\n",
      "Epoch 5/30\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3196 - acc: 0.9587\n",
      "Epoch 6/30\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3160 - acc: 0.9548\n",
      "Epoch 7/30\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3116 - acc: 0.9479\n",
      "Epoch 8/30\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3099 - acc: 0.9447\n",
      "Epoch 9/30\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3073 - acc: 0.9337\n",
      "Epoch 10/30\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3059 - acc: 0.9286\n",
      "Epoch 11/30\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3023 - acc: 0.9199\n",
      "Epoch 12/30\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3040 - acc: 0.9200\n",
      "Epoch 13/30\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3043 - acc: 0.9201\n",
      "Epoch 14/30\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3026 - acc: 0.9193\n",
      "Epoch 15/30\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3014 - acc: 0.9116\n",
      "Epoch 16/30\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3038 - acc: 0.9034\n",
      "Epoch 17/30\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3022 - acc: 0.9002\n",
      "Epoch 18/30\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3032 - acc: 0.9011\n",
      "Epoch 19/30\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3014 - acc: 0.9009\n",
      "Epoch 20/30\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3030 - acc: 0.8902\n",
      "Epoch 21/30\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3022 - acc: 0.8955\n",
      "Epoch 22/30\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3016 - acc: 0.8893\n",
      "Epoch 23/30\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3042 - acc: 0.8835\n",
      "Epoch 24/30\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3032 - acc: 0.8814\n",
      "Epoch 25/30\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3009 - acc: 0.8759\n",
      "Epoch 26/30\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3025 - acc: 0.8836\n",
      "Epoch 27/30\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3007 - acc: 0.8792\n",
      "Epoch 28/30\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3042 - acc: 0.8780\n",
      "Epoch 29/30\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3036 - acc: 0.8805\n",
      "Epoch 30/30\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3029 - acc: 0.8777\n",
      "15473/15473 [==============================] - 16s 1ms/step\n",
      "30945/30945 [==============================] - 25s 809us/step\n",
      "[CV] .................... epochs=30, lr=0.002, nodes=64, total=28.7min\n",
      "[CV] epochs=30, lr=0.002, nodes=64 ...................................\n",
      "Epoch 1/30\n",
      "30946/30946 [==============================] - 66s 2ms/step - loss: 0.3521 - acc: 0.9815\n",
      "Epoch 2/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.3292 - acc: 0.9752\n",
      "Epoch 3/30\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3206 - acc: 0.9707\n",
      "Epoch 4/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.3153 - acc: 0.9642\n",
      "Epoch 5/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.3089 - acc: 0.9577\n",
      "Epoch 6/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.3056 - acc: 0.9534\n",
      "Epoch 7/30\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3027 - acc: 0.9461\n",
      "Epoch 8/30\n",
      "30946/30946 [==============================] - 56s 2ms/step - loss: 0.2992 - acc: 0.9445\n",
      "Epoch 9/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2966 - acc: 0.9364\n",
      "Epoch 10/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2964 - acc: 0.9316\n",
      "Epoch 11/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2946 - acc: 0.9244\n",
      "Epoch 12/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2947 - acc: 0.9217\n",
      "Epoch 13/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2934 - acc: 0.9202\n",
      "Epoch 14/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2952 - acc: 0.9170\n",
      "Epoch 15/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2936 - acc: 0.9110\n",
      "Epoch 16/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2959 - acc: 0.9032\n",
      "Epoch 17/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2966 - acc: 0.9048\n",
      "Epoch 18/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2938 - acc: 0.8992\n",
      "Epoch 19/30\n",
      "30946/30946 [==============================] - 56s 2ms/step - loss: 0.2930 - acc: 0.8952\n",
      "Epoch 20/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2944 - acc: 0.8946\n",
      "Epoch 21/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2964 - acc: 0.8944\n",
      "Epoch 22/30\n",
      "30946/30946 [==============================] - 56s 2ms/step - loss: 0.2959 - acc: 0.8921\n",
      "Epoch 23/30\n",
      "30946/30946 [==============================] - 56s 2ms/step - loss: 0.2962 - acc: 0.8894\n",
      "Epoch 24/30\n",
      "30946/30946 [==============================] - 56s 2ms/step - loss: 0.2992 - acc: 0.8806\n",
      "Epoch 25/30\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.2951 - acc: 0.8854\n",
      "Epoch 26/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2989 - acc: 0.8746\n",
      "Epoch 27/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2943 - acc: 0.8769\n",
      "Epoch 28/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2967 - acc: 0.8761\n",
      "Epoch 29/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2980 - acc: 0.8686\n",
      "Epoch 30/30\n",
      "30946/30946 [==============================] - 56s 2ms/step - loss: 0.2970 - acc: 0.8715\n",
      "15472/15472 [==============================] - 16s 1ms/step\n",
      "30946/30946 [==============================] - 25s 801us/step\n",
      "[CV] .................... epochs=30, lr=0.002, nodes=64, total=28.6min\n",
      "[CV] epochs=30, lr=0.003, nodes=16 ...................................\n",
      "Epoch 1/30\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.3552 - acc: 0.9788\n",
      "Epoch 2/30\n",
      "30945/30945 [==============================] - 24s 791us/step - loss: 0.3379 - acc: 0.9803\n",
      "Epoch 3/30\n",
      "30945/30945 [==============================] - 24s 764us/step - loss: 0.3338 - acc: 0.9733\n",
      "Epoch 4/30\n",
      "30945/30945 [==============================] - 23s 755us/step - loss: 0.3298 - acc: 0.9698\n",
      "Epoch 5/30\n",
      "30945/30945 [==============================] - 24s 768us/step - loss: 0.3234 - acc: 0.9653\n",
      "Epoch 6/30\n",
      "30945/30945 [==============================] - 24s 762us/step - loss: 0.3198 - acc: 0.9593\n",
      "Epoch 7/30\n",
      "30945/30945 [==============================] - 24s 761us/step - loss: 0.3183 - acc: 0.9598\n",
      "Epoch 8/30\n",
      "30945/30945 [==============================] - 23s 756us/step - loss: 0.3161 - acc: 0.9526\n",
      "Epoch 9/30\n",
      "30945/30945 [==============================] - 24s 764us/step - loss: 0.3151 - acc: 0.9533\n",
      "Epoch 10/30\n",
      "30945/30945 [==============================] - 23s 753us/step - loss: 0.3122 - acc: 0.9486\n",
      "Epoch 11/30\n",
      "30945/30945 [==============================] - 23s 756us/step - loss: 0.3115 - acc: 0.9469\n",
      "Epoch 12/30\n",
      "30945/30945 [==============================] - 23s 755us/step - loss: 0.3113 - acc: 0.9472\n",
      "Epoch 13/30\n",
      "30945/30945 [==============================] - 24s 765us/step - loss: 0.3092 - acc: 0.9427\n",
      "Epoch 14/30\n",
      "30945/30945 [==============================] - 24s 763us/step - loss: 0.3089 - acc: 0.9408\n",
      "Epoch 15/30\n",
      "30945/30945 [==============================] - 24s 765us/step - loss: 0.3093 - acc: 0.9362\n",
      "Epoch 16/30\n",
      "30945/30945 [==============================] - 24s 764us/step - loss: 0.3066 - acc: 0.9349\n",
      "Epoch 17/30\n",
      "30945/30945 [==============================] - 23s 751us/step - loss: 0.3079 - acc: 0.9322\n",
      "Epoch 18/30\n",
      "30945/30945 [==============================] - 24s 769us/step - loss: 0.3054 - acc: 0.9265\n",
      "Epoch 19/30\n",
      "30945/30945 [==============================] - 23s 759us/step - loss: 0.3080 - acc: 0.9271\n",
      "Epoch 20/30\n",
      "30945/30945 [==============================] - 23s 758us/step - loss: 0.3094 - acc: 0.9220\n",
      "Epoch 21/30\n",
      "30945/30945 [==============================] - 23s 759us/step - loss: 0.3074 - acc: 0.9211\n",
      "Epoch 22/30\n",
      "30945/30945 [==============================] - 23s 744us/step - loss: 0.3068 - acc: 0.9216\n",
      "Epoch 23/30\n",
      "30945/30945 [==============================] - 24s 761us/step - loss: 0.3068 - acc: 0.9140\n",
      "Epoch 24/30\n",
      "30945/30945 [==============================] - 23s 759us/step - loss: 0.3081 - acc: 0.9069\n",
      "Epoch 25/30\n",
      "30945/30945 [==============================] - 23s 756us/step - loss: 0.3054 - acc: 0.9058\n",
      "Epoch 26/30\n",
      "30945/30945 [==============================] - 24s 760us/step - loss: 0.3078 - acc: 0.9099\n",
      "Epoch 27/30\n",
      "30945/30945 [==============================] - 23s 744us/step - loss: 0.3080 - acc: 0.9012\n",
      "Epoch 28/30\n",
      "30945/30945 [==============================] - 23s 758us/step - loss: 0.3075 - acc: 0.9003\n",
      "Epoch 29/30\n",
      "30945/30945 [==============================] - 24s 765us/step - loss: 0.3075 - acc: 0.8988\n",
      "Epoch 30/30\n",
      "30945/30945 [==============================] - 24s 760us/step - loss: 0.3090 - acc: 0.9051\n",
      "15473/15473 [==============================] - 15s 948us/step\n",
      "30945/30945 [==============================] - 22s 704us/step\n",
      "[CV] .................... epochs=30, lr=0.003, nodes=16, total=12.8min\n",
      "[CV] epochs=30, lr=0.003, nodes=16 ...................................\n",
      "Epoch 1/30\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.3647 - acc: 0.9788\n",
      "Epoch 2/30\n",
      "30945/30945 [==============================] - 25s 815us/step - loss: 0.3490 - acc: 0.9827\n",
      "Epoch 3/30\n",
      "30945/30945 [==============================] - 24s 767us/step - loss: 0.3428 - acc: 0.9781\n",
      "Epoch 4/30\n",
      "30945/30945 [==============================] - 24s 764us/step - loss: 0.3387 - acc: 0.9751\n",
      "Epoch 5/30\n",
      "30945/30945 [==============================] - 24s 772us/step - loss: 0.3358 - acc: 0.9687\n",
      "Epoch 6/30\n",
      "30945/30945 [==============================] - 24s 772us/step - loss: 0.3309 - acc: 0.9692\n",
      "Epoch 7/30\n",
      "30945/30945 [==============================] - 23s 758us/step - loss: 0.3300 - acc: 0.9603\n",
      "Epoch 8/30\n",
      "30945/30945 [==============================] - 23s 756us/step - loss: 0.3284 - acc: 0.9554\n",
      "Epoch 9/30\n",
      "30945/30945 [==============================] - 24s 761us/step - loss: 0.3267 - acc: 0.9543\n",
      "Epoch 10/30\n",
      "30945/30945 [==============================] - 24s 767us/step - loss: 0.3240 - acc: 0.9447\n",
      "Epoch 11/30\n",
      "30945/30945 [==============================] - 24s 766us/step - loss: 0.3238 - acc: 0.9429\n",
      "Epoch 12/30\n",
      "30945/30945 [==============================] - 24s 769us/step - loss: 0.3221 - acc: 0.9407\n",
      "Epoch 13/30\n",
      "30945/30945 [==============================] - 24s 768us/step - loss: 0.3227 - acc: 0.9406\n",
      "Epoch 14/30\n",
      "30945/30945 [==============================] - 24s 760us/step - loss: 0.3225 - acc: 0.9332\n",
      "Epoch 15/30\n",
      "30945/30945 [==============================] - 24s 761us/step - loss: 0.3229 - acc: 0.9350\n",
      "Epoch 16/30\n",
      "30945/30945 [==============================] - 24s 763us/step - loss: 0.3233 - acc: 0.9295\n",
      "Epoch 17/30\n",
      "30945/30945 [==============================] - 24s 763us/step - loss: 0.3220 - acc: 0.9291\n",
      "Epoch 18/30\n",
      "30945/30945 [==============================] - 24s 770us/step - loss: 0.3219 - acc: 0.9171\n",
      "Epoch 19/30\n",
      "30945/30945 [==============================] - 24s 761us/step - loss: 0.3217 - acc: 0.9240\n",
      "Epoch 20/30\n",
      "30945/30945 [==============================] - 24s 770us/step - loss: 0.3239 - acc: 0.9238\n",
      "Epoch 21/30\n",
      "30945/30945 [==============================] - 24s 764us/step - loss: 0.3242 - acc: 0.9209\n",
      "Epoch 22/30\n",
      "30945/30945 [==============================] - 24s 764us/step - loss: 0.3223 - acc: 0.9182\n",
      "Epoch 23/30\n",
      "30945/30945 [==============================] - 23s 753us/step - loss: 0.3202 - acc: 0.9169\n",
      "Epoch 24/30\n",
      "30945/30945 [==============================] - 23s 741us/step - loss: 0.3213 - acc: 0.9140\n",
      "Epoch 25/30\n",
      "30945/30945 [==============================] - 24s 760us/step - loss: 0.3218 - acc: 0.9163\n",
      "Epoch 26/30\n",
      "30945/30945 [==============================] - 23s 755us/step - loss: 0.3235 - acc: 0.9107\n",
      "Epoch 27/30\n",
      "30945/30945 [==============================] - 23s 759us/step - loss: 0.3246 - acc: 0.8952\n",
      "Epoch 28/30\n",
      "30945/30945 [==============================] - 23s 754us/step - loss: 0.3231 - acc: 0.9058\n",
      "Epoch 29/30\n",
      "30945/30945 [==============================] - 25s 796us/step - loss: 0.3230 - acc: 0.9040\n",
      "Epoch 30/30\n",
      "30945/30945 [==============================] - 24s 774us/step - loss: 0.3245 - acc: 0.9030\n",
      "15473/15473 [==============================] - 15s 975us/step\n",
      "30945/30945 [==============================] - 22s 697us/step\n",
      "[CV] .................... epochs=30, lr=0.003, nodes=16, total=12.9min\n",
      "[CV] epochs=30, lr=0.003, nodes=16 ...................................\n",
      "Epoch 1/30\n",
      "30946/30946 [==============================] - 37s 1ms/step - loss: 0.3561 - acc: 0.9680\n",
      "Epoch 2/30\n",
      "30946/30946 [==============================] - 24s 776us/step - loss: 0.3396 - acc: 0.9843\n",
      "Epoch 3/30\n",
      "30946/30946 [==============================] - 23s 750us/step - loss: 0.3345 - acc: 0.9782\n",
      "Epoch 4/30\n",
      "30946/30946 [==============================] - 23s 755us/step - loss: 0.3292 - acc: 0.9704\n",
      "Epoch 5/30\n",
      "30946/30946 [==============================] - 23s 748us/step - loss: 0.3241 - acc: 0.9654\n",
      "Epoch 6/30\n",
      "30946/30946 [==============================] - 23s 748us/step - loss: 0.3206 - acc: 0.9656\n",
      "Epoch 7/30\n",
      "30946/30946 [==============================] - 24s 765us/step - loss: 0.3193 - acc: 0.9626\n",
      "Epoch 8/30\n",
      "30946/30946 [==============================] - 23s 746us/step - loss: 0.3168 - acc: 0.9569\n",
      "Epoch 9/30\n",
      "30946/30946 [==============================] - 23s 748us/step - loss: 0.3149 - acc: 0.9568\n",
      "Epoch 10/30\n",
      "30946/30946 [==============================] - 24s 767us/step - loss: 0.3144 - acc: 0.9563\n",
      "Epoch 11/30\n",
      "30946/30946 [==============================] - 23s 750us/step - loss: 0.3108 - acc: 0.9521\n",
      "Epoch 12/30\n",
      "30946/30946 [==============================] - 24s 763us/step - loss: 0.3087 - acc: 0.9476\n",
      "Epoch 13/30\n",
      "30946/30946 [==============================] - 23s 746us/step - loss: 0.3081 - acc: 0.9455\n",
      "Epoch 14/30\n",
      "30946/30946 [==============================] - 23s 748us/step - loss: 0.3091 - acc: 0.9383\n",
      "Epoch 15/30\n",
      "30946/30946 [==============================] - 23s 748us/step - loss: 0.3061 - acc: 0.9335\n",
      "Epoch 16/30\n",
      "30946/30946 [==============================] - 23s 741us/step - loss: 0.3055 - acc: 0.9350\n",
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30946/30946 [==============================] - 23s 745us/step - loss: 0.3050 - acc: 0.9294\n",
      "Epoch 18/30\n",
      "30946/30946 [==============================] - 23s 749us/step - loss: 0.3043 - acc: 0.9247\n",
      "Epoch 19/30\n",
      "30946/30946 [==============================] - 23s 743us/step - loss: 0.3011 - acc: 0.9232\n",
      "Epoch 20/30\n",
      "30946/30946 [==============================] - 23s 755us/step - loss: 0.3019 - acc: 0.9242\n",
      "Epoch 21/30\n",
      "30946/30946 [==============================] - 24s 762us/step - loss: 0.3025 - acc: 0.9211\n",
      "Epoch 22/30\n",
      "30946/30946 [==============================] - 23s 751us/step - loss: 0.2993 - acc: 0.9179\n",
      "Epoch 23/30\n",
      "30946/30946 [==============================] - 23s 754us/step - loss: 0.3013 - acc: 0.9133\n",
      "Epoch 24/30\n",
      "30946/30946 [==============================] - 23s 754us/step - loss: 0.2995 - acc: 0.9096\n",
      "Epoch 25/30\n",
      "30946/30946 [==============================] - 23s 743us/step - loss: 0.2999 - acc: 0.9058\n",
      "Epoch 26/30\n",
      "30946/30946 [==============================] - 23s 742us/step - loss: 0.2993 - acc: 0.9064\n",
      "Epoch 27/30\n",
      "30946/30946 [==============================] - 23s 739us/step - loss: 0.3015 - acc: 0.9016\n",
      "Epoch 28/30\n",
      "30946/30946 [==============================] - 23s 757us/step - loss: 0.3023 - acc: 0.9017\n",
      "Epoch 29/30\n",
      "30946/30946 [==============================] - 24s 761us/step - loss: 0.3014 - acc: 0.8974\n",
      "Epoch 30/30\n",
      "30946/30946 [==============================] - 23s 751us/step - loss: 0.3022 - acc: 0.8960\n",
      "15472/15472 [==============================] - 15s 949us/step\n",
      "30946/30946 [==============================] - 22s 699us/step\n",
      "[CV] .................... epochs=30, lr=0.003, nodes=16, total=12.7min\n",
      "[CV] epochs=30, lr=0.003, nodes=32 ...................................\n",
      "Epoch 1/30\n",
      "30945/30945 [==============================] - 46s 1ms/step - loss: 0.3515 - acc: 0.9801\n",
      "Epoch 2/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3358 - acc: 0.9799\n",
      "Epoch 3/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3267 - acc: 0.9718\n",
      "Epoch 4/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3209 - acc: 0.9682\n",
      "Epoch 5/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3180 - acc: 0.9597\n",
      "Epoch 6/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3135 - acc: 0.9578\n",
      "Epoch 7/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3116 - acc: 0.9536\n",
      "Epoch 8/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3075 - acc: 0.9519\n",
      "Epoch 9/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3073 - acc: 0.9437\n",
      "Epoch 10/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3056 - acc: 0.9415\n",
      "Epoch 11/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3046 - acc: 0.9321\n",
      "Epoch 12/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3031 - acc: 0.9357\n",
      "Epoch 13/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3046 - acc: 0.9279\n",
      "Epoch 14/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3033 - acc: 0.9263\n",
      "Epoch 15/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3037 - acc: 0.9160\n",
      "Epoch 16/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3036 - acc: 0.9136\n",
      "Epoch 17/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3037 - acc: 0.9100\n",
      "Epoch 18/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3044 - acc: 0.9127\n",
      "Epoch 19/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3021 - acc: 0.8991\n",
      "Epoch 20/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3022 - acc: 0.9069\n",
      "Epoch 21/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3040 - acc: 0.9038\n",
      "Epoch 22/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3058 - acc: 0.8990\n",
      "Epoch 23/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3070 - acc: 0.8975\n",
      "Epoch 24/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3060 - acc: 0.8867\n",
      "Epoch 25/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3058 - acc: 0.8894\n",
      "Epoch 26/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3067 - acc: 0.8874\n",
      "Epoch 27/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3069 - acc: 0.8922\n",
      "Epoch 28/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3084 - acc: 0.8843\n",
      "Epoch 29/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3060 - acc: 0.8848\n",
      "Epoch 30/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3086 - acc: 0.8805\n",
      "15473/15473 [==============================] - 15s 996us/step\n",
      "30945/30945 [==============================] - 25s 802us/step\n",
      "[CV] .................... epochs=30, lr=0.003, nodes=32, total=18.1min\n",
      "[CV] epochs=30, lr=0.003, nodes=32 ...................................\n",
      "Epoch 1/30\n",
      "30945/30945 [==============================] - 46s 1ms/step - loss: 0.3613 - acc: 0.9762\n",
      "Epoch 2/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3452 - acc: 0.9791\n",
      "Epoch 3/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3386 - acc: 0.9727\n",
      "Epoch 4/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3325 - acc: 0.9677\n",
      "Epoch 5/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3301 - acc: 0.9635\n",
      "Epoch 6/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3242 - acc: 0.9602\n",
      "Epoch 7/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3245 - acc: 0.9545\n",
      "Epoch 8/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3206 - acc: 0.9487\n",
      "Epoch 9/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3183 - acc: 0.9468\n",
      "Epoch 10/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3163 - acc: 0.9364\n",
      "Epoch 11/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3164 - acc: 0.9329\n",
      "Epoch 12/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3161 - acc: 0.9295\n",
      "Epoch 13/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3175 - acc: 0.9286\n",
      "Epoch 14/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3170 - acc: 0.9277\n",
      "Epoch 15/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3164 - acc: 0.9172\n",
      "Epoch 16/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3153 - acc: 0.9080\n",
      "Epoch 17/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3168 - acc: 0.9050\n",
      "Epoch 18/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3152 - acc: 0.9027\n",
      "Epoch 19/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3134 - acc: 0.9048\n",
      "Epoch 20/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3157 - acc: 0.9081\n",
      "Epoch 21/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3146 - acc: 0.8976\n",
      "Epoch 22/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3150 - acc: 0.8923\n",
      "Epoch 23/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3131 - acc: 0.8900\n",
      "Epoch 24/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3174 - acc: 0.8890\n",
      "Epoch 25/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3153 - acc: 0.8855\n",
      "Epoch 26/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3163 - acc: 0.8917\n",
      "Epoch 27/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3170 - acc: 0.8752\n",
      "Epoch 28/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3176 - acc: 0.8842\n",
      "Epoch 29/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3157 - acc: 0.8806\n",
      "Epoch 30/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3153 - acc: 0.8745\n",
      "15473/15473 [==============================] - 15s 998us/step\n",
      "30945/30945 [==============================] - 25s 808us/step\n",
      "[CV] .................... epochs=30, lr=0.003, nodes=32, total=18.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] epochs=30, lr=0.003, nodes=32 ...................................\n",
      "Epoch 1/30\n",
      "30946/30946 [==============================] - 46s 1ms/step - loss: 0.3526 - acc: 0.9823\n",
      "Epoch 2/30\n",
      "30946/30946 [==============================] - 34s 1ms/step - loss: 0.3338 - acc: 0.9771\n",
      "Epoch 3/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.3271 - acc: 0.9722\n",
      "Epoch 4/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.3207 - acc: 0.9624\n",
      "Epoch 5/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.3190 - acc: 0.9596\n",
      "Epoch 6/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.3156 - acc: 0.9543\n",
      "Epoch 7/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.3119 - acc: 0.9472\n",
      "Epoch 8/30\n",
      "30946/30946 [==============================] - 34s 1ms/step - loss: 0.3103 - acc: 0.9466\n",
      "Epoch 9/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.3051 - acc: 0.9394\n",
      "Epoch 10/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.3050 - acc: 0.9371\n",
      "Epoch 11/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.3037 - acc: 0.9259\n",
      "Epoch 12/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.3017 - acc: 0.9263\n",
      "Epoch 13/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.3012 - acc: 0.9174\n",
      "Epoch 14/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.3009 - acc: 0.9195\n",
      "Epoch 15/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.2998 - acc: 0.9163\n",
      "Epoch 16/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.3008 - acc: 0.9074\n",
      "Epoch 17/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.2994 - acc: 0.9083\n",
      "Epoch 18/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.2965 - acc: 0.8994\n",
      "Epoch 19/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.2986 - acc: 0.9006\n",
      "Epoch 20/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.2973 - acc: 0.8997\n",
      "Epoch 21/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.2975 - acc: 0.8981\n",
      "Epoch 22/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.2993 - acc: 0.8963\n",
      "Epoch 23/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.2981 - acc: 0.8915\n",
      "Epoch 24/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.2980 - acc: 0.8861\n",
      "Epoch 25/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.2997 - acc: 0.8875\n",
      "Epoch 26/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.2978 - acc: 0.8903\n",
      "Epoch 27/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.2988 - acc: 0.8847\n",
      "Epoch 28/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.2985 - acc: 0.8803\n",
      "Epoch 29/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.2992 - acc: 0.8843\n",
      "Epoch 30/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.2982 - acc: 0.8777\n",
      "15472/15472 [==============================] - 15s 1ms/step\n",
      "30946/30946 [==============================] - 23s 752us/step\n",
      "[CV] .................... epochs=30, lr=0.003, nodes=32, total=17.6min\n",
      "[CV] epochs=30, lr=0.003, nodes=64 ...................................\n",
      "Epoch 1/30\n",
      "30945/30945 [==============================] - 67s 2ms/step - loss: 0.3507 - acc: 0.9771\n",
      "Epoch 2/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3321 - acc: 0.9726\n",
      "Epoch 3/30\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3241 - acc: 0.9665\n",
      "Epoch 4/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3158 - acc: 0.9608\n",
      "Epoch 5/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3106 - acc: 0.9541\n",
      "Epoch 6/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3080 - acc: 0.9506\n",
      "Epoch 7/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3058 - acc: 0.9442\n",
      "Epoch 8/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3035 - acc: 0.9391\n",
      "Epoch 9/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3020 - acc: 0.9348\n",
      "Epoch 10/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3013 - acc: 0.9313\n",
      "Epoch 11/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.2984 - acc: 0.9225\n",
      "Epoch 12/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3002 - acc: 0.9185\n",
      "Epoch 13/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3022 - acc: 0.9124\n",
      "Epoch 14/30\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3014 - acc: 0.9117\n",
      "Epoch 15/30\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3047 - acc: 0.9088\n",
      "Epoch 16/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3038 - acc: 0.9043\n",
      "Epoch 17/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3033 - acc: 0.9013\n",
      "Epoch 18/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3017 - acc: 0.8984\n",
      "Epoch 19/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3030 - acc: 0.9023\n",
      "Epoch 20/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3079 - acc: 0.8878\n",
      "Epoch 21/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3040 - acc: 0.8931\n",
      "Epoch 22/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3037 - acc: 0.8868\n",
      "Epoch 23/30\n",
      "30945/30945 [==============================] - 58s 2ms/step - loss: 0.3031 - acc: 0.8848\n",
      "Epoch 24/30\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3044 - acc: 0.8863\n",
      "Epoch 25/30\n",
      "30945/30945 [==============================] - 58s 2ms/step - loss: 0.3043 - acc: 0.8872\n",
      "Epoch 26/30\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3062 - acc: 0.8805\n",
      "Epoch 27/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3048 - acc: 0.8801\n",
      "Epoch 28/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3034 - acc: 0.8786\n",
      "Epoch 29/30\n",
      "30945/30945 [==============================] - 58s 2ms/step - loss: 0.3047 - acc: 0.8728\n",
      "Epoch 30/30\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3074 - acc: 0.8708\n",
      "15473/15473 [==============================] - 14s 883us/step\n",
      "30945/30945 [==============================] - 23s 740us/step\n",
      "[CV] .................... epochs=30, lr=0.003, nodes=64, total=29.4min\n",
      "[CV] epochs=30, lr=0.003, nodes=64 ...................................\n",
      "Epoch 1/30\n",
      "30945/30945 [==============================] - 65s 2ms/step - loss: 0.3611 - acc: 0.9753\n",
      "Epoch 2/30\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3423 - acc: 0.9746\n",
      "Epoch 3/30\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3332 - acc: 0.9673\n",
      "Epoch 4/30\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3269 - acc: 0.9636\n",
      "Epoch 5/30\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3212 - acc: 0.9570\n",
      "Epoch 6/30\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3186 - acc: 0.9488\n",
      "Epoch 7/30\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3161 - acc: 0.9459\n",
      "Epoch 8/30\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3139 - acc: 0.9413\n",
      "Epoch 9/30\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3139 - acc: 0.9366\n",
      "Epoch 10/30\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3122 - acc: 0.9334\n",
      "Epoch 11/30\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3117 - acc: 0.9246\n",
      "Epoch 12/30\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3113 - acc: 0.9239\n",
      "Epoch 13/30\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3101 - acc: 0.9192\n",
      "Epoch 14/30\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3109 - acc: 0.9167\n",
      "Epoch 15/30\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3136 - acc: 0.9156\n",
      "Epoch 16/30\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3120 - acc: 0.9071\n",
      "Epoch 17/30\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3112 - acc: 0.9056\n",
      "Epoch 18/30\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3111 - acc: 0.8931\n",
      "Epoch 19/30\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3101 - acc: 0.8974\n",
      "Epoch 20/30\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3130 - acc: 0.8895\n",
      "Epoch 21/30\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3092 - acc: 0.8938\n",
      "Epoch 22/30\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3096 - acc: 0.8904\n",
      "Epoch 23/30\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3136 - acc: 0.8872\n",
      "Epoch 24/30\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3114 - acc: 0.8820\n",
      "Epoch 25/30\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3110 - acc: 0.8763\n",
      "Epoch 26/30\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.3130 - acc: 0.8857\n",
      "Epoch 27/30\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3100 - acc: 0.8712\n",
      "Epoch 28/30\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3110 - acc: 0.8778\n",
      "Epoch 29/30\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3092 - acc: 0.8739\n",
      "Epoch 30/30\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.3103 - acc: 0.8714\n",
      "15473/15473 [==============================] - 16s 1ms/step\n",
      "30945/30945 [==============================] - 25s 810us/step\n",
      "[CV] .................... epochs=30, lr=0.003, nodes=64, total=27.7min\n",
      "[CV] epochs=30, lr=0.003, nodes=64 ...................................\n",
      "Epoch 1/30\n",
      "30946/30946 [==============================] - 66s 2ms/step - loss: 0.3500 - acc: 0.9782\n",
      "Epoch 2/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.3314 - acc: 0.9730\n",
      "Epoch 3/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.3215 - acc: 0.9672\n",
      "Epoch 4/30\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3165 - acc: 0.9574\n",
      "Epoch 5/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.3089 - acc: 0.9505\n",
      "Epoch 6/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.3075 - acc: 0.9494\n",
      "Epoch 7/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.3031 - acc: 0.9425\n",
      "Epoch 8/30\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3020 - acc: 0.9327\n",
      "Epoch 9/30\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3018 - acc: 0.9267\n",
      "Epoch 10/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2997 - acc: 0.9191\n",
      "Epoch 11/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2990 - acc: 0.9197\n",
      "Epoch 12/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2984 - acc: 0.9203\n",
      "Epoch 13/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2979 - acc: 0.9107\n",
      "Epoch 14/30\n",
      "30946/30946 [==============================] - 56s 2ms/step - loss: 0.2976 - acc: 0.9034\n",
      "Epoch 15/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2955 - acc: 0.9067\n",
      "Epoch 16/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2961 - acc: 0.9030\n",
      "Epoch 17/30\n",
      "30946/30946 [==============================] - 56s 2ms/step - loss: 0.2995 - acc: 0.8987\n",
      "Epoch 18/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2973 - acc: 0.8911\n",
      "Epoch 19/30\n",
      "30946/30946 [==============================] - 56s 2ms/step - loss: 0.2986 - acc: 0.8862\n",
      "Epoch 20/30\n",
      "30946/30946 [==============================] - 56s 2ms/step - loss: 0.3000 - acc: 0.8894\n",
      "Epoch 21/30\n",
      "30946/30946 [==============================] - 56s 2ms/step - loss: 0.2995 - acc: 0.8803\n",
      "Epoch 22/30\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3002 - acc: 0.8782\n",
      "Epoch 23/30\n",
      "30946/30946 [==============================] - 56s 2ms/step - loss: 0.3014 - acc: 0.8740\n",
      "Epoch 24/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.3013 - acc: 0.8715\n",
      "Epoch 25/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.3024 - acc: 0.8618\n",
      "Epoch 26/30\n",
      "30946/30946 [==============================] - 56s 2ms/step - loss: 0.3032 - acc: 0.8683\n",
      "Epoch 27/30\n",
      "30946/30946 [==============================] - 56s 2ms/step - loss: 0.3019 - acc: 0.8635\n",
      "Epoch 28/30\n",
      "30946/30946 [==============================] - 56s 2ms/step - loss: 0.3032 - acc: 0.8641\n",
      "Epoch 29/30\n",
      "30946/30946 [==============================] - 56s 2ms/step - loss: 0.3030 - acc: 0.8644\n",
      "Epoch 30/30\n",
      "30946/30946 [==============================] - 56s 2ms/step - loss: 0.3010 - acc: 0.8560\n",
      "15472/15472 [==============================] - 16s 1ms/step\n",
      "30946/30946 [==============================] - 26s 831us/step\n",
      "[CV] .................... epochs=30, lr=0.003, nodes=64, total=28.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  81 out of  81 | elapsed: 1693.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "46418/46418 [==============================] - 47s 1ms/step - loss: 0.3641 - acc: 0.9618\n",
      "Epoch 2/10\n",
      "46418/46418 [==============================] - 45s 965us/step - loss: 0.3442 - acc: 0.9830\n",
      "Epoch 3/10\n",
      "46418/46418 [==============================] - 44s 946us/step - loss: 0.3383 - acc: 0.9804\n",
      "Epoch 4/10\n",
      "46418/46418 [==============================] - 44s 944us/step - loss: 0.3344 - acc: 0.9750\n",
      "Epoch 5/10\n",
      "46418/46418 [==============================] - 43s 936us/step - loss: 0.3320 - acc: 0.9718\n",
      "Epoch 6/10\n",
      "46418/46418 [==============================] - 43s 934us/step - loss: 0.3297 - acc: 0.9654\n",
      "Epoch 7/10\n",
      "46418/46418 [==============================] - 43s 933us/step - loss: 0.3277 - acc: 0.9643\n",
      "Epoch 8/10\n",
      "46418/46418 [==============================] - 43s 934us/step - loss: 0.3257 - acc: 0.9574\n",
      "Epoch 9/10\n",
      "46418/46418 [==============================] - 43s 937us/step - loss: 0.3251 - acc: 0.9565\n",
      "Epoch 10/10\n",
      "46418/46418 [==============================] - 43s 937us/step - loss: 0.3240 - acc: 0.9539\n"
     ]
    }
   ],
   "source": [
    "#start fitting process\n",
    "param_grid = dict(epochs=epochs,nodes=nodes, lr=lrs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1,refit=True,verbose=2)\n",
    "grid_result = grid.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7ffc79278>,\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'epochs': [10, 20, 30], 'nodes': [16, 32, 64], 'lr': [0.001, 0.002, 0.003]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=2)\n"
     ]
    }
   ],
   "source": [
    "print(grid_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator : <keras.wrappers.scikit_learn.KerasClassifier object at 0x887d8e8d0>\n",
      "Best score : 0.9802662760148995\n",
      "Best params : {'epochs': 10, 'lr': 0.001, 'nodes': 16}\n"
     ]
    }
   ],
   "source": [
    "print('Best estimator : {}'.format (grid.best_estimator_))\n",
    "print('Best score : {}'.format(grid.best_score_))\n",
    "print('Best params : {}'.format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([  282.14273198,   412.61235968,   590.69232233,   267.92312781,\n",
      "         392.4418989 ,   593.37367829,   246.37826745,   373.27251657,\n",
      "         585.33218129,   446.11738094,   675.25052961,  1095.17514602,\n",
      "         467.25050513,   668.95570461,  1108.70000831,   472.17317764,\n",
      "         698.6985542 ,  1210.74587321,   725.23662893,  1192.23849821,\n",
      "       13149.07480772,   788.9326237 ,  1096.581803  ,  1758.84920621,\n",
      "         752.81749868,  1062.1605703 ,  1698.34982109]), 'std_fit_time': array([2.23591969e+01, 2.15047723e+00, 2.64419706e+01, 2.76638036e+00,\n",
      "       1.48957421e+01, 1.52180747e+01, 1.64775877e+01, 1.12871429e+01,\n",
      "       4.83799418e+00, 3.62796152e+01, 1.81110625e+01, 3.96805023e+00,\n",
      "       4.08766490e+00, 3.99024957e+00, 1.62677176e+01, 7.07579227e+00,\n",
      "       3.89000555e+01, 6.99882339e+01, 1.55882980e+01, 4.87303314e+01,\n",
      "       1.58591078e+04, 2.11081407e+01, 1.12746574e+01, 7.81184425e+01,\n",
      "       6.30624252e+00, 1.40923421e+01, 4.29098750e+01]), 'mean_score_time': array([12.02174298, 14.38173946, 13.46587944, 12.32335536, 12.92721065,\n",
      "       13.93557262, 11.21999733, 13.33071971, 14.39609599, 11.50784167,\n",
      "       13.76164508, 13.82472722, 12.9402113 , 13.82380398, 14.44641264,\n",
      "       13.24558075, 14.79218674, 14.20285447, 13.89610442, 16.36801004,\n",
      "       16.2751472 , 14.77849229, 15.88712605, 15.95045932, 14.8662227 ,\n",
      "       15.4829824 , 15.09711059]), 'std_score_time': array([1.16481462, 0.11500077, 0.40565325, 0.03134912, 0.37499668,\n",
      "       0.29574422, 0.73839175, 0.05551965, 0.13849248, 0.64646563,\n",
      "       0.31374801, 0.02677314, 0.08158559, 0.04038155, 0.64145047,\n",
      "       0.16964276, 1.26399535, 0.18698179, 0.4390211 , 0.22425822,\n",
      "       1.47202456, 0.33031886, 0.68195178, 0.27370412, 0.20737284,\n",
      "       0.02631901, 1.01448767]), 'param_epochs': masked_array(data=[10, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20,\n",
      "                   20, 20, 20, 20, 30, 30, 30, 30, 30, 30, 30, 30, 30],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_lr': masked_array(data=[0.001, 0.001, 0.001, 0.002, 0.002, 0.002, 0.003, 0.003,\n",
      "                   0.003, 0.001, 0.001, 0.001, 0.002, 0.002, 0.002, 0.003,\n",
      "                   0.003, 0.003, 0.001, 0.001, 0.001, 0.002, 0.002, 0.002,\n",
      "                   0.003, 0.003, 0.003],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_nodes': masked_array(data=[16, 32, 64, 16, 32, 64, 16, 32, 64, 16, 32, 64, 16, 32,\n",
      "                   64, 16, 32, 64, 16, 32, 64, 16, 32, 64, 16, 32, 64],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'epochs': 10, 'lr': 0.001, 'nodes': 16}, {'epochs': 10, 'lr': 0.001, 'nodes': 32}, {'epochs': 10, 'lr': 0.001, 'nodes': 64}, {'epochs': 10, 'lr': 0.002, 'nodes': 16}, {'epochs': 10, 'lr': 0.002, 'nodes': 32}, {'epochs': 10, 'lr': 0.002, 'nodes': 64}, {'epochs': 10, 'lr': 0.003, 'nodes': 16}, {'epochs': 10, 'lr': 0.003, 'nodes': 32}, {'epochs': 10, 'lr': 0.003, 'nodes': 64}, {'epochs': 20, 'lr': 0.001, 'nodes': 16}, {'epochs': 20, 'lr': 0.001, 'nodes': 32}, {'epochs': 20, 'lr': 0.001, 'nodes': 64}, {'epochs': 20, 'lr': 0.002, 'nodes': 16}, {'epochs': 20, 'lr': 0.002, 'nodes': 32}, {'epochs': 20, 'lr': 0.002, 'nodes': 64}, {'epochs': 20, 'lr': 0.003, 'nodes': 16}, {'epochs': 20, 'lr': 0.003, 'nodes': 32}, {'epochs': 20, 'lr': 0.003, 'nodes': 64}, {'epochs': 30, 'lr': 0.001, 'nodes': 16}, {'epochs': 30, 'lr': 0.001, 'nodes': 32}, {'epochs': 30, 'lr': 0.001, 'nodes': 64}, {'epochs': 30, 'lr': 0.002, 'nodes': 16}, {'epochs': 30, 'lr': 0.002, 'nodes': 32}, {'epochs': 30, 'lr': 0.002, 'nodes': 64}, {'epochs': 30, 'lr': 0.003, 'nodes': 16}, {'epochs': 30, 'lr': 0.003, 'nodes': 32}, {'epochs': 30, 'lr': 0.003, 'nodes': 64}], 'split0_test_score': array([0.98351968, 0.97725069, 0.95779745, 0.98009436, 0.96833193,\n",
      "       0.95088218, 0.97544109, 0.95139921, 0.97214503, 0.97382537,\n",
      "       0.95404899, 0.93013637, 0.96426032, 0.94584114, 0.90609449,\n",
      "       0.95165773, 0.91869709, 0.90305694, 0.96005946, 0.92302721,\n",
      "       0.89995476, 0.94920184, 0.91766303, 0.90758095, 0.94842629,\n",
      "       0.93239837, 0.92606476]), 'split1_test_score': array([0.9747948 , 0.97679829, 0.96361404, 0.9777031 , 0.97240354,\n",
      "       0.96561753, 0.97608738, 0.96955988, 0.96348478, 0.97033542,\n",
      "       0.95740968, 0.94674594, 0.97621664, 0.94357914, 0.90674077,\n",
      "       0.95960706, 0.94286822, 0.92451367, 0.96975376, 0.9380857 ,\n",
      "       0.92179926, 0.94222193, 0.92515996, 0.92257481, 0.94144639,\n",
      "       0.91307439, 0.92386738]), 'split2_test_score': array([0.98248449, 0.97440538, 0.95934592, 0.97330662, 0.96904085,\n",
      "       0.96464581, 0.9663909 , 0.95314116, 0.95643744, 0.9709152 ,\n",
      "       0.94525595, 0.92638314, 0.9473242 , 0.93181231, 0.92567218,\n",
      "       0.94234747, 0.92418563, 0.87609876, 0.96063857, 0.93265253,\n",
      "       0.90324457, 0.93368666, 0.89438987, 0.90059462, 0.94034385,\n",
      "       0.91171148, 0.88139866]), 'mean_test_score': array([0.98026628, 0.97615149, 0.96025249, 0.97703477, 0.96992546,\n",
      "       0.96038175, 0.97263992, 0.95803352, 0.96402258, 0.97169202,\n",
      "       0.95223836, 0.93442199, 0.96260072, 0.94041105, 0.91283554,\n",
      "       0.95120427, 0.92858374, 0.90122366, 0.96348399, 0.93125512,\n",
      "       0.90833297, 0.94170365, 0.91240467, 0.91025033, 0.94340558,\n",
      "       0.91906157, 0.91044422]), 'std_test_score': array([0.00389199, 0.00124839, 0.00245964, 0.00281108, 0.00177604,\n",
      "       0.00672902, 0.00442646, 0.00818146, 0.00642383, 0.00152699,\n",
      "       0.00512424, 0.00884817, 0.01185346, 0.00614976, 0.00908042,\n",
      "       0.00705345, 0.01034636, 0.01980766, 0.00443977, 0.00622657,\n",
      "       0.00961651, 0.0063446 , 0.01310052, 0.0091697 , 0.00357866,\n",
      "       0.00944709, 0.02055724]), 'rank_test_score': array([ 1,  3, 11,  2,  6, 10,  4, 12,  7,  5, 13, 18,  9, 17, 22, 14, 20,\n",
      "       27,  8, 19, 26, 16, 23, 25, 15, 21, 24], dtype=int32), 'split0_train_score': array([0.98545807, 0.97676523, 0.95201163, 0.97634513, 0.96351592,\n",
      "       0.94703506, 0.97259654, 0.94364195, 0.97056067, 0.97450315,\n",
      "       0.94926482, 0.92506059, 0.95983196, 0.94231701, 0.89794797,\n",
      "       0.95401519, 0.91278074, 0.89251899, 0.95789304, 0.92008402,\n",
      "       0.88993375, 0.94819842, 0.91694943, 0.90176119, 0.95097754,\n",
      "       0.93633867, 0.92502828]), 'split1_train_score': array([0.97014057, 0.97498788, 0.96125384, 0.97731459, 0.96742608,\n",
      "       0.9592826 , 0.9723057 , 0.96749071, 0.95708515, 0.96984973,\n",
      "       0.95369203, 0.94057198, 0.97847794, 0.93679108, 0.89193731,\n",
      "       0.95847471, 0.94322185, 0.91291   , 0.96933269, 0.9372435 ,\n",
      "       0.91714332, 0.94076587, 0.91888835, 0.91601228, 0.94028114,\n",
      "       0.90990467, 0.92308935]), 'split2_train_score': array([0.98203322, 0.9707232 , 0.95692497, 0.96859045, 0.96232146,\n",
      "       0.96170749, 0.96361404, 0.94936341, 0.95253021, 0.97088477,\n",
      "       0.94302979, 0.92257481, 0.94955729, 0.93181671, 0.91840626,\n",
      "       0.94025076, 0.91921411, 0.8577199 , 0.96177212, 0.93414335,\n",
      "       0.89724035, 0.93582369, 0.89071285, 0.89930847, 0.94845861,\n",
      "       0.91268662, 0.87665611]), 'mean_train_score': array([0.97921062, 0.97415877, 0.95673015, 0.97408339, 0.96442115,\n",
      "       0.95600838, 0.96950543, 0.95349869, 0.96005868, 0.97174588,\n",
      "       0.94866222, 0.92940246, 0.9626224 , 0.93697494, 0.90276385,\n",
      "       0.95091355, 0.92507223, 0.8877163 , 0.96299928, 0.93049029,\n",
      "       0.90143914, 0.94159599, 0.90885021, 0.90569398, 0.94657243,\n",
      "       0.91964332, 0.90825791]), 'std_train_score': array([0.00656413, 0.00253536, 0.00377563, 0.00390421, 0.00218004,\n",
      "       0.00642186, 0.00416753, 0.01016583, 0.00765531, 0.00199495,\n",
      "       0.00437365, 0.00796297, 0.01197055, 0.0042887 , 0.01132978,\n",
      "       0.00775643, 0.0130997 , 0.02278576, 0.00475015, 0.00746639,\n",
      "       0.01149819, 0.00508595, 0.01284945, 0.00736453, 0.00456592,\n",
      "       0.0118599 , 0.02235986])}\n"
     ]
    }
   ],
   "source": [
    "print(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predictions\n",
    "predictions = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23209, 6)\n"
     ]
    }
   ],
   "source": [
    "#predictions\n",
    "predict = grid.predict_proba(X_test)\n",
    "print(predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log_loss : 0.3504030505499869\n",
      "Hamming_loss : 15.158630990851249\n",
      "Accuracy : 21.612305571114653\n"
     ]
    }
   ],
   "source": [
    "#calculate score\n",
    "loss = log_loss(Y_test,predict)\n",
    "print(\"Log_loss : {}\".format(loss))\n",
    "predict = np.round(predict)\n",
    "loss = hamming_loss(Y_test,predict)\n",
    "print(\"Hamming_loss : {}\".format(loss*100))\n",
    "accuracy = accuracy_score(Y_test,predict)\n",
    "print(\"Accuracy : {}\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Free Form Visualisation \n",
    "Let us have a plot showing the **hamming-loss** and **log-loss** of different models, which we selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAE5CAYAAACDPheMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJUkYERFRSRJGRERUkoQRERGV/H/LbTmVkDrdSwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1053d0da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = ['BR-MultNB','BR-GausNB','BR-SVC','CC-MultNB','LP-MultNB','BP-MLL-ini','BP-MLL-fin']\n",
    "y = [3.27,20.74,4.26,3.56,3.17,13.96,15.158]\n",
    "colors = itertools.cycle(['b', 'g', 'r', 'c', 'm', 'y', 'k'])\n",
    "plt.ylabel('Hamming-Loss')\n",
    "plt.xlabel('Model-details')\n",
    "plt.xticks(rotation=90)\n",
    "for i in range(len(y)):\n",
    "    plt.bar(x[i], y[i], color=next(colors))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAE5CAYAAACDPheMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIqKSBEZERFSSwIiIiEr+P2MtWFYAG0YWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106d5f320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = ['BR-MultNB','BR-GausNB','BR-SVC','CC-MultNB','LP-MultNB','BP-MLL-ini','BP-MLL-fin']\n",
    "y = [1.92,1.422,0.46,1.5,1.47,0.36,0.35]\n",
    "colors = itertools.cycle(['b', 'g', 'r', 'c', 'm', 'y', 'k'])\n",
    "plt.ylabel('Log-Loss')\n",
    "plt.xlabel('Model-details')\n",
    "plt.xticks(rotation=90)\n",
    "for i in range(len(y)):\n",
    "    plt.bar(x[i], y[i], color=next(colors))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- While showing among the best problem transformation method models, hamming-loss was considered (this is because for BP-MLL neural network we had to round the final results to get the hamming-loss because of the output being multivalued probabilities)\n",
    "- But while chosing among the best Adaptation Algorithm model, log loss was preferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
